travis_fold:start:worker_info[0K[33;1mWorker information[0m
hostname: i-07c3f6b-precise-production-2-worker-org-docker.travisci.net:23ef416d-3c79-40b9-b3e3-cb00694257c3
version: v2.5.0 https://github.com/travis-ci/worker/tree/da3a43228dffc0fcca5a46569ca786b22991979f
instance: 4824d32:travis:scala
startup: 609.795375ms
travis_fold:end:worker_info[0Ktravis_fold:start:system_info[0K[33;1mBuild system information[0m
Build language: scala
Build group: stable
Build dist: precise
Build id: 238842038
Job id: 238842040
travis-build version: 53940dac2
[34m[1mBuild image provisioning date and time[0m
Thu Feb  5 15:09:33 UTC 2015
[34m[1mOperating System Details[0m
Distributor ID:	Ubuntu
Description:	Ubuntu 12.04.5 LTS
Release:	12.04
Codename:	precise
[34m[1mLinux Version[0m
3.13.0-29-generic
[34m[1mCookbooks Version[0m
a68419e https://github.com/travis-ci/travis-cookbooks/tree/a68419e
[34m[1mGCC version[0m
gcc (Ubuntu/Linaro 4.6.3-1ubuntu5) 4.6.3
Copyright (C) 2011 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.

[34m[1mLLVM version[0m
clang version 3.4 (tags/RELEASE_34/final)
Target: x86_64-unknown-linux-gnu
Thread model: posix
[34m[1mPre-installed Ruby versions[0m
ruby-1.9.3-p551
[34m[1mPre-installed Node.js versions[0m
v0.10.36
[34m[1mPre-installed Go versions[0m
1.4.1
[34m[1mRedis version[0m
redis-server 2.8.19
[34m[1mriak version[0m
2.0.2
[34m[1mMongoDB version[0m
MongoDB 2.4.12
[34m[1mCouchDB version[0m
couchdb 1.6.1
[34m[1mNeo4j version[0m
1.9.4
[34m[1mRabbitMQ Version[0m
3.4.3
[34m[1mElasticSearch version[0m
1.4.0
[34m[1mInstalled Sphinx versions[0m
2.0.10
2.1.9
2.2.6
[34m[1mDefault Sphinx version[0m
2.2.6
[34m[1mInstalled Firefox version[0m
firefox 31.0esr
[34m[1mPhantomJS version[0m
1.9.8
[34m[1mant -version[0m
Apache Ant(TM) version 1.8.2 compiled on December 3 2011
[34m[1mmvn -version[0m
Apache Maven 3.2.5 (12a6b3acb947671f09b81f49094c53f426d8cea1; 2014-12-14T17:29:23+00:00)
Maven home: /usr/local/maven
Java version: 1.7.0_76, vendor: Oracle Corporation
Java home: /usr/lib/jvm/java-7-oracle/jre
Default locale: en_US, platform encoding: ANSI_X3.4-1968
OS name: "linux", version: "3.13.0-29-generic", arch: "amd64", family: "unix"
travis_fold:end:system_info[0K
travis_fold:start:fix.CVE-2015-7547[0K$ export DEBIAN_FRONTEND=noninteractive
Reading package lists...
Building dependency tree...
Reading state information...
The following extra packages will be installed:
  libc-bin libc-dev-bin libc6-dev
Suggested packages:
  glibc-doc
The following packages will be upgraded:
  libc-bin libc-dev-bin libc6 libc6-dev
4 upgraded, 0 newly installed, 0 to remove and 278 not upgraded.
Need to get 8,856 kB of archives.
After this operation, 13.3 kB of additional disk space will be used.
Get:1 http://us.archive.ubuntu.com/ubuntu/ precise-updates/main libc6-dev amd64 2.15-0ubuntu10.18 [2,948 kB]
Get:2 http://us.archive.ubuntu.com/ubuntu/ precise-updates/main libc-dev-bin amd64 2.15-0ubuntu10.18 [84.5 kB]
Get:3 http://us.archive.ubuntu.com/ubuntu/ precise-updates/main libc-bin amd64 2.15-0ubuntu10.18 [1,178 kB]
Get:4 http://us.archive.ubuntu.com/ubuntu/ precise-updates/main libc6 amd64 2.15-0ubuntu10.18 [4,646 kB]
Fetched 8,856 kB in 0s (34.6 MB/s)
Preconfiguring packages ...
(Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 72019 files and directories currently installed.)
Preparing to replace libc6-dev 2.15-0ubuntu10.10 (using .../libc6-dev_2.15-0ubuntu10.18_amd64.deb) ...
Unpacking replacement libc6-dev ...
Preparing to replace libc-dev-bin 2.15-0ubuntu10.10 (using .../libc-dev-bin_2.15-0ubuntu10.18_amd64.deb) ...
Unpacking replacement libc-dev-bin ...
Preparing to replace libc-bin 2.15-0ubuntu10.10 (using .../libc-bin_2.15-0ubuntu10.18_amd64.deb) ...
Unpacking replacement libc-bin ...
Processing triggers for man-db ...
Setting up libc-bin (2.15-0ubuntu10.18) ...
(Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 72018 files and directories currently installed.)
Preparing to replace libc6 2.15-0ubuntu10.10 (using .../libc6_2.15-0ubuntu10.18_amd64.deb) ...
Unpacking replacement libc6 ...
Setting up libc6 (2.15-0ubuntu10.18) ...
Setting up libc-dev-bin (2.15-0ubuntu10.18) ...
Setting up libc6-dev (2.15-0ubuntu10.18) ...
Processing triggers for libc-bin ...
ldconfig deferred processing now taking place
travis_fold:end:fix.CVE-2015-7547[0Ktravis_fold:start:update_libssl1.0.0[0K$ sudo apt-get install libssl1.0.0
Reading package lists... 0%Reading package lists... 0%Reading package lists... 1%Reading package lists... 10%Reading package lists... 10%Reading package lists... 11%Reading package lists... 11%Reading package lists... 46%Reading package lists... 46%Reading package lists... 46%Reading package lists... 47%Reading package lists... 47%Reading package lists... 58%Reading package lists... 58%Reading package lists... 58%Reading package lists... 58%Reading package lists... 94%Reading package lists... 94%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 95%Reading package lists... 96%Reading package lists... 96%Reading package lists... 96%Reading package lists... 96%Reading package lists... 97%Reading package lists... 97%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... 98%Reading package lists... Done
Building dependency tree... 0%Building dependency tree... 0%Building dependency tree... 50%Building dependency tree... 50%Building dependency tree... 65%Building dependency tree       
Reading state information... 0%Reading state information... 0%Reading state information... Done
The following extra packages will be installed:
  libssl-dev
The following packages will be upgraded:
  libssl-dev libssl1.0.0
2 upgraded, 0 newly installed, 0 to remove and 276 not upgraded.
Need to get 2,634 kB of archives.
After this operation, 29.7 kB of additional disk space will be used.
0% [Working]            Get:1 http://us.archive.ubuntu.com/ubuntu/ precise-updates/main libssl-dev amd64 1.0.1-4ubuntu5.39 [1,580 kB]
            1% [1 libssl-dev 14.1 kB/1,580 kB 1%]                                     60% [Working]             Get:2 http://us.archive.ubuntu.com/ubuntu/ precise-updates/main libssl1.0.0 amd64 1.0.1-4ubuntu5.39 [1,054 kB]
             61% [2 libssl1.0.0 36.9 kB/1,054 kB 3%]                                       100% [Working]              Fetched 2,634 kB in 0s (6,497 kB/s)
Preconfiguring packages ...
(Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 72018 files and directories currently installed.)
Preparing to replace libssl-dev 1.0.1-4ubuntu5.21 (using .../libssl-dev_1.0.1-4ubuntu5.39_amd64.deb) ...
Unpacking replacement libssl-dev ...
Preparing to replace libssl1.0.0 1.0.1-4ubuntu5.21 (using .../libssl1.0.0_1.0.1-4ubuntu5.39_amd64.deb) ...
Unpacking replacement libssl1.0.0 ...
Setting up libssl1.0.0 (1.0.1-4ubuntu5.39) ...
Setting up libssl-dev (1.0.1-4ubuntu5.39) ...
Processing triggers for libc-bin ...
ldconfig deferred processing now taking place
travis_fold:end:update_libssl1.0.0[0K$ jdk_switcher use oraclejdk8
Switching to Oracle JDK8 (java-8-oracle), JAVA_HOME will be set to /usr/lib/jvm/java-8-oracle
[32;1mUpdating sbt[0m
travis_fold:start:git.checkout[0Ktravis_time:start:22270fbc[0K$ git clone --depth=50 --branch=feature/constructor-level-injection https://github.com/dcshock/forklift.git dcshock/forklift
Cloning into 'dcshock/forklift'...
remote: Counting objects: 2319, done.[K
remote: Compressing objects:   0% (1/1025)   [Kremote: Compressing objects:   1% (11/1025)   [Kremote: Compressing objects:   2% (21/1025)   [Kremote: Compressing objects:   3% (31/1025)   [Kremote: Compressing objects:   4% (41/1025)   [Kremote: Compressing objects:   5% (52/1025)   [Kremote: Compressing objects:   6% (62/1025)   [Kremote: Compressing objects:   7% (72/1025)   [Kremote: Compressing objects:   8% (82/1025)   [Kremote: Compressing objects:   9% (93/1025)   [Kremote: Compressing objects:  10% (103/1025)   [Kremote: Compressing objects:  11% (113/1025)   [Kremote: Compressing objects:  12% (123/1025)   [Kremote: Compressing objects:  13% (134/1025)   [Kremote: Compressing objects:  14% (144/1025)   [Kremote: Compressing objects:  15% (154/1025)   [Kremote: Compressing objects:  16% (164/1025)   [Kremote: Compressing objects:  17% (175/1025)   [Kremote: Compressing objects:  18% (185/1025)   [Kremote: Compressing objects:  19% (195/1025)   [Kremote: Compressing objects:  20% (205/1025)   [Kremote: Compressing objects:  21% (216/1025)   [Kremote: Compressing objects:  22% (226/1025)   [Kremote: Compressing objects:  23% (236/1025)   [Kremote: Compressing objects:  24% (246/1025)   [Kremote: Compressing objects:  25% (257/1025)   [Kremote: Compressing objects:  26% (267/1025)   [Kremote: Compressing objects:  27% (277/1025)   [Kremote: Compressing objects:  28% (287/1025)   [Kremote: Compressing objects:  29% (298/1025)   [Kremote: Compressing objects:  30% (308/1025)   [Kremote: Compressing objects:  31% (318/1025)   [Kremote: Compressing objects:  32% (328/1025)   [Kremote: Compressing objects:  33% (339/1025)   [Kremote: Compressing objects:  34% (349/1025)   [Kremote: Compressing objects:  35% (359/1025)   [Kremote: Compressing objects:  36% (369/1025)   [Kremote: Compressing objects:  37% (380/1025)   [Kremote: Compressing objects:  38% (390/1025)   [Kremote: Compressing objects:  39% (400/1025)   [Kremote: Compressing objects:  40% (410/1025)   [Kremote: Compressing objects:  41% (421/1025)   [Kremote: Compressing objects:  42% (431/1025)   [Kremote: Compressing objects:  43% (441/1025)   [Kremote: Compressing objects:  44% (451/1025)   [Kremote: Compressing objects:  45% (462/1025)   [Kremote: Compressing objects:  46% (472/1025)   [Kremote: Compressing objects:  47% (482/1025)   [Kremote: Compressing objects:  48% (492/1025)   [Kremote: Compressing objects:  49% (503/1025)   [Kremote: Compressing objects:  50% (513/1025)   [Kremote: Compressing objects:  51% (523/1025)   [Kremote: Compressing objects:  52% (533/1025)   [Kremote: Compressing objects:  53% (544/1025)   [Kremote: Compressing objects:  54% (554/1025)   [Kremote: Compressing objects:  55% (564/1025)   [Kremote: Compressing objects:  56% (574/1025)   [Kremote: Compressing objects:  57% (585/1025)   [Kremote: Compressing objects:  58% (595/1025)   [Kremote: Compressing objects:  59% (605/1025)   [Kremote: Compressing objects:  60% (615/1025)   [Kremote: Compressing objects:  61% (626/1025)   [Kremote: Compressing objects:  62% (636/1025)   [Kremote: Compressing objects:  63% (646/1025)   [Kremote: Compressing objects:  64% (656/1025)   [Kremote: Compressing objects:  65% (667/1025)   [Kremote: Compressing objects:  66% (677/1025)   [Kremote: Compressing objects:  67% (687/1025)   [Kremote: Compressing objects:  68% (697/1025)   [Kremote: Compressing objects:  69% (708/1025)   [Kremote: Compressing objects:  70% (718/1025)   [Kremote: Compressing objects:  71% (728/1025)   [Kremote: Compressing objects:  72% (738/1025)   [Kremote: Compressing objects:  73% (749/1025)   [Kremote: Compressing objects:  74% (759/1025)   [Kremote: Compressing objects:  75% (769/1025)   [Kremote: Compressing objects:  76% (779/1025)   [Kremote: Compressing objects:  77% (790/1025)   [Kremote: Compressing objects:  78% (800/1025)   [Kremote: Compressing objects:  79% (810/1025)   [Kremote: Compressing objects:  80% (820/1025)   [Kremote: Compressing objects:  81% (831/1025)   [Kremote: Compressing objects:  82% (841/1025)   [Kremote: Compressing objects:  83% (851/1025)   [Kremote: Compressing objects:  84% (861/1025)   [Kremote: Compressing objects:  85% (872/1025)   [Kremote: Compressing objects:  86% (882/1025)   [Kremote: Compressing objects:  87% (892/1025)   [Kremote: Compressing objects:  88% (902/1025)   [Kremote: Compressing objects:  89% (913/1025)   [Kremote: Compressing objects:  90% (923/1025)   [Kremote: Compressing objects:  91% (933/1025)   [Kremote: Compressing objects:  92% (943/1025)   [Kremote: Compressing objects:  93% (954/1025)   [Kremote: Compressing objects:  94% (964/1025)   [Kremote: Compressing objects:  95% (974/1025)   [Kremote: Compressing objects:  96% (984/1025)   [Kremote: Compressing objects:  97% (995/1025)   [Kremote: Compressing objects:  98% (1005/1025)   [Kremote: Compressing objects:  99% (1015/1025)   [Kremote: Compressing objects: 100% (1025/1025)   [Kremote: Compressing objects: 100% (1025/1025), done.[K
Receiving objects:   0% (1/2319)   Receiving objects:   1% (24/2319)   Receiving objects:   2% (47/2319)   Receiving objects:   3% (70/2319)   Receiving objects:   4% (93/2319)   Receiving objects:   5% (116/2319)   Receiving objects:   6% (140/2319)   Receiving objects:   7% (163/2319)   Receiving objects:   8% (186/2319)   Receiving objects:   9% (209/2319)   Receiving objects:  10% (232/2319)   Receiving objects:  11% (256/2319)   Receiving objects:  12% (279/2319)   Receiving objects:  13% (302/2319)   Receiving objects:  14% (325/2319)   Receiving objects:  15% (348/2319)   Receiving objects:  16% (372/2319)   Receiving objects:  17% (395/2319)   Receiving objects:  18% (418/2319)   Receiving objects:  19% (441/2319)   Receiving objects:  20% (464/2319)   Receiving objects:  21% (487/2319)   Receiving objects:  22% (511/2319)   Receiving objects:  23% (534/2319)   Receiving objects:  24% (557/2319)   Receiving objects:  25% (580/2319)   Receiving objects:  26% (603/2319)   Receiving objects:  27% (627/2319)   Receiving objects:  28% (650/2319)   Receiving objects:  29% (673/2319)   Receiving objects:  30% (696/2319)   Receiving objects:  31% (719/2319)   Receiving objects:  32% (743/2319)   Receiving objects:  33% (766/2319)   Receiving objects:  34% (789/2319)   Receiving objects:  35% (812/2319)   Receiving objects:  36% (835/2319)   Receiving objects:  37% (859/2319)   Receiving objects:  38% (882/2319)   Receiving objects:  39% (905/2319)   Receiving objects:  40% (928/2319)   Receiving objects:  41% (951/2319)   Receiving objects:  42% (974/2319)   Receiving objects:  43% (998/2319)   Receiving objects:  44% (1021/2319)   Receiving objects:  45% (1044/2319)   Receiving objects:  46% (1067/2319)   Receiving objects:  47% (1090/2319)   Receiving objects:  48% (1114/2319)   Receiving objects:  49% (1137/2319)   Receiving objects:  50% (1160/2319)   Receiving objects:  51% (1183/2319)   Receiving objects:  52% (1206/2319)   Receiving objects:  53% (1230/2319)   Receiving objects:  54% (1253/2319)   Receiving objects:  55% (1276/2319)   Receiving objects:  56% (1299/2319)   Receiving objects:  57% (1322/2319)   Receiving objects:  58% (1346/2319)   Receiving objects:  59% (1369/2319)   Receiving objects:  60% (1392/2319)   Receiving objects:  61% (1415/2319)   Receiving objects:  62% (1438/2319)   Receiving objects:  63% (1461/2319)   Receiving objects:  64% (1485/2319)   Receiving objects:  65% (1508/2319)   Receiving objects:  66% (1531/2319)   Receiving objects:  67% (1554/2319)   Receiving objects:  68% (1577/2319)   Receiving objects:  69% (1601/2319)   Receiving objects:  70% (1624/2319)   Receiving objects:  71% (1647/2319)   Receiving objects:  72% (1670/2319)   Receiving objects:  73% (1693/2319)   Receiving objects:  74% (1717/2319)   Receiving objects:  75% (1740/2319)   Receiving objects:  76% (1763/2319)   Receiving objects:  77% (1786/2319)   Receiving objects:  78% (1809/2319)   Receiving objects:  79% (1833/2319)   Receiving objects:  80% (1856/2319)   Receiving objects:  81% (1879/2319)   Receiving objects:  82% (1902/2319)   Receiving objects:  83% (1925/2319)   Receiving objects:  84% (1948/2319)   Receiving objects:  85% (1972/2319)   Receiving objects:  86% (1995/2319)   Receiving objects:  87% (2018/2319)   Receiving objects:  88% (2041/2319)   Receiving objects:  89% (2064/2319)   Receiving objects:  90% (2088/2319)   Receiving objects:  91% (2111/2319)   Receiving objects:  92% (2134/2319)   Receiving objects:  93% (2157/2319)   Receiving objects:  94% (2180/2319)   Receiving objects:  95% (2204/2319)   Receiving objects:  96% (2227/2319)   Receiving objects:  97% (2250/2319)   Receiving objects:  98% (2273/2319)   Receiving objects:  99% (2296/2319)   remote: Total 2319 (delta 1068), reused 2098 (delta 953), pack-reused 0[K
Receiving objects: 100% (2319/2319)   Receiving objects: 100% (2319/2319), 1.23 MiB | 0 bytes/s, done.
Resolving deltas:   0% (0/1068)   Resolving deltas:   1% (15/1068)   Resolving deltas:   2% (24/1068)   Resolving deltas:   9% (106/1068)   Resolving deltas:  11% (120/1068)   Resolving deltas:  12% (133/1068)   Resolving deltas:  13% (146/1068)   Resolving deltas:  14% (152/1068)   Resolving deltas:  15% (168/1068)   Resolving deltas:  16% (174/1068)   Resolving deltas:  17% (183/1068)   Resolving deltas:  18% (196/1068)   Resolving deltas:  19% (204/1068)   Resolving deltas:  20% (214/1068)   Resolving deltas:  21% (225/1068)   Resolving deltas:  26% (279/1068)   Resolving deltas:  27% (290/1068)   Resolving deltas:  28% (306/1068)   Resolving deltas:  29% (319/1068)   Resolving deltas:  30% (325/1068)   Resolving deltas:  31% (332/1068)   Resolving deltas:  34% (364/1068)   Resolving deltas:  43% (464/1068)   Resolving deltas:  47% (508/1068)   Resolving deltas:  48% (516/1068)   Resolving deltas:  49% (530/1068)   Resolving deltas:  50% (536/1068)   Resolving deltas:  52% (563/1068)   Resolving deltas:  53% (568/1068)   Resolving deltas:  55% (588/1068)   Resolving deltas:  57% (610/1068)   Resolving deltas:  63% (674/1068)   Resolving deltas:  64% (687/1068)   Resolving deltas:  65% (695/1068)   Resolving deltas:  67% (716/1068)   Resolving deltas:  68% (733/1068)   Resolving deltas:  69% (739/1068)   Resolving deltas:  70% (751/1068)   Resolving deltas:  71% (768/1068)   Resolving deltas:  72% (770/1068)   Resolving deltas:  73% (781/1068)   Resolving deltas:  74% (799/1068)   Resolving deltas:  75% (802/1068)   Resolving deltas:  76% (813/1068)   Resolving deltas:  77% (824/1068)   Resolving deltas:  78% (834/1068)   Resolving deltas:  79% (845/1068)   Resolving deltas:  80% (857/1068)   Resolving deltas:  81% (866/1068)   Resolving deltas:  82% (884/1068)   Resolving deltas:  83% (894/1068)   Resolving deltas:  84% (900/1068)   Resolving deltas:  85% (910/1068)   Resolving deltas:  86% (927/1068)   Resolving deltas:  87% (930/1068)   Resolving deltas:  88% (940/1068)   Resolving deltas:  89% (952/1068)   Resolving deltas:  90% (967/1068)   Resolving deltas:  92% (986/1068)   Resolving deltas:  93% (995/1068)   Resolving deltas:  94% (1009/1068)   Resolving deltas:  95% (1019/1068)   Resolving deltas:  96% (1026/1068)   Resolving deltas:  97% (1039/1068)   Resolving deltas:  98% (1049/1068)   Resolving deltas:  99% (1061/1068)   Resolving deltas: 100% (1068/1068)   Resolving deltas: 100% (1068/1068), done.
Checking connectivity... done.

travis_time:end:22270fbc:start=1496424690703858298,finish=1496424691198228726,duration=494370428[0K$ cd dcshock/forklift
$ git checkout -qf 4ae22ce6b49323f86bd1458d11c1850a215bd9b7
travis_fold:end:git.checkout[0K$ export JVM_OPTS=@/etc/sbt/jvmopts
$ export SBT_OPTS=@/etc/sbt/sbtopts
$ java -Xmx32m -version
java version "1.8.0_31"
Java(TM) SE Runtime Environment (build 1.8.0_31-b13)
Java HotSpot(TM) 64-Bit Server VM (build 25.31-b07, mixed mode)
$ javac -J-Xmx32m -version
javac 1.8.0_31
Using Scala 2.11.4
travis_time:start:104bfdec[0K$ sbt ++2.11.4 test
Detected sbt version 0.13.13
Downloading sbt launcher for 0.13.13:
  From  http://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/sbt-launch/0.13.13/sbt-launch.jar
    To  /home/travis/.sbt/launchers/0.13.13/sbt-launch.jar
Using jvm options defined in file /etc/sbt/jvmopts
# Executing command line:
java
-Xms2048M
-Xmx2048M
-Xss6M
-XX:MaxPermSize=512M
-jar
/home/travis/.sbt/launchers/0.13.13/sbt-launch.jar
++2.11.4
test

Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=512M; support was removed in 8.0
Getting org.scala-sbt sbt 0.13.13 ...
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/sbt/0.13.13/jars/sbt.jar ...
	[SUCCESSFUL ] org.scala-sbt#sbt;0.13.13!sbt.jar (444ms)
downloading https://repo1.maven.org/maven2/org/scala-lang/scala-library/2.10.6/scala-library-2.10.6.jar ...
	[SUCCESSFUL ] org.scala-lang#scala-library;2.10.6!scala-library.jar (2047ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/main/0.13.13/jars/main.jar ...
	[SUCCESSFUL ] org.scala-sbt#main;0.13.13!main.jar (1265ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/compiler-interface/0.13.13/jars/compiler-interface.jar ...
	[SUCCESSFUL ] org.scala-sbt#compiler-interface;0.13.13!compiler-interface.jar (510ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/actions/0.13.13/jars/actions.jar ...
	[SUCCESSFUL ] org.scala-sbt#actions;0.13.13!actions.jar (573ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/main-settings/0.13.13/jars/main-settings.jar ...
	[SUCCESSFUL ] org.scala-sbt#main-settings;0.13.13!main-settings.jar (605ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/interface/0.13.13/jars/interface.jar ...
	[SUCCESSFUL ] org.scala-sbt#interface;0.13.13!interface.jar (430ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/io/0.13.13/jars/io.jar ...
	[SUCCESSFUL ] org.scala-sbt#io;0.13.13!io.jar (519ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/ivy/0.13.13/jars/ivy.jar ...
	[SUCCESSFUL ] org.scala-sbt#ivy;0.13.13!ivy.jar (1014ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/logging/0.13.13/jars/logging.jar ...
	[SUCCESSFUL ] org.scala-sbt#logging;0.13.13!logging.jar (469ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/logic/0.13.13/jars/logic.jar ...
	[SUCCESSFUL ] org.scala-sbt#logic;0.13.13!logic.jar (392ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/process/0.13.13/jars/process.jar ...
	[SUCCESSFUL ] org.scala-sbt#process;0.13.13!process.jar (373ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/run/0.13.13/jars/run.jar ...
	[SUCCESSFUL ] org.scala-sbt#run;0.13.13!run.jar (411ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/command/0.13.13/jars/command.jar ...
	[SUCCESSFUL ] org.scala-sbt#command;0.13.13!command.jar (538ms)
downloading https://repo1.maven.org/maven2/org/scala-sbt/launcher-interface/1.0.0-M1/launcher-interface-1.0.0-M1.jar ...
	[SUCCESSFUL ] org.scala-sbt#launcher-interface;1.0.0-M1!launcher-interface.jar (26ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/classpath/0.13.13/jars/classpath.jar ...
	[SUCCESSFUL ] org.scala-sbt#classpath;0.13.13!classpath.jar (533ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/completion/0.13.13/jars/completion.jar ...
	[SUCCESSFUL ] org.scala-sbt#completion;0.13.13!completion.jar (732ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/api/0.13.13/jars/api.jar ...
	[SUCCESSFUL ] org.scala-sbt#api;0.13.13!api.jar (567ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/compiler-integration/0.13.13/jars/compiler-integration.jar ...
	[SUCCESSFUL ] org.scala-sbt#compiler-integration;0.13.13!compiler-integration.jar (507ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/compiler-ivy-integration/0.13.13/jars/compiler-ivy-integration.jar ...
	[SUCCESSFUL ] org.scala-sbt#compiler-ivy-integration;0.13.13!compiler-ivy-integration.jar (418ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/relation/0.13.13/jars/relation.jar ...
	[SUCCESSFUL ] org.scala-sbt#relation;0.13.13!relation.jar (353ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/task-system/0.13.13/jars/task-system.jar ...
	[SUCCESSFUL ] org.scala-sbt#task-system;0.13.13!task-system.jar (507ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/tasks/0.13.13/jars/tasks.jar ...
	[SUCCESSFUL ] org.scala-sbt#tasks;0.13.13!tasks.jar (651ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/tracking/0.13.13/jars/tracking.jar ...
	[SUCCESSFUL ] org.scala-sbt#tracking;0.13.13!tracking.jar (650ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/testing/0.13.13/jars/testing.jar ...
	[SUCCESSFUL ] org.scala-sbt#testing;0.13.13!testing.jar (405ms)
downloading https://repo1.maven.org/maven2/org/scala-lang/scala-compiler/2.10.6/scala-compiler-2.10.6.jar ...
	[SUCCESSFUL ] org.scala-lang#scala-compiler;2.10.6!scala-compiler.jar (4275ms)
downloading https://repo1.maven.org/maven2/org/scala-lang/scala-reflect/2.10.6/scala-reflect-2.10.6.jar ...
	[SUCCESSFUL ] org.scala-lang#scala-reflect;2.10.6!scala-reflect.jar (988ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/control/0.13.13/jars/control.jar ...
	[SUCCESSFUL ] org.scala-sbt#control;0.13.13!control.jar (441ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/collections/0.13.13/jars/collections.jar ...
	[SUCCESSFUL ] org.scala-sbt#collections;0.13.13!collections.jar (577ms)
downloading https://repo1.maven.org/maven2/jline/jline/2.13/jline-2.13.jar ...
	[SUCCESSFUL ] jline#jline;2.13!jline.jar (95ms)
downloading https://repo1.maven.org/maven2/org/fusesource/jansi/jansi/1.11/jansi-1.11.jar ...
	[SUCCESSFUL ] org.fusesource.jansi#jansi;1.11!jansi.jar (44ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/classfile/0.13.13/jars/classfile.jar ...
	[SUCCESSFUL ] org.scala-sbt#classfile;0.13.13!classfile.jar (470ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/incremental-compiler/0.13.13/jars/incremental-compiler.jar ...
	[SUCCESSFUL ] org.scala-sbt#incremental-compiler;0.13.13!incremental-compiler.jar (605ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/compile/0.13.13/jars/compile.jar ...
	[SUCCESSFUL ] org.scala-sbt#compile;0.13.13!compile.jar (507ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/persist/0.13.13/jars/persist.jar ...
	[SUCCESSFUL ] org.scala-sbt#persist;0.13.13!persist.jar (480ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/cross/0.13.13/jars/cross.jar ...
	[SUCCESSFUL ] org.scala-sbt#cross;0.13.13!cross.jar (368ms)
downloading https://repo1.maven.org/maven2/org/scala-sbt/ivy/ivy/2.3.0-sbt-2cf13e211b2cb31f0d3b317289dca70eca3362f6/ivy-2.3.0-sbt-2cf13e211b2cb31f0d3b317289dca70eca3362f6.jar ...
	[SUCCESSFUL ] org.scala-sbt.ivy#ivy;2.3.0-sbt-2cf13e211b2cb31f0d3b317289dca70eca3362f6!ivy.jar (328ms)
downloading https://repo1.maven.org/maven2/com/jcraft/jsch/0.1.50/jsch-0.1.50.jar ...
	[SUCCESSFUL ] com.jcraft#jsch;0.1.50!jsch.jar (83ms)
downloading https://repo1.maven.org/maven2/org/scala-sbt/serialization_2.10/0.1.2/serialization_2.10-0.1.2.jar ...
	[SUCCESSFUL ] org.scala-sbt#serialization_2.10;0.1.2!serialization_2.10.jar (108ms)
downloading https://repo1.maven.org/maven2/org/scala-lang/modules/scala-pickling_2.10/0.10.1/scala-pickling_2.10-0.10.1.jar ...
	[SUCCESSFUL ] org.scala-lang.modules#scala-pickling_2.10;0.10.1!scala-pickling_2.10.jar (254ms)
downloading https://repo1.maven.org/maven2/org/scalamacros/quasiquotes_2.10/2.0.1/quasiquotes_2.10-2.0.1.jar ...
	[SUCCESSFUL ] org.scalamacros#quasiquotes_2.10;2.0.1!quasiquotes_2.10.jar (218ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/cache/0.13.13/jars/cache.jar ...
	[SUCCESSFUL ] org.scala-sbt#cache;0.13.13!cache.jar (445ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/test-agent/0.13.13/jars/test-agent.jar ...
	[SUCCESSFUL ] org.scala-sbt#test-agent;0.13.13!test-agent.jar (384ms)
downloading https://repo.typesafe.com/typesafe/ivy-releases/org.scala-sbt/apply-macro/0.13.13/jars/apply-macro.jar ...
	[SUCCESSFUL ] org.scala-sbt#apply-macro;0.13.13!apply-macro.jar (390ms)
downloading https://repo1.maven.org/maven2/org/scala-sbt/template-resolver/0.1/template-resolver-0.1.jar ...
	[SUCCESSFUL ] org.scala-sbt#template-resolver;0.1!template-resolver.jar (10ms)
:: retrieving :: org.scala-sbt#boot-app
	confs: [default]
	50 artifacts copied, 0 already retrieved (17645kB/53ms)
Getting Scala 2.10.6 (for sbt)...
downloading https://repo1.maven.org/maven2/org/scala-lang/jline/2.10.6/jline-2.10.6.jar ...
	[SUCCESSFUL ] org.scala-lang#jline;2.10.6!jline.jar (57ms)
:: retrieving :: org.scala-sbt#boot-scala
	confs: [default]
	5 artifacts copied, 0 already retrieved (24494kB/30ms)
[0m[[0minfo[0m] [0mLoading project definition from /home/travis/build/dcshock/forklift/project[0m
[0m[[0minfo[0m] [0mUpdating {file:/home/travis/build/dcshock/forklift/project/}forklift-build...[0m
[0m[[0minfo[0m] [0mResolving com.typesafe.sbt#sbt-native-packager;1.0.0-M4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.typesafe.sbt#sbt-native-packager;1.0.0-M4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-compress;1.4.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-compress;1.4.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-parent;24 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-parent;24 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;9 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;9 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.tukaani#xz;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.tukaani#xz;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.vafer#jdeb;1.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.vafer#jdeb;1.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-io#commons-io;2.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-io#commons-io;2.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-parent;25 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-parent;25 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;9 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-compress;1.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-compress;1.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-parent;32 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-parent;32 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.tukaani#xz;1.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.tukaani#xz;1.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven-core;3.2.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven-core;3.2.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven;3.2.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven;3.2.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven-parent;24 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven-parent;24 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;14 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;14 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven-model;3.2.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven-model;3.2.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven;3.2.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.plexus#plexus-utils;3.0.17 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.plexus#plexus-utils;3.0.17 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.plexus#plexus;3.3.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.plexus#plexus;3.3.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.spice#spice-parent;17 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.spice#spice-parent;17 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.forge#forge-parent;10 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.forge#forge-parent;10 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven-settings;3.2.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven-settings;3.2.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven;3.2.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven-settings-builder;3.2.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven-settings-builder;3.2.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven;3.2.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.plexus#plexus-interpolation;1.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.plexus#plexus-interpolation;1.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.plexus#plexus-components;1.3.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.plexus#plexus-components;1.3.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.plexus#plexus;3.3.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.plexus#plexus-component-annotations;1.5.5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.plexus#plexus-component-annotations;1.5.5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.plexus#plexus-containers;1.5.5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.plexus#plexus-containers;1.5.5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.plexus#plexus;2.0.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.plexus#plexus;2.0.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.plexus#plexus-sec-dispatcher;1.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.plexus#plexus-sec-dispatcher;1.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.spice#spice-parent;12 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.spice#spice-parent;12 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.forge#forge-parent;4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.forge#forge-parent;4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.plexus#plexus-cipher;1.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.plexus#plexus-cipher;1.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.spice#spice-parent;12 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven-repository-metadata;3.2.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven-repository-metadata;3.2.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven;3.2.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven-artifact;3.2.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven-artifact;3.2.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven;3.2.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven-plugin-api;3.2.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven-plugin-api;3.2.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven;3.2.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.sisu#org.eclipse.sisu.plexus;0.0.0.M5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.sisu#org.eclipse.sisu.plexus;0.0.0.M5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.sisu#sisu-plexus;0.0.0.M5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.sisu#sisu-plexus;0.0.0.M5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.oss#oss-parent;7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving javax.enterprise#cdi-api;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving javax.enterprise#cdi-api;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.jboss.weld#weld-api-parent;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.jboss.weld#weld-api-parent;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.jboss.weld#weld-api-bom;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.jboss.weld#weld-api-bom;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.jboss.weld#weld-parent;6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.jboss.weld#weld-parent;6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving javax.annotation#jsr250-api;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving javax.annotation#jsr250-api;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving javax.inject#javax.inject;1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving javax.inject#javax.inject;1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.google.guava#guava;10.0.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.google.guava#guava;10.0.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.google.guava#guava-parent;10.0.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.google.guava#guava-parent;10.0.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.oss#oss-parent;7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.google.code.findbugs#jsr305;1.3.9 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.google.code.findbugs#jsr305;1.3.9 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.sisu#sisu-guice;3.1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.sisu#sisu-guice;3.1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.sisu.inject#guice-parent;3.1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.sisu.inject#guice-parent;3.1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.forge#forge-parent;10 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving aopalliance#aopalliance;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving aopalliance#aopalliance;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.sisu#org.eclipse.sisu.inject;0.0.0.M5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.sisu#org.eclipse.sisu.inject;0.0.0.M5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.sisu#sisu-inject;0.0.0.M5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.sisu#sisu-inject;0.0.0.M5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.oss#oss-parent;7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven-model-builder;3.2.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven-model-builder;3.2.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven;3.2.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven-aether-provider;3.2.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven-aether-provider;3.2.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.maven#maven;3.2.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.aether#aether-api;0.9.0.M2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.aether#aether-api;0.9.0.M2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.aether#aether;0.9.0.M2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.aether#aether;0.9.0.M2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.aether#aether-spi;0.9.0.M2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.aether#aether-spi;0.9.0.M2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.aether#aether;0.9.0.M2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.aether#aether-util;0.9.0.M2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.aether#aether-util;0.9.0.M2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.aether#aether;0.9.0.M2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.aether#aether-impl;0.9.0.M2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.aether#aether-impl;0.9.0.M2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.aether#aether;0.9.0.M2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.plexus#plexus-classworlds;2.5.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.plexus#plexus-classworlds;2.5.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.plexus#plexus;3.3.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.ant#ant;1.9.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.ant#ant;1.9.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.ant#ant-parent;1.9.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.ant#ant-parent;1.9.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.ant#ant-launcher;1.9.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.ant#ant-launcher;1.9.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.ant#ant-parent;1.9.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.bouncycastle#bcpg-jdk15on;1.51 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.bouncycastle#bcpg-jdk15on;1.51 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.bouncycastle#bcprov-jdk15on;1.51 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.bouncycastle#bcprov-jdk15on;1.51 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.eed3si9n#sbt-assembly;0.13.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.eed3si9n#sbt-assembly;0.13.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scalactic#scalactic_2.10;2.2.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scalactic#scalactic_2.10;2.2.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-library;2.10.6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-reflect;2.10.6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.jsuereth#sbt-pgp;1.0.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.jsuereth#sbt-pgp;1.0.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.jsuereth#pgp-library_2.10;1.0.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.jsuereth#pgp-library_2.10;1.0.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving net.databinder#dispatch-http_2.10;0.8.10 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving net.databinder#dispatch-http_2.10;0.8.10 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving net.databinder#dispatch-core_2.10;0.8.10 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving net.databinder#dispatch-core_2.10;0.8.10 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpclient;4.1.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpclient;4.1.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpcomponents-client;4.1.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpcomponents-client;4.1.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#project;5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#project;5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpcore;4.1.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpcore;4.1.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpcomponents-core;4.1.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpcomponents-core;4.1.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#project;5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-logging#commons-logging;1.1.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-logging#commons-logging;1.1.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-parent;5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-parent;5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-codec#commons-codec;1.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-codec#commons-codec;1.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-parent;11 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-parent;11 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving net.databinder#dispatch-futures_2.10;0.8.10 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving net.databinder#dispatch-futures_2.10;0.8.10 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-actors;2.10.6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-actors;2.10.6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.cavorite#sbt-avro-1-7;1.1.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.cavorite#sbt-avro-1-7;1.1.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro;1.7.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro;1.7.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro-parent;1.7.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro-parent;1.7.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro-toplevel;1.7.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro-toplevel;1.7.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;10 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;10 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.jackson#jackson-core-asl;1.9.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.jackson#jackson-core-asl;1.9.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.jackson#jackson-mapper-asl;1.9.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.jackson#jackson-mapper-asl;1.9.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.thoughtworks.paranamer#paranamer;2.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.thoughtworks.paranamer#paranamer;2.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.thoughtworks.paranamer#paranamer-parent;2.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.thoughtworks.paranamer#paranamer-parent;2.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus#codehaus-parent;1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus#codehaus-parent;1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.xerial.snappy#snappy-java;1.0.5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.xerial.snappy#snappy-java;1.0.5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.oss#oss-parent;7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-api;1.6.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-api;1.6.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-parent;1.6.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-parent;1.6.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro-compiler;1.7.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro-compiler;1.7.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro-parent;1.7.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-lang#commons-lang;2.6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-lang#commons-lang;2.6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-parent;17 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-parent;17 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.velocity#velocity;1.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.velocity#velocity;1.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-collections#commons-collections;3.2.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-collections#commons-collections;3.2.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-parent;9 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-parent;9 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#sbt;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#main;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#actions;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#classpath;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-compiler;2.10.6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#interface;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#io;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#control;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#launcher-interface;1.0.0-M1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#completion;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#collections;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving jline#jline;2.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.fusesource.jansi#jansi;1.11 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#api;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#classfile;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#logging;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#process;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#compiler-integration;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#incremental-compiler;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#relation;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#compile;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#persist;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-tools.sbinary#sbinary_2.10;0.4.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#compiler-ivy-integration;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#ivy;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#cross;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt.ivy#ivy;2.3.0-sbt-2cf13e211b2cb31f0d3b317289dca70eca3362f6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.jcraft#jsch;0.1.50 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#serialization_2.10;0.1.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang.modules#scala-pickling_2.10;0.10.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scalamacros#quasiquotes_2.10;2.0.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.json4s#json4s-core_2.10;3.2.10 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.json4s#json4s-ast_2.10;3.2.10 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.thoughtworks.paranamer#paranamer;2.6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.spire-math#jawn-parser_2.10;0.6.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.spire-math#json4s-support_2.10;0.6.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#run;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#task-system;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#tasks;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#tracking;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#cache;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#testing;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#test-agent;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#test-interface;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#main-settings;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#apply-macro;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#command;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#template-resolver;0.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#logic;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#compiler-interface;0.13.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#jline;2.10.6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.fusesource.jansi#jansi;1.4 ...[0m
[0m[[0minfo[0m] [0mdownloading https://repo.scala-sbt.org/scalasbt/sbt-plugin-releases/com.typesafe.sbt/sbt-native-packager/scala_2.10/sbt_0.13/1.0.0-M4/jars/sbt-native-packager.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.typesafe.sbt#sbt-native-packager;1.0.0-M4!sbt-native-packager.jar (685ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo.scala-sbt.org/scalasbt/sbt-plugin-releases/com.eed3si9n/sbt-assembly/scala_2.10/sbt_0.13/0.13.0/jars/sbt-assembly.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.eed3si9n#sbt-assembly;0.13.0!sbt-assembly.jar (469ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo.scala-sbt.org/scalasbt/sbt-plugin-releases/com.jsuereth/sbt-pgp/scala_2.10/sbt_0.13/1.0.0/jars/sbt-pgp.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.jsuereth#sbt-pgp;1.0.0!sbt-pgp.jar (484ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo.scala-sbt.org/scalasbt/sbt-plugin-releases/com.cavorite/sbt-avro-1-7/scala_2.10/sbt_0.13/1.1.2/jars/sbt-avro-1-7.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.cavorite#sbt-avro-1-7;1.1.2!sbt-avro-1-7.jar (391ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/vafer/jdeb/1.3/jdeb-1.3.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.vafer#jdeb;1.3!jdeb.jar (361ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/commons-io/commons-io/2.4/commons-io-2.4.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] commons-io#commons-io;2.4!commons-io.jar (61ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/commons/commons-compress/1.7/commons-compress-1.7.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.commons#commons-compress;1.7!commons-compress.jar (111ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/maven/maven-core/3.2.2/maven-core-3.2.2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.maven#maven-core;3.2.2!maven-core.jar (171ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/maven/maven-plugin-api/3.2.2/maven-plugin-api-3.2.2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.maven#maven-plugin-api;3.2.2!maven-plugin-api.jar (23ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/ant/ant/1.9.3/ant-1.9.3.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.ant#ant;1.9.3!ant.jar (569ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/bouncycastle/bcpg-jdk15on/1.51/bcpg-jdk15on-1.51.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.bouncycastle#bcpg-jdk15on;1.51!bcpg-jdk15on.jar (81ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/tukaani/xz/1.4/xz-1.4.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.tukaani#xz;1.4!xz.jar (37ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/maven/maven-model/3.2.2/maven-model-3.2.2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.maven#maven-model;3.2.2!maven-model.jar (58ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/maven/maven-settings/3.2.2/maven-settings-3.2.2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.maven#maven-settings;3.2.2!maven-settings.jar (26ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/maven/maven-settings-builder/3.2.2/maven-settings-builder-3.2.2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.maven#maven-settings-builder;3.2.2!maven-settings-builder.jar (27ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/maven/maven-repository-metadata/3.2.2/maven-repository-metadata-3.2.2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.maven#maven-repository-metadata;3.2.2!maven-repository-metadata.jar (17ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/maven/maven-artifact/3.2.2/maven-artifact-3.2.2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.maven#maven-artifact;3.2.2!maven-artifact.jar (23ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/maven/maven-model-builder/3.2.2/maven-model-builder-3.2.2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.maven#maven-model-builder;3.2.2!maven-model-builder.jar (77ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/maven/maven-aether-provider/3.2.2/maven-aether-provider-3.2.2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.maven#maven-aether-provider;3.2.2!maven-aether-provider.jar (31ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/eclipse/aether/aether-impl/0.9.0.M2/aether-impl-0.9.0.M2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.eclipse.aether#aether-impl;0.9.0.M2!aether-impl.jar (95ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/eclipse/aether/aether-api/0.9.0.M2/aether-api-0.9.0.M2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.eclipse.aether#aether-api;0.9.0.M2!aether-api.jar (48ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/eclipse/aether/aether-util/0.9.0.M2/aether-util-0.9.0.M2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.eclipse.aether#aether-util;0.9.0.M2!aether-util.jar (46ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/eclipse/sisu/org.eclipse.sisu.plexus/0.0.0.M5/org.eclipse.sisu.plexus-0.0.0.M5.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.eclipse.sisu#org.eclipse.sisu.plexus;0.0.0.M5!org.eclipse.sisu.plexus.jar(eclipse-plugin) (78ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/codehaus/plexus/plexus-interpolation/1.19/plexus-interpolation-1.19.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.codehaus.plexus#plexus-interpolation;1.19!plexus-interpolation.jar (32ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/codehaus/plexus/plexus-utils/3.0.17/plexus-utils-3.0.17.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.codehaus.plexus#plexus-utils;3.0.17!plexus-utils.jar (81ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/codehaus/plexus/plexus-classworlds/2.5.1/plexus-classworlds-2.5.1.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.codehaus.plexus#plexus-classworlds;2.5.1!plexus-classworlds.jar(bundle) (38ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/codehaus/plexus/plexus-component-annotations/1.5.5/plexus-component-annotations-1.5.5.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.codehaus.plexus#plexus-component-annotations;1.5.5!plexus-component-annotations.jar (11ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/sonatype/plexus/plexus-sec-dispatcher/1.3/plexus-sec-dispatcher-1.3.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.sonatype.plexus#plexus-sec-dispatcher;1.3!plexus-sec-dispatcher.jar (18ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/sonatype/plexus/plexus-cipher/1.4/plexus-cipher-1.4.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.sonatype.plexus#plexus-cipher;1.4!plexus-cipher.jar (16ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/javax/enterprise/cdi-api/1.0/cdi-api-1.0.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] javax.enterprise#cdi-api;1.0!cdi-api.jar (21ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/google/guava/guava/10.0.1/guava-10.0.1.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.google.guava#guava;10.0.1!guava.jar (449ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/sonatype/sisu/sisu-guice/3.1.0/sisu-guice-3.1.0-no_aop.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.sonatype.sisu#sisu-guice;3.1.0!sisu-guice.jar (118ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/eclipse/sisu/org.eclipse.sisu.inject/0.0.0.M5/org.eclipse.sisu.inject-0.0.0.M5.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.eclipse.sisu#org.eclipse.sisu.inject;0.0.0.M5!org.eclipse.sisu.inject.jar(eclipse-plugin) (108ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/javax/annotation/jsr250-api/1.0/jsr250-api-1.0.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] javax.annotation#jsr250-api;1.0!jsr250-api.jar (10ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/javax/inject/javax.inject/1/javax.inject-1.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] javax.inject#javax.inject;1!javax.inject.jar (8ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.google.code.findbugs#jsr305;1.3.9!jsr305.jar (41ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/aopalliance/aopalliance/1.0/aopalliance-1.0.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] aopalliance#aopalliance;1.0!aopalliance.jar (10ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/eclipse/aether/aether-spi/0.9.0.M2/aether-spi-0.9.0.M2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.eclipse.aether#aether-spi;0.9.0.M2!aether-spi.jar (13ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/ant/ant-launcher/1.9.3/ant-launcher-1.9.3.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.ant#ant-launcher;1.9.3!ant-launcher.jar (15ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/bouncycastle/bcprov-jdk15on/1.51/bcprov-jdk15on-1.51.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.bouncycastle#bcprov-jdk15on;1.51!bcprov-jdk15on.jar (804ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/scalactic/scalactic_2.10/2.2.1/scalactic_2.10-2.2.1.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.scalactic#scalactic_2.10;2.2.1!scalactic_2.10.jar(bundle) (125ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo.scala-sbt.org/scalasbt/sbt-plugin-releases/com.jsuereth/pgp-library_2.10/1.0.0/jars/pgp-library_2.10.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.jsuereth#pgp-library_2.10;1.0.0!pgp-library_2.10.jar (633ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/net/databinder/dispatch-http_2.10/0.8.10/dispatch-http_2.10-0.8.10.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] net.databinder#dispatch-http_2.10;0.8.10!dispatch-http_2.10.jar (18ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/net/databinder/dispatch-core_2.10/0.8.10/dispatch-core_2.10-0.8.10.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] net.databinder#dispatch-core_2.10;0.8.10!dispatch-core_2.10.jar (46ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/net/databinder/dispatch-futures_2.10/0.8.10/dispatch-futures_2.10-0.8.10.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] net.databinder#dispatch-futures_2.10;0.8.10!dispatch-futures_2.10.jar (18ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/httpcomponents/httpclient/4.1.3/httpclient-4.1.3.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.httpcomponents#httpclient;4.1.3!httpclient.jar (108ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/httpcomponents/httpcore/4.1.4/httpcore-4.1.4.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.httpcomponents#httpcore;4.1.4!httpcore.jar (60ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] commons-logging#commons-logging;1.1.1!commons-logging.jar (28ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/commons-codec/commons-codec/1.4/commons-codec-1.4.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] commons-codec#commons-codec;1.4!commons-codec.jar (25ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/scala-lang/scala-actors/2.10.6/scala-actors-2.10.6.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.scala-lang#scala-actors;2.10.6!scala-actors.jar (145ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/avro/avro/1.7.7/avro-1.7.7.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.avro#avro;1.7.7!avro.jar(bundle) (132ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/avro/avro-compiler/1.7.7/avro-compiler-1.7.7.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.avro#avro-compiler;1.7.7!avro-compiler.jar(bundle) (32ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.codehaus.jackson#jackson-core-asl;1.9.13!jackson-core-asl.jar (73ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.codehaus.jackson#jackson-mapper-asl;1.9.13!jackson-mapper-asl.jar (224ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.thoughtworks.paranamer#paranamer;2.3!paranamer.jar (15ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.0.5!snappy-java.jar(bundle) (371ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.6.4/slf4j-api-1.6.4.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.slf4j#slf4j-api;1.6.4!slf4j-api.jar (19ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/commons-lang/commons-lang/2.6/commons-lang-2.6.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] commons-lang#commons-lang;2.6!commons-lang.jar (113ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/velocity/velocity/1.7/velocity-1.7.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.velocity#velocity;1.7!velocity.jar (168ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] commons-collections#commons-collections;3.2.1!commons-collections.jar (171ms)[0m
[0m[[0minfo[0m] [0mDone updating.[0m
[0m[[0minfo[0m] [0mCompiling 1 Scala source to /home/travis/build/dcshock/forklift/project/target/scala-2.10/sbt-0.13/classes...[0m
[0m[[0minfo[0m] [0m'compiler-interface' not yet compiled for Scala 2.10.6. Compiling...[0m
[0m[[0minfo[0m] [0m  Compilation completed in 10.18 s[0m
[0m[[33mwarn[0m] [0m/home/travis/build/dcshock/forklift/project/Build.scala:4: trait Build in package sbt is deprecated: Use .sbt format instead[0m
[0m[[33mwarn[0m] [0mobject ForkliftBuild extends Build {[0m
[0m[[33mwarn[0m] [0m                             ^[0m
[0m[[33mwarn[0m] [0mone warning found[0m
[0m[[0minfo[0m] [0mSet current project to forklift (in build file:/home/travis/build/dcshock/forklift/)[0m
[0m[[0minfo[0m] [0mSetting version to 2.11.4[0m
[0m[[0minfo[0m] [0mReapplying settings...[0m
[0m[[0minfo[0m] [0mSet current project to forklift (in build file:/home/travis/build/dcshock/forklift/)[0m
[0m[[0minfo[0m] [0mUpdating {file:/home/travis/build/dcshock/forklift/}core...[0m
[0m[[0minfo[0m] [0mUpdating {file:/home/travis/build/dcshock/forklift/}forklift...[0m
[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-library;2.11.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-library;2.11.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro-compiler;1.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro-compiler;1.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro-parent;1.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro-parent;1.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro-toplevel;1.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro-toplevel;1.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;10 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro;1.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro;1.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro-parent;1.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.jackson#jackson-core-asl;1.8.8 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.jackson#jackson-core-asl;1.8.8 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.jackson#jackson-mapper-asl;1.8.8 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.jackson#jackson-mapper-asl;1.8.8 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.thoughtworks.paranamer#paranamer;2.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.xerial.snappy#snappy-java;1.0.4.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.xerial.snappy#snappy-java;1.0.4.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-api;1.6.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-lang#commons-lang;2.6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.velocity#velocity;1.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-collections#commons-collections;3.2.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-compiler;2.11.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-compiler;2.11.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-reflect;2.11.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-reflect;2.11.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang.modules#scala-xml_2.11;1.0.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang.modules#scala-xml_2.11;1.0.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang.modules#scala-parser-combinators_2.11;1.0.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang.modules#scala-parser-combinators_2.11;1.0.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving jline#jline;2.12 ...[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/scala-lang/scala-library/2.11.4/scala-library-2.11.4.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.scala-lang#scala-library;2.11.4!scala-library.jar (1600ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/avro/avro-compiler/1.7.3/avro-compiler-1.7.3.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.avro#avro-compiler;1.7.3!avro-compiler.jar (31ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/avro/avro/1.7.3/avro-1.7.3.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.avro#avro;1.7.3!avro.jar (94ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.codehaus.jackson#jackson-core-asl;1.8.8!jackson-core-asl.jar (73ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.codehaus.jackson#jackson-mapper-asl;1.8.8!jackson-mapper-asl.jar (199ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.0.4.1/snappy-java-1.0.4.1.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.0.4.1!snappy-java.jar(bundle) (294ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/scala-lang/scala-compiler/2.11.4/scala-compiler-2.11.4.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.scala-lang#scala-compiler;2.11.4!scala-compiler.jar (3837ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/scala-lang/scala-reflect/2.11.4/scala-reflect-2.11.4.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.scala-lang#scala-reflect;2.11.4!scala-reflect.jar (2019ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/scala-lang/modules/scala-xml_2.11/1.0.2/scala-xml_2.11-1.0.2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.scala-lang.modules#scala-xml_2.11;1.0.2!scala-xml_2.11.jar(bundle) (351ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.2/scala-parser-combinators_2.11-1.0.2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.scala-lang.modules#scala-parser-combinators_2.11;1.0.2!scala-parser-combinators_2.11.jar(bundle) (187ms)[0m
[0m[[0minfo[0m] [0mDone updating.[0m
[0m[[0minfo[0m] [0mResolving org.apache.avro#avro-compiler;1.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro;1.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.jackson#jackson-core-asl;1.8.8 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.jackson#jackson-mapper-asl;1.8.8 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.thoughtworks.paranamer#paranamer;2.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.xerial.snappy#snappy-java;1.0.4.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-api;1.6.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-lang#commons-lang;2.6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.velocity#velocity;1.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-collections#commons-collections;3.2.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.google.guava#guava;18.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.google.guava#guava;18.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.google.guava#guava-parent;18.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.google.guava#guava-parent;18.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.oss#oss-parent;7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.core#jackson-databind;2.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.core#jackson-databind;2.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson#jackson-parent;2.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson#jackson-parent;2.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml#oss-parent;25 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml#oss-parent;25 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.core#jackson-annotations;2.7.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.core#jackson-annotations;2.7.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson#jackson-parent;2.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.core#jackson-core;2.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.core#jackson-core;2.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson#jackson-parent;2.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.datatype#jackson-datatype-jsr310;2.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.datatype#jackson-datatype-jsr310;2.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson#jackson-parent;2.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback#logback-classic;1.0.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback#logback-classic;1.0.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback#logback-parent;1.0.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback#logback-parent;1.0.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback#logback-core;1.0.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback#logback-core;1.0.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback#logback-parent;1.0.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-api;1.7.5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-api;1.7.5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-parent;1.7.5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-parent;1.7.5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.reflections#reflections;0.9.10 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.reflections#reflections;0.9.10 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.javassist#javassist;3.18.2-GA ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.javassist#javassist;3.18.2-GA ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.google.code.findbugs#annotations;2.0.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.google.code.findbugs#annotations;2.0.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving javax.inject#javax.inject;1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.novocode#junit-interface;0.11 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.novocode#junit-interface;0.11 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving junit#junit;4.11 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving junit#junit;4.11 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.hamcrest#hamcrest-core;1.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.hamcrest#hamcrest-core;1.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.hamcrest#hamcrest-parent;1.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.hamcrest#hamcrest-parent;1.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#test-interface;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.mockito#mockito-all;1.9.5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.mockito#mockito-all;1.9.5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-compiler;2.11.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-library;2.11.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-reflect;2.11.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang.modules#scala-xml_2.11;1.0.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang.modules#scala-parser-combinators_2.11;1.0.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving jline#jline;2.12 ...[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/google/guava/guava/18.0/guava-18.0.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.google.guava#guava;18.0!guava.jar(bundle) (1058ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-databind/2.7.3/jackson-databind-2.7.3.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.fasterxml.jackson.core#jackson-databind;2.7.3!jackson-databind.jar(bundle) (547ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/fasterxml/jackson/datatype/jackson-datatype-jsr310/2.7.3/jackson-datatype-jsr310-2.7.3.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.fasterxml.jackson.datatype#jackson-datatype-jsr310;2.7.3!jackson-datatype-jsr310.jar(bundle) (90ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/ch/qos/logback/logback-classic/1.0.13/logback-classic-1.0.13.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] ch.qos.logback#logback-classic;1.0.13!logback-classic.jar (142ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/reflections/reflections/0.9.10/reflections-0.9.10.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.reflections#reflections;0.9.10!reflections.jar (75ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-annotations/2.7.0/jackson-annotations-2.7.0.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.fasterxml.jackson.core#jackson-annotations;2.7.0!jackson-annotations.jar(bundle) (41ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-core/2.7.3/jackson-core-2.7.3.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.fasterxml.jackson.core#jackson-core;2.7.3!jackson-core.jar(bundle) (241ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/ch/qos/logback/logback-core/1.0.13/logback-core-1.0.13.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] ch.qos.logback#logback-core;1.0.13!logback-core.jar (237ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.5/slf4j-api-1.7.5.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.slf4j#slf4j-api;1.7.5!slf4j-api.jar (27ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/javassist/javassist/3.18.2-GA/javassist-3.18.2-GA.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.javassist#javassist;3.18.2-GA!javassist.jar(bundle) (449ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/google/code/findbugs/annotations/2.0.1/annotations-2.0.1.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.google.code.findbugs#annotations;2.0.1!annotations.jar (58ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/novocode/junit-interface/0.11/junit-interface-0.11.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.novocode#junit-interface;0.11!junit-interface.jar (47ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/mockito/mockito-all/1.9.5/mockito-all-1.9.5.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.mockito#mockito-all;1.9.5!mockito-all.jar (895ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/junit/junit/4.11/junit-4.11.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] junit#junit;4.11!junit.jar (119ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.hamcrest#hamcrest-core;1.3!hamcrest-core.jar (33ms)[0m
[0m[[0minfo[0m] [0mDone updating.[0m
[0m[[0minfo[0m] [0mUpdating {file:/home/travis/build/dcshock/forklift/}activemq...[0m
[0m[[0minfo[0m] [0mUpdating {file:/home/travis/build/dcshock/forklift/}replay...[0m
[0m[[0minfo[0m] [0mResolving com.github.dcshock#forklift;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro-compiler;1.7.3 ...[0m
[0m[[0minfo[0m] [0mUpdating {file:/home/travis/build/dcshock/forklift/}retry...[0m
[0m[[0minfo[0m] [0mUpdating {file:/home/travis/build/dcshock/forklift/}stats...[0m
[0m[[0minfo[0m] [0mUpdating {file:/home/travis/build/dcshock/forklift/}kafka...[0m
[0m[[0minfo[0m] [0mCompiling 62 Java sources to /home/travis/build/dcshock/forklift/core/target/classes...[0m
[0m[[0minfo[0m] [0mResolving org.apache.avro#avro;1.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.jackson#jackson-core-asl;1.8.8 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.jackson#jackson-mapper-asl;1.8.8 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.thoughtworks.paranamer#paranamer;2.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.xerial.snappy#snappy-java;1.0.4.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-api;1.6.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-lang#commons-lang;2.6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.velocity#velocity;1.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-collections#commons-collections;3.2.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.google.guava#guava;18.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.core#jackson-databind;2.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.core#jackson-annotations;2.7.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.core#jackson-core;2.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.datatype#jackson-datatype-jsr310;2.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback#logback-classic;1.0.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback#logback-core;1.0.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-api;1.7.5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.reflections#reflections;0.9.10 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.javassist#javassist;3.18.2-GA ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.google.code.findbugs#annotations;2.0.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving javax.inject#javax.inject;1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.activemq#activemq-client;5.14.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.activemq#activemq-client;5.14.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.activemq#activemq-parent;5.14.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.activemq#activemq-parent;5.14.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;17 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;17 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-api;1.7.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-api;1.7.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-parent;1.7.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-parent;1.7.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.geronimo.specs#geronimo-jms_1.1_spec;1.1.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.geronimo.specs#geronimo-jms_1.1_spec;1.1.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.geronimo.specs#specs;1.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.geronimo.specs#specs;1.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.geronimo.genesis.config#project-config;1.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.geronimo.genesis.config#project-config;1.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.geronimo.genesis.config#config;1.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.geronimo.genesis.config#config;1.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.geronimo.genesis#genesis;1.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.geronimo.genesis#genesis;1.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.fusesource.hawtbuf#hawtbuf;1.11 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.fusesource.hawtbuf#hawtbuf;1.11 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.fusesource.hawtbuf#hawtbuf-project;1.11 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.fusesource.hawtbuf#hawtbuf-project;1.11 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.fusesource#fusesource-pom;1.10 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.fusesource#fusesource-pom;1.10 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.geronimo.specs#geronimo-j2ee-management_1.1_spec;1.0.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.geronimo.specs#geronimo-j2ee-management_1.1_spec;1.0.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.geronimo.specs#specs;1.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.activemq#activemq-broker;5.14.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.activemq#activemq-broker;5.14.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.activemq#activemq-parent;5.14.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.activemq#activemq-openwire-legacy;5.14.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.activemq#activemq-openwire-legacy;5.14.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.activemq#activemq-parent;5.14.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-io#commons-io;2.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.novocode#junit-interface;0.11 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving junit#junit;4.11 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.hamcrest#hamcrest-core;1.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#test-interface;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.activemq#activemq-all;5.14.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.activemq#activemq-all;5.14.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.activemq#activemq-parent;5.14.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-compiler;2.11.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-library;2.11.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-reflect;2.11.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang.modules#scala-xml_2.11;1.0.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang.modules#scala-parser-combinators_2.11;1.0.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving jline#jline;2.12 ...[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/activemq/activemq-client/5.14.0/activemq-client-5.14.0.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.activemq#activemq-client;5.14.0!activemq-client.jar(bundle) (916ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/activemq/activemq-broker/5.14.0/activemq-broker-5.14.0.jar ...[0m
[0m[[0minfo[0m] [0m/home/travis/build/dcshock/forklift/core/src/main/java/forklift/consumer/MessageRunnable.java: Some input files use unchecked or unsafe operations.[0m
[0m[[0minfo[0m] [0m/home/travis/build/dcshock/forklift/core/src/main/java/forklift/consumer/MessageRunnable.java: Recompile with -Xlint:unchecked for details.[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.activemq#activemq-broker;5.14.0!activemq-broker.jar (509ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/geronimo/specs/geronimo-jms_1.1_spec/1.1.1/geronimo-jms_1.1_spec-1.1.1.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.geronimo.specs#geronimo-jms_1.1_spec;1.1.1!geronimo-jms_1.1_spec.jar (104ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.13/slf4j-api-1.7.13.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.slf4j#slf4j-api;1.7.13!slf4j-api.jar (37ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/fusesource/hawtbuf/hawtbuf/1.11/hawtbuf-1.11.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.fusesource.hawtbuf#hawtbuf;1.11!hawtbuf.jar(bundle) (63ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/geronimo/specs/geronimo-j2ee-management_1.1_spec/1.0.1/geronimo-j2ee-management_1.1_spec-1.0.1.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.geronimo.specs#geronimo-j2ee-management_1.1_spec;1.0.1!geronimo-j2ee-management_1.1_spec.jar (127ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/activemq/activemq-openwire-legacy/5.14.0/activemq-openwire-legacy-5.14.0.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.activemq#activemq-openwire-legacy;5.14.0!activemq-openwire-legacy.jar (446ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/activemq/activemq-all/5.14.0/activemq-all-5.14.0.jar ...[0m
[0m[[0minfo[0m] [0mCompiling 25 Java sources to /home/travis/build/dcshock/forklift/core/target/test-classes...[0m
[0m[[33mwarn[0m] [0m/home/travis/build/dcshock/forklift/core/src/test/java/forklift/deployment/ClassDeploymentTest.java:21: non-varargs call of varargs method with inexact argument type for last parameter;[0m
[0m[[33mwarn[0m] [0m  cast to java.lang.Class<?> for a varargs call[0m
[0m[[33mwarn[0m] [0m  cast to java.lang.Class<?>[] for a non-varargs call and to suppress this warning[0m
[0m[[33mwarn[0m] [0m        new ClassDeployment(null);[0m
SLF4J: The following loggers will not work because they were created
SLF4J: during the default configuration phase of the underlying logging system.
SLF4J: See also http://www.slf4j.org/codes.html#substituteLogger
SLF4J: ForkLift
SLF4J: forklift.consumer.MessageRunnableTest
SLF4J: forklift.consumer.parser.KeyValueParser
SLF4J: forklift.consumer.LifeCycleMonitorsTest
SLF4J: forklift.properties.PropertiesManager
17:34:10.768 [pool-5-thread-5] DEBUG org.reflections.Reflections - going to scan these urls:
file:/tmp/1496424849868-0/test7848698823553865636.jar
17:34:10.764 [pool-5-thread-26] DEBUG org.reflections.Reflections - going to scan these urls:
file:/home/travis/build/dcshock/forklift/core/target/test-classes/forklift-test-consumer-0.1.jar
17:34:10.763 [pool-5-thread-25] DEBUG org.reflections.Reflections - going to scan these urls:
file:/home/travis/build/dcshock/forklift/core/target/test-classes/forklift-multitq-consumer-0.1.jar
17:34:10.764 [pool-5-thread-28] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.lifecycle.BadAuditor-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Validating)
17:34:10.877 [pool-5-thread-26] DEBUG org.reflections.Reflections - could not scan file META-INF/MANIFEST.MF in url file:/home/travis/build/dcshock/forklift/core/target/test-classes/forklift-test-consumer-0.1.jar with scanner SubTypesScanner
17:34:10.878 [pool-5-thread-26] DEBUG org.reflections.Reflections - could not scan file META-INF/MANIFEST.MF in url file:/home/travis/build/dcshock/forklift/core/target/test-classes/forklift-test-consumer-0.1.jar with scanner TypeAnnotationsScanner
17:34:10.888 [pool-5-thread-25] DEBUG org.reflections.Reflections - could not scan file META-INF/MANIFEST.MF in url file:/home/travis/build/dcshock/forklift/core/target/test-classes/forklift-multitq-consumer-0.1.jar with scanner SubTypesScanner
17:34:10.889 [pool-5-thread-25] DEBUG org.reflections.Reflections - could not scan file META-INF/MANIFEST.MF in url file:/home/travis/build/dcshock/forklift/core/target/test-classes/forklift-multitq-consumer-0.1.jar with scanner TypeAnnotationsScanner
17:34:10.889 [pool-5-thread-5] DEBUG org.reflections.Reflections - could not scan file META-INF/MANIFEST.MF in url file:/tmp/1496424849868-0/test7848698823553865636.jar with scanner SubTypesScanner
17:34:10.890 [pool-5-thread-5] DEBUG org.reflections.Reflections - could not scan file META-INF/MANIFEST.MF in url file:/tmp/1496424849868-0/test7848698823553865636.jar with scanner TypeAnnotationsScanner
17:34:10.935 [pool-5-thread-25] INFO  org.reflections.Reflections - Reflections took 154 ms to scan 1 urls, producing 2 keys and 4 values 
17:34:10.941 [pool-5-thread-5] INFO  org.reflections.Reflections - Reflections took 168 ms to scan 1 urls, producing 1 keys and 1 values 
17:34:10.939 [pool-5-thread-26] INFO  org.reflections.Reflections - Reflections took 159 ms to scan 1 urls, producing 1 keys and 1 values 
17:34:11.419 [pool-5-thread-25] DEBUG org.reflections.Reflections - going to scan these urls:
file:/tmp/._forklift-jarjar-consumer-0.1.619412659207066393.jar
file:/tmp/._forklift-multitq-consumer.4450934068364141052.jar
file:/home/travis/build/dcshock/forklift/core/target/test-classes/forklift-jarjar-consumer-0.1-binks.jar
file:/tmp/._forklift-test-consumer.3965609013111181660.jar
17:34:11.419 [pool-5-thread-25] DEBUG org.reflections.Reflections - could not scan file META-INF/MANIFEST.MF in url file:/tmp/._forklift-jarjar-consumer-0.1.619412659207066393.jar with scanner SubTypesScanner
17:34:11.419 [pool-5-thread-25] DEBUG org.reflections.Reflections - could not scan file META-INF/MANIFEST.MF in url file:/tmp/._forklift-jarjar-consumer-0.1.619412659207066393.jar with scanner TypeAnnotationsScanner
17:34:11.420 [pool-5-thread-25] DEBUG org.reflections.Reflections - could not scan file META-INF/MANIFEST.MF in url file:/tmp/._forklift-multitq-consumer.4450934068364141052.jar with scanner SubTypesScanner
17:34:11.420 [pool-5-thread-25] DEBUG org.reflections.Reflections - could not scan file META-INF/MANIFEST.MF in url file:/tmp/._forklift-multitq-consumer.4450934068364141052.jar with scanner TypeAnnotationsScanner
17:34:11.421 [pool-5-thread-25] DEBUG org.reflections.Reflections - could not scan file META-INF/MANIFEST.MF in url file:/home/travis/build/dcshock/forklift/core/target/test-classes/forklift-jarjar-consumer-0.1-binks.jar with scanner SubTypesScanner
17:34:11.421 [pool-5-thread-25] DEBUG org.reflections.Reflections - could not scan file META-INF/MANIFEST.MF in url file:/home/travis/build/dcshock/forklift/core/target/test-classes/forklift-jarjar-consumer-0.1-binks.jar with scanner TypeAnnotationsScanner
17:34:11.421 [pool-5-thread-25] DEBUG org.reflections.Reflections - could not scan file ./forklift-jarjar-consumer-0.1.jar in url file:/home/travis/build/dcshock/forklift/core/target/test-classes/forklift-jarjar-consumer-0.1-binks.jar with scanner SubTypesScanner
17:34:11.421 [pool-5-thread-25] DEBUG org.reflections.Reflections - could not scan file ./forklift-jarjar-consumer-0.1.jar in url file:/home/travis/build/dcshock/forklift/core/target/test-classes/forklift-jarjar-consumer-0.1-binks.jar with scanner TypeAnnotationsScanner
17:34:11.422 [pool-5-thread-25] DEBUG org.reflections.Reflections - could not scan file ./forklift-multitq-consumer.jar in url file:/home/travis/build/dcshock/forklift/core/target/test-classes/forklift-jarjar-consumer-0.1-binks.jar with scanner SubTypesScanner
17:34:11.422 [pool-5-thread-25] DEBUG org.reflections.Reflections - could not scan file ./forklift-multitq-consumer.jar in url file:/home/travis/build/dcshock/forklift/core/target/test-classes/forklift-jarjar-consumer-0.1-binks.jar with scanner TypeAnnotationsScanner
17:34:11.422 [pool-5-thread-25] DEBUG org.reflections.Reflections - could not scan file ./forklift-test-consumer.jar in url file:/home/travis/build/dcshock/forklift/core/target/test-classes/forklift-jarjar-consumer-0.1-binks.jar with scanner SubTypesScanner
17:34:11.422 [pool-5-thread-25] DEBUG org.reflections.Reflections - could not scan file ./forklift-test-consumer.jar in url file:/home/travis/build/dcshock/forklift/core/target/test-classes/forklift-jarjar-consumer-0.1-binks.jar with scanner TypeAnnotationsScanner
17:34:11.422 [pool-5-thread-25] DEBUG org.reflections.Reflections - could not scan file META-INF/MANIFEST.MF in url file:/tmp/._forklift-test-consumer.3965609013111181660.jar with scanner SubTypesScanner
17:34:11.423 [pool-5-thread-25] DEBUG org.reflections.Reflections - could not scan file META-INF/MANIFEST.MF in url file:/tmp/._forklift-test-consumer.3965609013111181660.jar with scanner TypeAnnotationsScanner
17:34:11.423 [pool-5-thread-25] INFO  org.reflections.Reflections - Reflections took 4 ms to scan 4 urls, producing 2 keys and 6 values 
17:34:11.439 [pool-5-thread-15] DEBUG org.reflections.Reflections - going to scan these urls:
file:/tmp/1496424851438-0/test5701891558175701643.jar
17:34:11.439 [pool-5-thread-15] DEBUG org.reflections.Reflections - could not scan file META-INF/MANIFEST.MF in url file:/tmp/1496424851438-0/test5701891558175701643.jar with scanner SubTypesScanner
17:34:11.439 [pool-5-thread-15] DEBUG org.reflections.Reflections - could not scan file META-INF/MANIFEST.MF in url file:/tmp/1496424851438-0/test5701891558175701643.jar with scanner TypeAnnotationsScanner
17:34:11.440 [pool-5-thread-15] INFO  org.reflections.Reflections - Reflections took 0 ms to scan 1 urls, producing 1 keys and 1 values 
17:34:11.531 [pool-5-thread-25] DEBUG org.reflections.Reflections - going to scan these urls:
file:/tmp/test4991053796222623380.jar
17:34:11.531 [pool-5-thread-25] DEBUG org.reflections.Reflections - could not scan file META-INF/MANIFEST.MF in url file:/tmp/test4991053796222623380.jar with scanner SubTypesScanner
17:34:11.531 [pool-5-thread-25] DEBUG org.reflections.Reflections - could not scan file META-INF/MANIFEST.MF in url file:/tmp/test4991053796222623380.jar with scanner TypeAnnotationsScanner
17:34:11.531 [pool-5-thread-25] INFO  org.reflections.Reflections - Reflections took 0 ms to scan 1 urls, producing 0 keys and 0 values 
17:34:12.440 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.MessageRunnableTest$TestListener5-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Processing)
17:34:12.520 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.MessageRunnableTest$TestListener5-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Invalid)
17:34:12.521 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.MessageRunnableTest$TestListener5-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Validating)
17:34:12.539 [pool-5-thread-17] ERROR forklift.consumer.MessageRunnable - boogers
17:34:12.540 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.MessageRunnableTest$TestListener5-public static void forklift.consumer.MessageRunnableTest$TestListener5.validate(forklift.consumer.MessageRunnable)
17:34:12.547 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.MessageRunnableTest$TestListener5-public static void forklift.consumer.MessageRunnableTest$TestListener5.invalid(forklift.consumer.MessageRunnable)
17:34:12.547 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.MessageRunnableTest$TestListener5-public static void forklift.consumer.MessageRunnableTest$TestListener5.process(forklift.consumer.MessageRunnable)
17:34:12.593 [pool-5-thread-28] ERROR forklift.consumer.LifeCycleMonitors - Error invoking LifeCycle Monitor
java.lang.reflect.InvocationTargetException: null
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_31]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_31]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_31]
	at java.lang.reflect.Method.invoke(Method.java:483) ~[na:1.8.0_31]
	at forklift.consumer.LifeCycleMonitors.lambda$null$3(LifeCycleMonitors.java:148) [classes/:na]
	at forklift.consumer.LifeCycleMonitors$$Lambda$57/306332954.accept(Unknown Source) [classes/:na]
	at java.util.ArrayList.forEach(ArrayList.java:1249) [na:1.8.0_31]
	at forklift.consumer.LifeCycleMonitors.lambda$call$4(LifeCycleMonitors.java:141) [classes/:na]
	at forklift.consumer.LifeCycleMonitors$$Lambda$55/607802932.accept(Unknown Source) [classes/:na]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) [na:1.8.0_31]
	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) [na:1.8.0_31]
	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) [na:1.8.0_31]
	at java.util.HashMap$KeySpliterator.forEachRemaining(HashMap.java:1540) [na:1.8.0_31]
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512) [na:1.8.0_31]
	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502) [na:1.8.0_31]
	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) [na:1.8.0_31]
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) [na:1.8.0_31]
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) [na:1.8.0_31]
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418) [na:1.8.0_31]
	at forklift.consumer.LifeCycleMonitors.call(LifeCycleMonitors.java:140) [classes/:na]
	at forklift.consumer.LifeCycleMonitorsTest.badListener(LifeCycleMonitorsTest.java:121) [test-classes/:na]
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[na:1.8.0_31]
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[na:1.8.0_31]
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[na:1.8.0_31]
	at java.lang.reflect.Method.invoke(Method.java:483) ~[na:1.8.0_31]
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47) [junit-4.11.jar:na]
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) [junit-4.11.jar:na]
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44) [junit-4.11.jar:na]
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17) [junit-4.11.jar:na]
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271) [junit-4.11.jar:na]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70) [junit-4.11.jar:na]
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50) [junit-4.11.jar:na]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238) [junit-4.11.jar:na]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63) [junit-4.11.jar:na]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236) [junit-4.11.jar:na]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53) [junit-4.11.jar:na]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229) [junit-4.11.jar:na]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309) [junit-4.11.jar:na]
	at org.junit.runners.Suite.runChild(Suite.java:127) [junit-4.11.jar:na]
	at org.junit.runners.Suite.runChild(Suite.java:26) [junit-4.11.jar:na]
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238) [junit-4.11.jar:na]
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63) [junit-4.11.jar:na]
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236) [junit-4.11.jar:na]
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53) [junit-4.11.jar:na]
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229) [junit-4.11.jar:na]
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309) [junit-4.11.jar:na]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160) [junit-4.11.jar:na]
	at org.junit.runner.JUnitCore.run(JUnitCore.java:138) [junit-4.11.jar:na]
	at com.novocode.junit.JUnitRunner$1.execute(JUnitRunner.java:132) [junit-interface-0.11.jar:0.11]
	at sbt.TestRunner.runTest$1(TestFramework.scala:76) [testing-0.13.13.jar:0.13.13]
	at sbt.TestRunner.run(TestFramework.scala:85) [testing-0.13.13.jar:0.13.13]
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202) [testing-0.13.13.jar:0.13.13]
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202) [testing-0.13.13.jar:0.13.13]
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185) [testing-0.13.13.jar:0.13.13]
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202) [testing-0.13.13.jar:0.13.13]
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202) [testing-0.13.13.jar:0.13.13]
	at sbt.TestFunction.apply(TestFramework.scala:207) [testing-0.13.13.jar:0.13.13]
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216) [actions-0.13.13.jar:0.13.13]
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216) [actions-0.13.13.jar:0.13.13]
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44) [task-system-0.13.13.jar:0.13.13]
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44) [task-system-0.13.13.jar:0.13.13]
	at sbt.std.Transform$$anon$4.work(System.scala:63) [task-system-0.13.13.jar:0.13.13]
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228) [tasks-0.13.13.jar:0.13.13]
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228) [tasks-0.13.13.jar:0.13.13]
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17) [control-0.13.13.jar:0.13.13]
	at sbt.Execute.work(Execute.scala:237) [tasks-0.13.13.jar:0.13.13]
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228) [tasks-0.13.13.jar:0.13.13]
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228) [tasks-0.13.13.jar:0.13.13]
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159) [tasks-0.13.13.jar:0.13.13]
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28) [tasks-0.13.13.jar:0.13.13]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_31]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_31]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_31]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_31]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_31]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_31]
Caused by: java.lang.RuntimeException: purposely blow up on validate
	at forklift.consumer.lifecycle.BadAuditor.validate(BadAuditor.java:15) ~[test-classes/:na]
	... 76 common frames omitted
17:34:12.602 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.MessageRunnableTest$TestListener1-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Processing)
17:34:12.602 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.MessageRunnableTest$TestListener1-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Invalid)
17:34:12.603 [pool-5-thread-17] ERROR forklift.consumer.MessageRunnable - onValidate method validateMsg has wrong return type void
17:34:12.604 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.MessageRunnableTest$TestListener1-public static void forklift.consumer.MessageRunnableTest$TestListener1.invalid(forklift.consumer.MessageRunnable)
17:34:12.604 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.MessageRunnableTest$TestListener1-public static void forklift.consumer.MessageRunnableTest$TestListener1.process(forklift.consumer.MessageRunnable)
17:34:12.662 [pool-5-thread-28] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.lifecycle.TestAuditor-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Processing)
17:34:12.663 [pool-5-thread-28] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.lifecycle.TestAuditor-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Retrying)
17:34:12.663 [pool-5-thread-28] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.lifecycle.TestAuditor-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Validating)
17:34:12.663 [pool-5-thread-28] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.lifecycle.TestAuditor-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Complete)
17:34:12.671 [pool-5-thread-2] ERROR forklift.consumer.MessageRunnable - failure
java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at forklift.consumer.MessageRunnable.lambda$null$7(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$66/513219867.get(Unknown Source)
	at forklift.consumer.MessageRunnable.runLoggingErrors(MessageRunnable.java:218)
	at forklift.consumer.MessageRunnable.lambda$run$14(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$59/1455320668.run(Unknown Source)
	at forklift.classloader.RunAsClassLoader.run(RunAsClassLoader.java:14)
	at forklift.consumer.MessageRunnable.run(MessageRunnable.java:61)
	at forklift.consumer.OnDecoratorTest.runTest(OnDecoratorTest.java:225)
	at forklift.consumer.OnDecoratorTest.onProcessStepErrorPath(OnDecoratorTest.java:140)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:138)
	at com.novocode.junit.JUnitRunner$1.execute(JUnitRunner.java:132)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:237)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: failure
	at forklift.consumer.OnDecoratorTest$TestConsumerError.processing(OnDecoratorTest.java:156)
	... 69 more

17:34:12.720 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.MessageRunnableTest$TestListener6-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Processing)
17:34:12.729 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.MessageRunnableTest$TestListener6-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Validating)
17:34:12.730 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.MessageRunnableTest$TestListener6-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Error)
17:34:12.740 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.MessageRunnableTest$TestListener6-public static void forklift.consumer.MessageRunnableTest$TestListener6.invalid(forklift.consumer.MessageRunnable)
17:34:12.741 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.MessageRunnableTest$TestListener6-public static void forklift.consumer.MessageRunnableTest$TestListener6.error(forklift.consumer.MessageRunnable)
17:34:12.741 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.MessageRunnableTest$TestListener6-public static void forklift.consumer.MessageRunnableTest$TestListener6.process(forklift.consumer.MessageRunnable)
17:34:12.764 [pool-5-thread-2] ERROR forklift.consumer.MessageRunnable - Validator validation returned false
17:34:12.771 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.MessageRunnableTest$TestListener4-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Processing)
17:34:12.772 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.MessageRunnableTest$TestListener4-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Validating)
17:34:12.780 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.MessageRunnableTest$TestListener4-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Complete)
17:34:12.781 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.MessageRunnableTest$TestListener4-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Error)
17:34:12.782 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.MessageRunnableTest$TestListener4-public static void forklift.consumer.MessageRunnableTest$TestListener4.invalid(forklift.consumer.MessageRunnable)
17:34:12.782 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.MessageRunnableTest$TestListener4-public static void forklift.consumer.MessageRunnableTest$TestListener4.error(forklift.consumer.MessageRunnable)
17:34:12.782 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.MessageRunnableTest$TestListener4-public static void forklift.consumer.MessageRunnableTest$TestListener4.process(forklift.consumer.MessageRunnable)
17:34:12.782 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.MessageRunnableTest$TestListener4-public static void forklift.consumer.MessageRunnableTest$TestListener4.complete(forklift.consumer.MessageRunnable)
17:34:12.838 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.MessageRunnableTest$TestListener3-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Processing)
17:34:12.839 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.MessageRunnableTest$TestListener3-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Validating)
17:34:12.839 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.MessageRunnableTest$TestListener3-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Error)
17:34:12.840 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.MessageRunnableTest$TestListener3-public static void forklift.consumer.MessageRunnableTest$TestListener3.invalid(forklift.consumer.MessageRunnable)
17:34:12.840 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.MessageRunnableTest$TestListener3-public static void forklift.consumer.MessageRunnableTest$TestListener3.error(forklift.consumer.MessageRunnable)
17:34:12.840 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.MessageRunnableTest$TestListener3-public static void forklift.consumer.MessageRunnableTest$TestListener3.process(forklift.consumer.MessageRunnable)
17:34:12.862 [Thread-6] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.lifecycle.TestAuditor2-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Processing)
17:34:12.863 [Thread-6] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.lifecycle.TestAuditor2-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Retrying)
17:34:12.863 [Thread-6] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.lifecycle.TestAuditor2-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Validating)
17:34:12.863 [Thread-6] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.lifecycle.TestAuditor2-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Complete)
17:34:12.863 [Thread-6] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.lifecycle.TestAuditor2-public static void forklift.consumer.lifecycle.TestAuditor2.validate(forklift.consumer.MessageRunnable) throws java.lang.InterruptedException
17:34:12.863 [Thread-6] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.lifecycle.TestAuditor2-public static void forklift.consumer.lifecycle.TestAuditor2.processing(forklift.consumer.MessageRunnable)
17:34:12.864 [Thread-6] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.lifecycle.TestAuditor2-public static void forklift.consumer.lifecycle.TestAuditor2.processing(forklift.consumer.MessageRunnable)
17:34:12.864 [Thread-6] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.lifecycle.TestAuditor2-public static void forklift.consumer.lifecycle.TestAuditor2.completed(forklift.consumer.MessageRunnable)
Processing: forklift.connectors.ForkliftMessage@7d4b246c
Validating: forklift.connectors.ForkliftMessage@4af8cd42
Processing: forklift.connectors.ForkliftMessage@6f4f8a2c
17:34:12.924 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.MessageRunnableTest$TestListener7-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Processing)
17:34:12.937 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.MessageRunnableTest$TestListener7-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Validating)
17:34:12.937 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.MessageRunnableTest$TestListener7-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Invalid)
17:34:12.939 [pool-5-thread-17] ERROR forklift.consumer.MessageRunnable - Error Validating
java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at forklift.consumer.MessageRunnable.lambda$null$5(MessageRunnable.java:81)
	at forklift.consumer.MessageRunnable$$Lambda$60/347142983.get(Unknown Source)
	at forklift.consumer.MessageRunnable.runLoggingErrors(MessageRunnable.java:218)
	at forklift.consumer.MessageRunnable.lambda$run$14(MessageRunnable.java:81)
	at forklift.consumer.MessageRunnable$$Lambda$59/1455320668.run(Unknown Source)
	at forklift.classloader.RunAsClassLoader.run(RunAsClassLoader.java:14)
	at forklift.consumer.MessageRunnable.run(MessageRunnable.java:61)
	at forklift.consumer.MessageRunnableTest.validationException(MessageRunnableTest.java:457)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:138)
	at com.novocode.junit.JUnitRunner$1.execute(JUnitRunner.java:132)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:237)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: Error Validating
	at forklift.consumer.MessageRunnableTest$TestConsumer7.validateMsg(MessageRunnableTest.java:474)
	... 68 more

17:34:12.943 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.MessageRunnableTest$TestListener7-public static void forklift.consumer.MessageRunnableTest$TestListener7.invalid(forklift.consumer.MessageRunnable)
17:34:12.943 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.MessageRunnableTest$TestListener7-public static void forklift.consumer.MessageRunnableTest$TestListener7.error(forklift.consumer.MessageRunnable)
17:34:12.944 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.MessageRunnableTest$TestListener7-public static void forklift.consumer.MessageRunnableTest$TestListener7.process(forklift.consumer.MessageRunnable)
17:34:13.009 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.MessageRunnableTest$TestListener2-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Processing)
17:34:13.009 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.MessageRunnableTest$TestListener2-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Validating)
17:34:13.009 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.MessageRunnableTest$TestListener2-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Error)
17:34:13.029 [pool-5-thread-17] ERROR forklift.consumer.MessageRunnable - onValidate method validateMsg has wrong return type class java.lang.Boolean
17:34:13.030 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.MessageRunnableTest$TestListener2-public static void forklift.consumer.MessageRunnableTest$TestListener2.invalid(forklift.consumer.MessageRunnable)
17:34:13.032 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.MessageRunnableTest$TestListener2-public static void forklift.consumer.MessageRunnableTest$TestListener2.error(forklift.consumer.MessageRunnable)
17:34:13.032 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.MessageRunnableTest$TestListener2-public static void forklift.consumer.MessageRunnableTest$TestListener2.process(forklift.consumer.MessageRunnable)
17:34:13.076 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.MessageRunnableTest$TestListener8-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Processing)
17:34:13.080 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.MessageRunnableTest$TestListener8-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Validating)
17:34:13.081 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.MessageRunnableTest$TestListener8-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Error)
17:34:13.095 [pool-5-thread-17] ERROR forklift.consumer.MessageRunnable - Error processing
java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at forklift.consumer.MessageRunnable.lambda$null$7(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$66/513219867.get(Unknown Source)
	at forklift.consumer.MessageRunnable.runLoggingErrors(MessageRunnable.java:218)
	at forklift.consumer.MessageRunnable.lambda$run$14(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$59/1455320668.run(Unknown Source)
	at forklift.classloader.RunAsClassLoader.run(RunAsClassLoader.java:14)
	at forklift.consumer.MessageRunnable.run(MessageRunnable.java:61)
	at forklift.consumer.MessageRunnableTest.processException(MessageRunnableTest.java:522)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:138)
	at com.novocode.junit.JUnitRunner$1.execute(JUnitRunner.java:132)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.Tests$$anonfun$9.apply(Tests.scala:216)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:237)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: Error processing
	at forklift.consumer.MessageRunnableTest$TestConsumer8.consumeMsg(MessageRunnableTest.java:534)
	... 68 more

17:34:13.096 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.MessageRunnableTest$TestListener8-public static void forklift.consumer.MessageRunnableTest$TestListener8.invalid(forklift.consumer.MessageRunnable)
17:34:13.096 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.MessageRunnableTest$TestListener8-public static void forklift.consumer.MessageRunnableTest$TestListener8.error(forklift.consumer.MessageRunnable)
17:34:13.096 [pool-5-thread-17] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.MessageRunnableTest$TestListener8-public static void forklift.consumer.MessageRunnableTest$TestListener8.process(forklift.consumer.MessageRunnable)
Processing: forklift.connectors.ForkliftMessage@69e3be8a
Processing: forklift.connectors.ForkliftMessage@443f2a6d
Validating: forklift.connectors.ForkliftMessage@4efee80c
Processing: forklift.connectors.ForkliftMessage@738cc5b5
Processing: forklift.connectors.ForkliftMessage@67245dc6
Processing: forklift.connectors.ForkliftMessage@40391fa3
Completed: forklift.connectors.ForkliftMessage@618879b5
Processing: forklift.connectors.ForkliftMessage@4000a632
Processing: forklift.connectors.ForkliftMessage@77b34f1c
Completed: forklift.connectors.ForkliftMessage@65b7e15c
Completed: forklift.connectors.ForkliftMessage@20b5738e
Processing: forklift.connectors.ForkliftMessage@631bd5fa
Completed: forklift.connectors.ForkliftMessage@4406837c
Processing: forklift.connectors.ForkliftMessage@33b8935e
Processing: forklift.connectors.ForkliftMessage@5022056
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.activemq#activemq-all;5.14.0!activemq-all.jar (10762ms)[0m
Processing: forklift.connectors.ForkliftMessage@32b1cf8e
Completed: forklift.connectors.ForkliftMessage@1041598
[0m[[0minfo[0m] [0mDone updating.[0m
[0m[[0minfo[0m] [0mResolving com.github.dcshock#forklift;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro-compiler;1.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-lang#commons-lang;2.6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.velocity#velocity;1.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-collections#commons-collections;3.2.1 ...[0m
[0m[[0minfo[0m] [0mCompiling 5 Java sources to /home/travis/build/dcshock/forklift/connectors/activemq/target/classes...[0m
[0m[[0minfo[0m] [0mResolving org.codehaus.jackson#jackson-core-asl;1.8.8 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.jackson#jackson-mapper-asl;1.8.8 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-api;1.6.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.google.guava#guava;18.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.core#jackson-databind;2.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.core#jackson-annotations;2.7.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.core#jackson-core;2.7.3 ...[0m
Completed: forklift.connectors.ForkliftMessage@115f114d
Completed: forklift.connectors.ForkliftMessage@99c6f69
Completed: forklift.connectors.ForkliftMessage@3803333c
Processing: forklift.connectors.ForkliftMessage@4bb8af3b
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.datatype#jackson-datatype-jsr310;2.7.3 ...[0m
Validating: forklift.connectors.ForkliftMessage@344d4075
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback#logback-classic;1.0.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback#logback-core;1.0.13 ...[0m
Validating: forklift.connectors.ForkliftMessage@30cff798
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-api;1.7.5 ...[0m
Validating: forklift.connectors.ForkliftMessage@261957fd
Completed: forklift.connectors.ForkliftMessage@167de5f0
[A[2K[0m[[0minfo[0m] [0mResolving org.reflections#reflections;0.9.10 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.javassist#javassist;3.18.2-GA ...[0m
Processing: forklift.connectors.ForkliftMessage@3c93be7
[A[2K[0m[[0minfo[0m] [0mResolving com.google.code.findbugs#annotations;2.0.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving javax.inject#javax.inject;1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.kafka#kafka-clients;0.10.1.1-cp1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.kafka#kafka-clients;0.10.1.1-cp1 ...[0m
Completed: forklift.connectors.ForkliftMessage@713951f8
Completed: forklift.connectors.ForkliftMessage@409a8cc1
Processing: forklift.connectors.ForkliftMessage@177517ae
Validating: forklift.connectors.ForkliftMessage@40228f9e
Processing: forklift.connectors.ForkliftMessage@6eef4f2d
Completed: forklift.connectors.ForkliftMessage@37cfc5ef
Completed: forklift.connectors.ForkliftMessage@5ef36f22
Processing: forklift.connectors.ForkliftMessage@652ddf19
Completed: forklift.connectors.ForkliftMessage@50bcc2b0
[0m[[0minfo[0m] [0mCompiling 10 Java sources to /home/travis/build/dcshock/forklift/connectors/activemq/target/test-classes...[0m
Processing: forklift.connectors.ForkliftMessage@44d4b0e2
Completed: forklift.connectors.ForkliftMessage@2a7cb4bf
[0m[[0minfo[0m] [0mResolving net.jpountz.lz4#lz4;1.3.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving net.jpountz.lz4#lz4;1.3.0 ...[0m
Validating: forklift.connectors.ForkliftMessage@612bead7
Processing: forklift.connectors.ForkliftMessage@529e30c1
[A[2K[0m[[0minfo[0m] [0mResolving org.xerial.snappy#snappy-java;1.1.2.6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.xerial.snappy#snappy-java;1.1.2.6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-api;1.7.21 ...[0m
Processing: forklift.connectors.ForkliftMessage@4636a8b2
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-api;1.7.21 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-parent;1.7.21 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-parent;1.7.21 ...[0m
Completed: forklift.connectors.ForkliftMessage@51b0a48b
Validating: forklift.connectors.ForkliftMessage@6a3d99d4
Completed: forklift.connectors.ForkliftMessage@d7df52a
Completed: forklift.connectors.ForkliftMessage@48b211d8
[A[2K[0m[[0minfo[0m] [0mResolving io.confluent#kafka-avro-serializer;3.1.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving io.confluent#kafka-avro-serializer;3.1.1 ...[0m
Processing: forklift.connectors.ForkliftMessage@4090af1d
Validating: forklift.connectors.ForkliftMessage@2bb51d07
Validating: forklift.connectors.ForkliftMessage@6163469d
[A[2K[0m[[0minfo[0m] [0mResolving io.confluent#kafka-schema-registry-parent;3.1.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving io.confluent#kafka-schema-registry-parent;3.1.1 ...[0m
SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/home/travis/.ivy2/cache/ch.qos.logback/logback-classic/jars/logback-classic-1.0.13.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/home/travis/.ivy2/cache/org.apache.activemq/activemq-all/jars/activemq-all-5.14.0.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
Validating: forklift.connectors.ForkliftMessage@41996254
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey#jersey-bom;2.19 ...[0m
Processing: forklift.connectors.ForkliftMessage@face3a0
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey#jersey-bom;2.19 ...[0m
SLF4J: Actual binding is of type [ch.qos.logback.classic.util.ContextSelectorStaticBinder]
[A[2K[0m[[0minfo[0m] [0mResolving net.java#jvnet-parent;4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving net.java#jvnet-parent;4 ...[0m
Completed: forklift.connectors.ForkliftMessage@61691d95
Processing: forklift.connectors.ForkliftMessage@7eade33c
Processing: forklift.connectors.ForkliftMessage@75eba0b2
17:34:18.925 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Creating RMIRegistry on port 1099
Processing: forklift.connectors.ForkliftMessage@6e53e6d0
Validating: forklift.connectors.ForkliftMessage@7e6ed5ae
Processing: forklift.connectors.ForkliftMessage@5b26c3b4
17:34:19.021 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Probably not using JRE 1.4: mx4j.tools.naming.NamingService
17:34:19.041 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Created JMXConnectorServer javax.management.remote.rmi.RMIConnectorServer@5bdf785b
Validating: forklift.connectors.ForkliftMessage@1f9f1fab
17:34:19.105 [JMX connector] DEBUG o.a.a.broker.jmx.ManagementContext - Starting JMXConnectorServer...
17:34:19.240 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Using Persistence Adapter: KahaDBPersistenceAdapter[/tmp/1496424858575-0/localhost/KahaDB]
17:34:19.318 [pool-5-thread-7] DEBUG o.a.a.store.kahadb.KahaDBStore - Store OpenWire version configured as: 11
Completed: forklift.connectors.ForkliftMessage@56d08ef6
Completed: forklift.connectors.ForkliftMessage@6565f755
17:34:19.586 [Thread-7] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.lifecycle.TestAuditor2-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Processing)
17:34:19.586 [Thread-7] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.lifecycle.TestAuditor2-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Retrying)
17:34:19.586 [Thread-7] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.lifecycle.TestAuditor2-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Validating)
17:34:19.587 [Thread-7] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.lifecycle.TestAuditor2-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Complete)
17:34:19.595 [Thread-7] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.lifecycle.TestAuditor2-public static void forklift.consumer.lifecycle.TestAuditor2.validate(forklift.consumer.MessageRunnable) throws java.lang.InterruptedException
17:34:19.596 [Thread-7] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.lifecycle.TestAuditor2-public static void forklift.consumer.lifecycle.TestAuditor2.processing(forklift.consumer.MessageRunnable)
17:34:19.596 [Thread-7] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.lifecycle.TestAuditor2-public static void forklift.consumer.lifecycle.TestAuditor2.processing(forklift.consumer.MessageRunnable)
17:34:19.596 [Thread-7] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.lifecycle.TestAuditor2-public static void forklift.consumer.lifecycle.TestAuditor2.completed(forklift.consumer.MessageRunnable)
17:34:19.597 [Thread-8] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.lifecycle.TestAuditor2-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Processing)
17:34:19.597 [Thread-8] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.lifecycle.TestAuditor2-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Retrying)
17:34:19.597 [Thread-8] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.lifecycle.TestAuditor2-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Validating)
17:34:19.597 [Thread-8] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.lifecycle.TestAuditor2-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Complete)
17:34:19.597 [Thread-8] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.lifecycle.TestAuditor2-public static void forklift.consumer.lifecycle.TestAuditor2.validate(forklift.consumer.MessageRunnable) throws java.lang.InterruptedException
17:34:19.599 [Thread-8] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.lifecycle.TestAuditor2-public static void forklift.consumer.lifecycle.TestAuditor2.processing(forklift.consumer.MessageRunnable)
17:34:19.599 [Thread-8] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.lifecycle.TestAuditor2-public static void forklift.consumer.lifecycle.TestAuditor2.processing(forklift.consumer.MessageRunnable)
17:34:19.599 [Thread-8] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.lifecycle.TestAuditor2-public static void forklift.consumer.lifecycle.TestAuditor2.completed(forklift.consumer.MessageRunnable)
17:34:19.599 [Thread-9] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.lifecycle.TestAuditor2-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Processing)
17:34:19.599 [Thread-9] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.lifecycle.TestAuditor2-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Retrying)
17:34:19.600 [Thread-9] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.lifecycle.TestAuditor2-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Validating)
17:34:19.600 [Thread-9] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.lifecycle.TestAuditor2-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Complete)
17:34:19.600 [Thread-9] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.lifecycle.TestAuditor2-public static void forklift.consumer.lifecycle.TestAuditor2.validate(forklift.consumer.MessageRunnable) throws java.lang.InterruptedException
17:34:19.600 [Thread-9] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.lifecycle.TestAuditor2-public static void forklift.consumer.lifecycle.TestAuditor2.processing(forklift.consumer.MessageRunnable)
17:34:19.600 [Thread-9] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.lifecycle.TestAuditor2-public static void forklift.consumer.lifecycle.TestAuditor2.processing(forklift.consumer.MessageRunnable)
17:34:19.600 [Thread-9] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.lifecycle.TestAuditor2-public static void forklift.consumer.lifecycle.TestAuditor2.completed(forklift.consumer.MessageRunnable)
17:34:19.605 [Thread-10] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.lifecycle.TestAuditor2-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Processing)
17:34:19.605 [Thread-10] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.lifecycle.TestAuditor2-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Retrying)
17:34:19.605 [Thread-10] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.lifecycle.TestAuditor2-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Validating)
17:34:19.606 [Thread-10] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.consumer.lifecycle.TestAuditor2-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Complete)
17:34:19.606 [Thread-10] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.lifecycle.TestAuditor2-public static void forklift.consumer.lifecycle.TestAuditor2.validate(forklift.consumer.MessageRunnable) throws java.lang.InterruptedException
17:34:19.606 [Thread-10] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.lifecycle.TestAuditor2-public static void forklift.consumer.lifecycle.TestAuditor2.processing(forklift.consumer.MessageRunnable)
17:34:19.606 [Thread-10] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.lifecycle.TestAuditor2-public static void forklift.consumer.lifecycle.TestAuditor2.processing(forklift.consumer.MessageRunnable)
17:34:19.606 [Thread-10] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.lifecycle.TestAuditor2-public static void forklift.consumer.lifecycle.TestAuditor2.completed(forklift.consumer.MessageRunnable)
Completed: forklift.connectors.ForkliftMessage@31785f90
Validating: forklift.connectors.ForkliftMessage@7d296dd7
Validating: forklift.connectors.ForkliftMessage@204844a3
[A[2K[0m[[0minfo[0m] [0mResolving io.confluent#kafka-schema-registry-client;3.1.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving io.confluent#kafka-schema-registry-client;3.1.1 ...[0m
Processing: forklift.connectors.ForkliftMessage@558efc0e
Processing: forklift.connectors.ForkliftMessage@42781235
Processing: forklift.connectors.ForkliftMessage@3a93836d
17:34:20.036 [JMX connector] INFO  o.a.a.broker.jmx.ManagementContext - JMX consoles can connect to service:jmx:rmi:///jndi/rmi://localhost:1099/jmxrmi
[A[2K[0m[[0minfo[0m] [0mResolving io.confluent#kafka-schema-registry-parent;3.1.1 ...[0m
Processing: forklift.connectors.ForkliftMessage@254d8f7b
Completed: forklift.connectors.ForkliftMessage@7c22c69f
17:34:20.507 [pool-5-thread-7] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
Completed: forklift.connectors.ForkliftMessage@3c664ed2
Processing: forklift.connectors.ForkliftMessage@489112e9
17:34:20.571 [pool-5-thread-7] INFO  o.a.a.s.kahadb.plist.PListStoreImpl - PListStore:[/tmp/1496424858575-0/localhost/tmp_storage] started
Validating: forklift.connectors.ForkliftMessage@40b23cf8
Processing: forklift.connectors.ForkliftMessage@474ab06d
[A[2K[0m[[0minfo[0m] [0mResolving io.confluent#common-config;3.1.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving io.confluent#common-config;3.1.1 ...[0m
Validating: forklift.connectors.ForkliftMessage@54e41799
17:34:20.992 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:1) is starting
17:34:21.040 [pool-5-thread-7] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:21.042 [pool-5-thread-7] INFO  o.a.a.t.TransportServerThreadSupport - Listening for connections at: tcp://localhost:61618
17:34:21.044 [pool-5-thread-7] INFO  o.a.a.broker.TransportConnector - Connector tcp://localhost:61618 started
17:34:21.046 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:1) started
17:34:21.047 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - For help or more information please see: http://activemq.apache.org
17:34:21.048 [pool-5-thread-7] WARN  o.a.activemq.broker.BrokerService - Store limit is 102400 mb (current store usage is 0 mb). The data directory: /tmp/1496424858575-0/localhost/KahaDB only has 14181 mb of usable space. - resetting to maximum available disk space: 14181 mb
17:34:21.062 [pool-5-thread-7] WARN  o.a.activemq.broker.BrokerService - Temporary Store limit is 51200 mb (current store usage is 0 mb). The data directory: /tmp/1496424858575-0/localhost only has 14181 mb of usable space. - resetting to maximum available disk space: 14181 mb
17:34:21.094 [pool-5-thread-7] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.MasterBroker
[A[2K[0m[[0minfo[0m] [0mResolving io.confluent#common;3.1.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving io.confluent#common;3.1.1 ...[0m
17:34:21.151 [pool-5-thread-7] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ BrokerService[localhost] Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@281f73f2[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:21.278 [pool-5-thread-7] DEBUG ForkLift - Creating ForkLift
17:34:21.278 [pool-5-thread-7] DEBUG ForkLift - Init complete!
17:34:21.279 [pool-5-thread-7] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.activemq.test.MessagingTest-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Pending)
17:34:21.280 [pool-5-thread-7] INFO  forklift.consumer.LifeCycleMonitors - Adding Monitor.... class forklift.activemq.test.MessagingTest-@forklift.decorators.LifeCycle(annotation=interface java.lang.annotation.Annotation, value=Complete)
17:34:21.298 [pool-5-thread-7] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@7ba8cd37[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:21.300 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Reconnect was triggered but transport is not started yet. Wait for start to connect the transport.
17:34:21.309 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Started unconnected
17:34:21.309 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Waking up reconnect task
Processing: forklift.connectors.ForkliftMessage@33c57fa1
Validating: forklift.connectors.ForkliftMessage@36debb32
17:34:21.320 [ActiveMQ Task-1] DEBUG o.a.a.t.failover.FailoverTransport - urlList connectionList:[tcp://127.0.0.1:61618], from: [tcp://127.0.0.1:61618]
17:34:21.411 [ActiveMQ Task-1] DEBUG o.a.a.t.failover.FailoverTransport - Attempting 0th connect to: tcp://127.0.0.1:61618
17:34:21.418 [ActiveMQ Task-1] DEBUG o.a.a.transport.WireFormatNegotiator - Sending: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:21.421 [ActiveMQ Task-1] DEBUG o.a.a.t.failover.FailoverTransport - Connection established
17:34:21.422 [ActiveMQ Task-1] INFO  o.a.a.t.failover.FailoverTransport - Successfully connected to tcp://127.0.0.1:61618
Completed: forklift.connectors.ForkliftMessage@2547432c
17:34:21.500 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.transport.WireFormatNegotiator - Sending: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:21.521 [ActiveMQ Transport: tcp:///127.0.0.1:61618@38926] DEBUG o.a.a.transport.InactivityMonitor - Using min of local: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]} and remote: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:21.521 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.transport.InactivityMonitor - Using min of local: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]} and remote: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:21.522 [ActiveMQ Transport: tcp:///127.0.0.1:61618@38926] DEBUG o.a.a.transport.WireFormatNegotiator - Received WireFormat: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:21.522 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.transport.WireFormatNegotiator - Received WireFormat: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:21.535 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:38926@61618 before negotiation: OpenWireFormat{version=12, cacheEnabled=false, stackTraceEnabled=false, tightEncodingEnabled=false, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:21.536 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:38926@61618 after negotiation: OpenWireFormat{version=12, cacheEnabled=true, stackTraceEnabled=true, tightEncodingEnabled=true, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
Validating: forklift.connectors.ForkliftMessage@69184cd
17:34:21.522 [ActiveMQ Transport: tcp:///127.0.0.1:61618@38926] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:61618@38926 before negotiation: OpenWireFormat{version=12, cacheEnabled=false, stackTraceEnabled=false, tightEncodingEnabled=false, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:21.540 [ActiveMQ Transport: tcp:///127.0.0.1:61618@38926] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:61618@38926 after negotiation: OpenWireFormat{version=12, cacheEnabled=true, stackTraceEnabled=true, tightEncodingEnabled=true, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
Processing: forklift.connectors.ForkliftMessage@6f52d78e
17:34:21.562 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.TransportConnection - Setting up new connection id: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1, address: tcp://127.0.0.1:38926, info: ConnectionInfo {commandId = 1, responseRequired = true, connectionId = ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1, clientId = ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-3:1, clientIp = null, userName = , password = *****, brokerPath = null, brokerMasterConnector = false, manageable = true, clientMaster = true, faultTolerant = true, failoverReconnect = false}
17:34:21.571 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:21.571 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:21.606 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Connection
17:34:21.665 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:-1:1 for destination: ActiveMQ.Advisory.TempQueue,ActiveMQ.Advisory.TempTopic
Processing: forklift.connectors.ForkliftMessage@10f0ce6f
Validating: forklift.connectors.ForkliftMessage@31ae2a56
Validating: forklift.connectors.ForkliftMessage@d5deb9b
[A[2K[0m[[0minfo[0m] [0mResolving io.confluent#common-utils;3.1.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving io.confluent#common-utils;3.1.1 ...[0m
17:34:22.278 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: queue://q1
17:34:22.329 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:22.330 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:22.330 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:22.331 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:22.331 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
Completed: forklift.connectors.ForkliftMessage@24dd769d
17:34:22.434 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 0, dequeueCount: 0, memUsage:0, maxPageSize:200
17:34:22.437 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:22.437 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:22.437 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Queue
17:34:22.489 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:22.489 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:22.489 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Producer.Queue.q1
17:34:22.596 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:1 sent to queue://q1
[A[2K[0m[[0minfo[0m] [0mResolving io.confluent#common;3.1.1 ...[0m
17:34:22.608 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=1, pending=0 toPageIn: 1, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 1, dequeueCount: 0, memUsage:2098, maxPageSize:200
Processing: forklift.connectors.ForkliftMessage@334a69bc
Validating: forklift.connectors.ForkliftMessage@4ea14aa7
17:34:22.671 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:2 sent to queue://q1
17:34:22.672 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=2, pending=0 toPageIn: 2, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 2, dequeueCount: 0, memUsage:3147, maxPageSize:200
17:34:22.679 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:3 sent to queue://q1
17:34:22.679 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=3, pending=0 toPageIn: 3, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 3, dequeueCount: 0, memUsage:4196, maxPageSize:200
17:34:22.690 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:4 sent to queue://q1
17:34:22.690 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=4, pending=0 toPageIn: 4, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 4, dequeueCount: 0, memUsage:6294, maxPageSize:200
17:34:22.712 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:5 sent to queue://q1
17:34:22.712 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=5, pending=0 toPageIn: 5, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 5, dequeueCount: 0, memUsage:7343, maxPageSize:200
17:34:22.726 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:6 sent to queue://q1
17:34:22.727 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=6, pending=0 toPageIn: 6, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 6, dequeueCount: 0, memUsage:8392, maxPageSize:200
17:34:22.734 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:7 sent to queue://q1
17:34:22.734 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=7, pending=0 toPageIn: 7, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 7, dequeueCount: 0, memUsage:9441, maxPageSize:200
17:34:22.738 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:8 sent to queue://q1
17:34:22.738 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=8, pending=0 toPageIn: 8, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 8, dequeueCount: 0, memUsage:10490, maxPageSize:200
Validating: forklift.connectors.ForkliftMessage@1eee027d
17:34:22.755 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:9 sent to queue://q1
17:34:22.755 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=9, pending=0 toPageIn: 9, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 9, dequeueCount: 0, memUsage:11539, maxPageSize:200
17:34:22.759 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:10 sent to queue://q1
17:34:22.777 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=10, pending=0 toPageIn: 10, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 0, memUsage:11539, maxPageSize:200
17:34:22.787 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:11 sent to queue://q1
17:34:22.787 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=11, pending=0 toPageIn: 11, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 11, dequeueCount: 0, memUsage:12588, maxPageSize:200
17:34:22.790 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:12 sent to queue://q1
17:34:22.791 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=12, pending=0 toPageIn: 12, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 12, dequeueCount: 0, memUsage:13637, maxPageSize:200
17:34:22.798 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:13 sent to queue://q1
17:34:22.799 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=13, pending=0 toPageIn: 13, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 13, dequeueCount: 0, memUsage:14686, maxPageSize:200
17:34:22.805 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:14 sent to queue://q1
17:34:22.806 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=14, pending=0 toPageIn: 14, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 14, dequeueCount: 0, memUsage:15735, maxPageSize:200
17:34:22.811 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:15 sent to queue://q1
17:34:22.812 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=15, pending=0 toPageIn: 15, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 15, dequeueCount: 0, memUsage:16784, maxPageSize:200
17:34:22.823 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:16 sent to queue://q1
17:34:22.824 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=16, pending=0 toPageIn: 16, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 16, dequeueCount: 0, memUsage:17833, maxPageSize:200
17:34:22.831 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:17 sent to queue://q1
17:34:22.832 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=17, pending=0 toPageIn: 17, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 17, dequeueCount: 0, memUsage:18882, maxPageSize:200
17:34:22.836 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:18 sent to queue://q1
17:34:22.841 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=18, pending=0 toPageIn: 18, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 18, dequeueCount: 0, memUsage:18882, maxPageSize:200
17:34:22.842 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:19 sent to queue://q1
17:34:22.843 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=19, pending=0 toPageIn: 19, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 19, dequeueCount: 0, memUsage:20980, maxPageSize:200
17:34:22.857 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:20 sent to queue://q1
17:34:22.857 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=20, pending=0 toPageIn: 20, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 0, memUsage:22029, maxPageSize:200
17:34:22.867 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:21 sent to queue://q1
17:34:22.867 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=21, pending=0 toPageIn: 21, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 21, dequeueCount: 0, memUsage:23078, maxPageSize:200
17:34:22.894 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:22 sent to queue://q1
17:34:22.896 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=22, pending=0 toPageIn: 22, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 22, dequeueCount: 0, memUsage:24127, maxPageSize:200
17:34:22.924 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:23 sent to queue://q1
17:34:22.924 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=23, pending=0 toPageIn: 23, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 23, dequeueCount: 0, memUsage:25176, maxPageSize:200
17:34:22.973 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:24 sent to queue://q1
17:34:22.973 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=24, pending=0 toPageIn: 24, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 24, dequeueCount: 0, memUsage:26225, maxPageSize:200
17:34:22.986 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:25 sent to queue://q1
17:34:22.986 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=25, pending=0 toPageIn: 25, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 25, dequeueCount: 0, memUsage:27274, maxPageSize:200
17:34:23.011 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:26 sent to queue://q1
17:34:23.012 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=26, pending=0 toPageIn: 26, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 26, dequeueCount: 0, memUsage:28323, maxPageSize:200
17:34:23.058 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:27 sent to queue://q1
17:34:23.058 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=27, pending=0 toPageIn: 27, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 27, dequeueCount: 0, memUsage:29372, maxPageSize:200
17:34:23.066 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:28 sent to queue://q1
17:34:23.066 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=28, pending=0 toPageIn: 28, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 28, dequeueCount: 0, memUsage:30421, maxPageSize:200
[A[2K[0m[[0minfo[0m] [0mResolving com.101tec#zkclient;0.9 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.101tec#zkclient;0.9 ...[0m
17:34:23.085 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:29 sent to queue://q1
17:34:23.085 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=29, pending=0 toPageIn: 29, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 29, dequeueCount: 0, memUsage:31470, maxPageSize:200
17:34:23.120 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:30 sent to queue://q1
17:34:23.128 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=30, pending=0 toPageIn: 30, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 30, dequeueCount: 0, memUsage:32519, maxPageSize:200
17:34:23.145 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:31 sent to queue://q1
17:34:23.147 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=31, pending=0 toPageIn: 31, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 31, dequeueCount: 0, memUsage:33568, maxPageSize:200
17:34:23.202 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:32 sent to queue://q1
17:34:23.203 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=32, pending=0 toPageIn: 32, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 32, dequeueCount: 0, memUsage:34617, maxPageSize:200
17:34:23.212 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:33 sent to queue://q1
17:34:23.213 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=33, pending=0 toPageIn: 33, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 33, dequeueCount: 0, memUsage:35666, maxPageSize:200
17:34:23.221 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:34 sent to queue://q1
17:34:23.223 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=34, pending=0 toPageIn: 34, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 34, dequeueCount: 0, memUsage:36715, maxPageSize:200
17:34:23.233 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:35 sent to queue://q1
17:34:23.233 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=35, pending=0 toPageIn: 35, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 35, dequeueCount: 0, memUsage:37764, maxPageSize:200
17:34:23.236 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:36 sent to queue://q1
17:34:23.236 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=36, pending=0 toPageIn: 36, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 36, dequeueCount: 0, memUsage:38813, maxPageSize:200
17:34:23.252 [Thread-13] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.lifecycle.TestAuditor-public static void forklift.consumer.lifecycle.TestAuditor.validate(forklift.consumer.MessageRunnable) throws java.lang.InterruptedException
17:34:23.252 [Thread-13] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.lifecycle.TestAuditor-public static void forklift.consumer.lifecycle.TestAuditor.processing(forklift.consumer.MessageRunnable) throws java.lang.InterruptedException
17:34:23.252 [Thread-13] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.lifecycle.TestAuditor-public static void forklift.consumer.lifecycle.TestAuditor.processing(forklift.consumer.MessageRunnable) throws java.lang.InterruptedException
17:34:23.252 [Thread-13] INFO  forklift.consumer.LifeCycleMonitors - Removing Monitor.... class forklift.consumer.lifecycle.TestAuditor-public static void forklift.consumer.lifecycle.TestAuditor.completed(forklift.consumer.MessageRunnable)
17:34:23.254 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:37 sent to queue://q1
17:34:23.254 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=37, pending=0 toPageIn: 37, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 37, dequeueCount: 0, memUsage:39862, maxPageSize:200
17:34:23.257 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:38 sent to queue://q1
17:34:23.258 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=38, pending=0 toPageIn: 38, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 38, dequeueCount: 0, memUsage:40911, maxPageSize:200
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.zookeeper#zookeeper;3.4.8 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.zookeeper#zookeeper;3.4.8 ...[0m
17:34:23.269 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:39 sent to queue://q1
17:34:23.269 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=39, pending=0 toPageIn: 39, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 39, dequeueCount: 0, memUsage:41960, maxPageSize:200
17:34:23.276 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:40 sent to queue://q1
17:34:23.277 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=40, pending=0 toPageIn: 40, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 40, dequeueCount: 0, memUsage:43009, maxPageSize:200
17:34:23.282 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:41 sent to queue://q1
17:34:23.282 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=41, pending=0 toPageIn: 41, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 41, dequeueCount: 0, memUsage:44058, maxPageSize:200
17:34:23.286 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:42 sent to queue://q1
17:34:23.286 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=42, pending=0 toPageIn: 42, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 42, dequeueCount: 0, memUsage:45107, maxPageSize:200
17:34:23.289 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:43 sent to queue://q1
17:34:23.289 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=43, pending=0 toPageIn: 43, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 43, dequeueCount: 0, memUsage:46156, maxPageSize:200
17:34:23.294 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:44 sent to queue://q1
17:34:23.294 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=44, pending=0 toPageIn: 44, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 44, dequeueCount: 0, memUsage:48254, maxPageSize:200
17:34:23.302 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:45 sent to queue://q1
17:34:23.302 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=45, pending=0 toPageIn: 45, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 45, dequeueCount: 0, memUsage:48254, maxPageSize:200
[A[2K[0m[[0minfo[0m] [0mResolving jline#jline;0.9.94 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving jline#jline;0.9.94 ...[0m
17:34:23.317 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:46 sent to queue://q1
17:34:23.317 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=46, pending=0 toPageIn: 46, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 46, dequeueCount: 0, memUsage:50352, maxPageSize:200
17:34:23.320 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:47 sent to queue://q1
17:34:23.320 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=47, pending=0 toPageIn: 47, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 47, dequeueCount: 0, memUsage:50352, maxPageSize:200
17:34:23.324 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:48 sent to queue://q1
17:34:23.325 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=48, pending=0 toPageIn: 48, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 48, dequeueCount: 0, memUsage:52450, maxPageSize:200
17:34:23.328 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:49 sent to queue://q1
17:34:23.333 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=49, pending=0 toPageIn: 49, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 49, dequeueCount: 0, memUsage:53499, maxPageSize:200
[A[2K[0m[[0minfo[0m] [0mResolving io.netty#netty;3.7.0.Final ...[0m
17:34:23.346 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:50 sent to queue://q1
[A[2K[0m[[0minfo[0m] [0mResolving io.netty#netty;3.7.0.Final ...[0m
17:34:23.347 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=50, pending=0 toPageIn: 50, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 50, dequeueCount: 0, memUsage:53499, maxPageSize:200
17:34:23.359 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:51 sent to queue://q1
17:34:23.360 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=51, pending=0 toPageIn: 51, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 51, dequeueCount: 0, memUsage:54548, maxPageSize:200
17:34:23.363 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:52 sent to queue://q1
17:34:23.364 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=52, pending=0 toPageIn: 52, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 52, dequeueCount: 0, memUsage:56646, maxPageSize:200
17:34:23.374 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:53 sent to queue://q1
17:34:23.375 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=53, pending=0 toPageIn: 53, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 53, dequeueCount: 0, memUsage:57695, maxPageSize:200
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.oss#oss-parent;7 ...[0m
17:34:23.382 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:54 sent to queue://q1
17:34:23.383 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=54, pending=0 toPageIn: 54, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 54, dequeueCount: 0, memUsage:58744, maxPageSize:200
17:34:23.421 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:55 sent to queue://q1
17:34:23.422 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=55, pending=0 toPageIn: 55, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 55, dequeueCount: 0, memUsage:59793, maxPageSize:200
17:34:23.427 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:56 sent to queue://q1
17:34:23.429 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=56, pending=0 toPageIn: 56, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 56, dequeueCount: 0, memUsage:60842, maxPageSize:200
17:34:23.433 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:57 sent to queue://q1
17:34:23.434 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=57, pending=0 toPageIn: 57, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 57, dequeueCount: 0, memUsage:61891, maxPageSize:200
17:34:23.438 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:58 sent to queue://q1
17:34:23.438 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=58, pending=0 toPageIn: 58, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 58, dequeueCount: 0, memUsage:62940, maxPageSize:200
17:34:23.442 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:59 sent to queue://q1
17:34:23.442 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=59, pending=0 toPageIn: 59, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 59, dequeueCount: 0, memUsage:63989, maxPageSize:200
17:34:23.447 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:60 sent to queue://q1
17:34:23.447 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=60, pending=0 toPageIn: 60, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 60, dequeueCount: 0, memUsage:65038, maxPageSize:200
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro;1.8.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro;1.8.1 ...[0m
17:34:23.481 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:61 sent to queue://q1
17:34:23.481 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=61, pending=0 toPageIn: 61, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 61, dequeueCount: 0, memUsage:66087, maxPageSize:200
17:34:23.488 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:62 sent to queue://q1
17:34:23.489 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=62, pending=0 toPageIn: 62, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 62, dequeueCount: 0, memUsage:66087, maxPageSize:200
17:34:23.491 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:63 sent to queue://q1
17:34:23.492 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=63, pending=0 toPageIn: 63, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 63, dequeueCount: 0, memUsage:68185, maxPageSize:200
17:34:23.495 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:64 sent to queue://q1
17:34:23.496 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=64, pending=0 toPageIn: 64, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 64, dequeueCount: 0, memUsage:68185, maxPageSize:200
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro-parent;1.8.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro-parent;1.8.1 ...[0m
17:34:23.505 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:65 sent to queue://q1
17:34:23.506 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=65, pending=0 toPageIn: 65, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 65, dequeueCount: 0, memUsage:69234, maxPageSize:200
17:34:23.512 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:66 sent to queue://q1
17:34:23.512 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=66, pending=0 toPageIn: 66, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 66, dequeueCount: 0, memUsage:70283, maxPageSize:200
17:34:23.517 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:67 sent to queue://q1
17:34:23.518 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=67, pending=0 toPageIn: 67, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 67, dequeueCount: 0, memUsage:72381, maxPageSize:200
17:34:23.522 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:68 sent to queue://q1
17:34:23.522 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=68, pending=0 toPageIn: 68, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 68, dequeueCount: 0, memUsage:72381, maxPageSize:200
17:34:23.527 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:69 sent to queue://q1
17:34:23.528 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=69, pending=0 toPageIn: 69, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 69, dequeueCount: 0, memUsage:74479, maxPageSize:200
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro-toplevel;1.8.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro-toplevel;1.8.1 ...[0m
17:34:23.532 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:70 sent to queue://q1
17:34:23.533 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=70, pending=0 toPageIn: 70, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 70, dequeueCount: 0, memUsage:75528, maxPageSize:200
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;10 ...[0m
17:34:23.578 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:71 sent to queue://q1
17:34:23.579 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=71, pending=0 toPageIn: 71, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 71, dequeueCount: 0, memUsage:76577, maxPageSize:200
17:34:23.583 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:72 sent to queue://q1
17:34:23.584 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=72, pending=0 toPageIn: 72, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 72, dequeueCount: 0, memUsage:77626, maxPageSize:200
17:34:23.590 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:73 sent to queue://q1
17:34:23.590 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=73, pending=0 toPageIn: 73, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 73, dequeueCount: 0, memUsage:78675, maxPageSize:200
17:34:23.596 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:74 sent to queue://q1
17:34:23.596 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=74, pending=0 toPageIn: 74, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 74, dequeueCount: 0, memUsage:79724, maxPageSize:200
17:34:23.602 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:75 sent to queue://q1
17:34:23.602 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=75, pending=0 toPageIn: 75, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 75, dequeueCount: 0, memUsage:80773, maxPageSize:200
17:34:23.605 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:76 sent to queue://q1
17:34:23.605 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=76, pending=0 toPageIn: 76, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 76, dequeueCount: 0, memUsage:81822, maxPageSize:200
17:34:23.611 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:77 sent to queue://q1
17:34:23.613 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=77, pending=0 toPageIn: 77, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 77, dequeueCount: 0, memUsage:82871, maxPageSize:200
17:34:23.618 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:78 sent to queue://q1
17:34:23.618 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=78, pending=0 toPageIn: 78, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 78, dequeueCount: 0, memUsage:83920, maxPageSize:200
17:34:23.632 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:79 sent to queue://q1
17:34:23.632 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=79, pending=0 toPageIn: 79, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 79, dequeueCount: 0, memUsage:84969, maxPageSize:200
17:34:23.648 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:80 sent to queue://q1
17:34:23.649 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=80, pending=0 toPageIn: 80, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 80, dequeueCount: 0, memUsage:84969, maxPageSize:200
17:34:23.655 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:81 sent to queue://q1
17:34:23.655 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=81, pending=0 toPageIn: 81, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 81, dequeueCount: 0, memUsage:86018, maxPageSize:200
17:34:23.665 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:82 sent to queue://q1
17:34:23.666 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=82, pending=0 toPageIn: 82, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 82, dequeueCount: 0, memUsage:87067, maxPageSize:200
17:34:23.673 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:83 sent to queue://q1
17:34:23.673 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=83, pending=0 toPageIn: 83, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 83, dequeueCount: 0, memUsage:88116, maxPageSize:200
17:34:23.676 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:84 sent to queue://q1
17:34:23.677 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=84, pending=0 toPageIn: 84, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 84, dequeueCount: 0, memUsage:89165, maxPageSize:200
17:34:23.691 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:85 sent to queue://q1
17:34:23.693 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=85, pending=0 toPageIn: 85, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 85, dequeueCount: 0, memUsage:90214, maxPageSize:200
17:34:23.708 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:86 sent to queue://q1
17:34:23.709 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=86, pending=0 toPageIn: 86, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 86, dequeueCount: 0, memUsage:91263, maxPageSize:200
17:34:23.712 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:87 sent to queue://q1
17:34:23.712 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=87, pending=0 toPageIn: 87, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 87, dequeueCount: 0, memUsage:92312, maxPageSize:200
17:34:23.715 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:88 sent to queue://q1
17:34:23.715 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=88, pending=0 toPageIn: 88, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 88, dequeueCount: 0, memUsage:93361, maxPageSize:200
17:34:23.731 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:89 sent to queue://q1
17:34:23.733 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=89, pending=0 toPageIn: 89, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 89, dequeueCount: 0, memUsage:94410, maxPageSize:200
17:34:23.740 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:90 sent to queue://q1
17:34:23.740 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=90, pending=0 toPageIn: 90, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 90, dequeueCount: 0, memUsage:95459, maxPageSize:200
17:34:23.759 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:91 sent to queue://q1
17:34:23.759 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=91, pending=0 toPageIn: 91, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 91, dequeueCount: 0, memUsage:96508, maxPageSize:200
17:34:23.761 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:92 sent to queue://q1
17:34:23.764 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=92, pending=0 toPageIn: 92, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 92, dequeueCount: 0, memUsage:97557, maxPageSize:200
17:34:23.766 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:93 sent to queue://q1
17:34:23.769 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=93, pending=0 toPageIn: 93, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 93, dequeueCount: 0, memUsage:98606, maxPageSize:200
17:34:23.773 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:94 sent to queue://q1
17:34:23.774 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=94, pending=0 toPageIn: 94, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 94, dequeueCount: 0, memUsage:99655, maxPageSize:200
17:34:23.779 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:95 sent to queue://q1
17:34:23.780 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=95, pending=0 toPageIn: 95, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 95, dequeueCount: 0, memUsage:100704, maxPageSize:200
17:34:23.787 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:96 sent to queue://q1
17:34:23.789 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=96, pending=0 toPageIn: 96, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 96, dequeueCount: 0, memUsage:101753, maxPageSize:200
17:34:23.790 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:97 sent to queue://q1
17:34:23.791 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=97, pending=0 toPageIn: 97, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 97, dequeueCount: 0, memUsage:102802, maxPageSize:200
17:34:23.792 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:98 sent to queue://q1
17:34:23.793 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=98, pending=0 toPageIn: 98, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 98, dequeueCount: 0, memUsage:103851, maxPageSize:200
17:34:23.809 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:99 sent to queue://q1
17:34:23.826 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=99, pending=0 toPageIn: 99, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 99, dequeueCount: 0, memUsage:103851, maxPageSize:200
17:34:23.828 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:1:1:100 sent to queue://q1
17:34:23.828 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=100, pending=0 toPageIn: 100, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 0, memUsage:105949, maxPageSize:200
17:34:23.904 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:2:1 for destination: queue://q1
17:34:23.917 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - queue://q1 add sub: QueueSubscription: consumer=ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:2:1, destinations=0, dispatched=0, delivered=0, pending=0, dequeues: 0, dispatched: 0, inflight: 0
17:34:23.918 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=100, pending=0 toPageIn: 100, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 0, memUsage:104900, maxPageSize:200
17:34:23.933 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:23.933 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:23.933 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Consumer.Queue.q1
17:34:23.937 [ActiveMQ Transport: tcp:///127.0.0.1:61618@38926] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Session Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@23f91e8b[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:24.218 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@52bf4c82
17:34:24.256 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=99, pending=0 toPageIn: 0, force:false, Inflight: 99, pagedInMessages.size 99, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 1, memUsage:103851, maxPageSize:200
17:34:24.256 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=99, pending=0 toPageIn: 0, force:false, Inflight: 99, pagedInMessages.size 99, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 1, memUsage:103851, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@205473b6
0
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@52bf4c82
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.jackson#jackson-core-asl;1.9.13 ...[0m
17:34:24.302 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@eff7250
17:34:24.304 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=98, pending=0 toPageIn: 0, force:false, Inflight: 98, pagedInMessages.size 98, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 2, memUsage:102802, maxPageSize:200
17:34:24.304 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=98, pending=0 toPageIn: 0, force:false, Inflight: 98, pagedInMessages.size 98, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 2, memUsage:102802, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@d3569fa
1
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@eff7250
17:34:24.308 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@5bafb523
17:34:24.313 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=97, pending=0 toPageIn: 0, force:false, Inflight: 97, pagedInMessages.size 97, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 3, memUsage:101753, maxPageSize:200
17:34:24.313 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=97, pending=0 toPageIn: 0, force:false, Inflight: 97, pagedInMessages.size 97, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 3, memUsage:101753, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@2d1981ad
2
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@5bafb523
17:34:24.325 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@58010bac
17:34:24.327 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=96, pending=0 toPageIn: 0, force:false, Inflight: 96, pagedInMessages.size 96, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 4, memUsage:100704, maxPageSize:200
17:34:24.327 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=96, pending=0 toPageIn: 0, force:false, Inflight: 96, pagedInMessages.size 96, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 4, memUsage:100704, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@7e5dd3ef
3
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@58010bac
17:34:24.333 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@587d67aa
17:34:24.334 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=95, pending=0 toPageIn: 0, force:false, Inflight: 95, pagedInMessages.size 95, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 5, memUsage:99655, maxPageSize:200
17:34:24.335 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=95, pending=0 toPageIn: 0, force:false, Inflight: 95, pagedInMessages.size 95, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 5, memUsage:99655, maxPageSize:200
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.jackson#jackson-mapper-asl;1.9.13 ...[0m
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@390881e1
4
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@587d67aa
17:34:24.345 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@6984a107
17:34:24.357 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=94, pending=0 toPageIn: 0, force:false, Inflight: 94, pagedInMessages.size 94, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 6, memUsage:98606, maxPageSize:200
17:34:24.357 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=94, pending=0 toPageIn: 0, force:false, Inflight: 94, pagedInMessages.size 94, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 6, memUsage:98606, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@7956c573
5
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@6984a107
17:34:24.365 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@4a25bdc4
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@37df3ae8
6
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@4a25bdc4
17:34:24.366 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@7b1f398d
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@34ad06c0
7
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@7b1f398d
17:34:24.367 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@1d472efe
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@1f96af8a
8
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@1d472efe
17:34:24.368 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@435131be
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@1ab9beee
9
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@435131be
17:34:24.368 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@3ead5399
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@14ed4139
10
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@3ead5399
17:34:24.369 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@5efb4edb
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@962c524
11
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@5efb4edb
17:34:24.369 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@5d077e0a
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@231d081a
12
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@5d077e0a
17:34:24.370 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@27141734
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@38c0ad17
13
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@27141734
17:34:24.371 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@1547ed33
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@12edf518
14
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@1547ed33
17:34:24.372 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@2f784a47
17:34:24.388 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=93, pending=0 toPageIn: 0, force:false, Inflight: 92, pagedInMessages.size 93, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 7, memUsage:97557, maxPageSize:200
17:34:24.388 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=93, pending=0 toPageIn: 0, force:false, Inflight: 92, pagedInMessages.size 93, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 7, memUsage:97557, maxPageSize:200
17:34:24.391 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=92, pending=0 toPageIn: 0, force:false, Inflight: 91, pagedInMessages.size 92, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 8, memUsage:96508, maxPageSize:200
17:34:24.391 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=92, pending=0 toPageIn: 0, force:false, Inflight: 91, pagedInMessages.size 92, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 8, memUsage:96508, maxPageSize:200
17:34:24.399 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=91, pending=0 toPageIn: 0, force:false, Inflight: 90, pagedInMessages.size 91, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 9, memUsage:95459, maxPageSize:200
17:34:24.399 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=91, pending=0 toPageIn: 0, force:false, Inflight: 90, pagedInMessages.size 91, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 9, memUsage:95459, maxPageSize:200
17:34:24.401 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=90, pending=0 toPageIn: 0, force:false, Inflight: 89, pagedInMessages.size 90, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 10, memUsage:94410, maxPageSize:200
17:34:24.401 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=90, pending=0 toPageIn: 0, force:false, Inflight: 89, pagedInMessages.size 90, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 10, memUsage:94410, maxPageSize:200
17:34:24.405 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=89, pending=0 toPageIn: 0, force:false, Inflight: 89, pagedInMessages.size 89, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 11, memUsage:93361, maxPageSize:200
17:34:24.406 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=89, pending=0 toPageIn: 0, force:false, Inflight: 89, pagedInMessages.size 89, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 11, memUsage:93361, maxPageSize:200
17:34:24.408 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=88, pending=0 toPageIn: 0, force:false, Inflight: 87, pagedInMessages.size 88, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 12, memUsage:92312, maxPageSize:200
17:34:24.408 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=88, pending=0 toPageIn: 0, force:false, Inflight: 87, pagedInMessages.size 88, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 12, memUsage:92312, maxPageSize:200
17:34:24.410 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=87, pending=0 toPageIn: 0, force:false, Inflight: 86, pagedInMessages.size 87, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 13, memUsage:91263, maxPageSize:200
17:34:24.410 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=87, pending=0 toPageIn: 0, force:false, Inflight: 86, pagedInMessages.size 87, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 13, memUsage:91263, maxPageSize:200
17:34:24.412 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=86, pending=0 toPageIn: 0, force:false, Inflight: 85, pagedInMessages.size 86, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 14, memUsage:90214, maxPageSize:200
17:34:24.412 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=86, pending=0 toPageIn: 0, force:false, Inflight: 85, pagedInMessages.size 86, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 14, memUsage:90214, maxPageSize:200
17:34:24.413 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=85, pending=0 toPageIn: 0, force:false, Inflight: 84, pagedInMessages.size 85, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 15, memUsage:89165, maxPageSize:200
17:34:24.414 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=85, pending=0 toPageIn: 0, force:false, Inflight: 84, pagedInMessages.size 85, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 15, memUsage:89165, maxPageSize:200
17:34:24.419 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=84, pending=0 toPageIn: 0, force:false, Inflight: 84, pagedInMessages.size 84, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 16, memUsage:88116, maxPageSize:200
17:34:24.419 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=84, pending=0 toPageIn: 0, force:false, Inflight: 84, pagedInMessages.size 84, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 16, memUsage:88116, maxPageSize:200
[A[2K[0m[[0minfo[0m] [0mResolving com.thoughtworks.paranamer#paranamer;2.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.thoughtworks.paranamer#paranamer;2.7 ...[0m
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@409e5f1d
15
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@2f784a47
17:34:24.431 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@13cd2bca
17:34:24.434 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=83, pending=0 toPageIn: 0, force:false, Inflight: 83, pagedInMessages.size 83, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 17, memUsage:87067, maxPageSize:200
17:34:24.434 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=83, pending=0 toPageIn: 0, force:false, Inflight: 83, pagedInMessages.size 83, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 17, memUsage:87067, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@4832f579
16
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@13cd2bca
17:34:24.437 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@2d9abbe6
17:34:24.439 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=82, pending=0 toPageIn: 0, force:false, Inflight: 82, pagedInMessages.size 82, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 18, memUsage:86018, maxPageSize:200
17:34:24.439 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=82, pending=0 toPageIn: 0, force:false, Inflight: 82, pagedInMessages.size 82, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 18, memUsage:86018, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@1fce6fff
17
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@2d9abbe6
17:34:24.464 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@65a784b7
17:34:24.470 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=81, pending=0 toPageIn: 0, force:false, Inflight: 81, pagedInMessages.size 81, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 19, memUsage:84969, maxPageSize:200
17:34:24.470 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=81, pending=0 toPageIn: 0, force:false, Inflight: 81, pagedInMessages.size 81, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 19, memUsage:84969, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@3a613c47
18
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@65a784b7
[A[2K[0m[[0minfo[0m] [0mResolving com.thoughtworks.paranamer#paranamer-parent;2.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.thoughtworks.paranamer#paranamer-parent;2.7 ...[0m
17:34:24.478 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@42dce566
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@2e01cb55
19
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@42dce566
17:34:24.484 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@775a701e
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@446ae9b6
20
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@775a701e
17:34:24.485 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=80, pending=0 toPageIn: 0, force:false, Inflight: 79, pagedInMessages.size 80, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 20, memUsage:83920, maxPageSize:200
17:34:24.485 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
17:34:24.485 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=80, pending=0 toPageIn: 0, force:false, Inflight: 79, pagedInMessages.size 80, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 20, memUsage:83920, maxPageSize:200
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@6138c388
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@4143e799
21
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@6138c388
17:34:24.486 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@65bda52f
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@7689c777
22
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@65bda52f
17:34:24.488 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=77, pending=0 toPageIn: 0, force:false, Inflight: 77, pagedInMessages.size 77, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 23, memUsage:80773, maxPageSize:200
17:34:24.488 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=77, pending=0 toPageIn: 0, force:false, Inflight: 77, pagedInMessages.size 77, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 23, memUsage:80773, maxPageSize:200
17:34:24.489 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=77, pending=0 toPageIn: 0, force:false, Inflight: 77, pagedInMessages.size 77, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 23, memUsage:80773, maxPageSize:200
17:34:24.489 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
17:34:24.489 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=77, pending=0 toPageIn: 0, force:false, Inflight: 77, pagedInMessages.size 77, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 23, memUsage:80773, maxPageSize:200
17:34:24.489 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=77, pending=0 toPageIn: 0, force:false, Inflight: 77, pagedInMessages.size 77, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 23, memUsage:80773, maxPageSize:200
17:34:24.489 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=77, pending=0 toPageIn: 0, force:false, Inflight: 77, pagedInMessages.size 77, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 23, memUsage:80773, maxPageSize:200
17:34:24.490 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=77, pending=0 toPageIn: 0, force:false, Inflight: 77, pagedInMessages.size 77, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 23, memUsage:80773, maxPageSize:200
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@518a7ead
17:34:24.491 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=76, pending=0 toPageIn: 0, force:false, Inflight: 76, pagedInMessages.size 76, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 24, memUsage:79724, maxPageSize:200
17:34:24.491 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=76, pending=0 toPageIn: 0, force:false, Inflight: 76, pagedInMessages.size 76, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 24, memUsage:79724, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@f2b342a
23
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@518a7ead
17:34:24.493 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@7b77c3d
17:34:24.495 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=75, pending=0 toPageIn: 0, force:false, Inflight: 75, pagedInMessages.size 75, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 25, memUsage:78675, maxPageSize:200
17:34:24.495 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=75, pending=0 toPageIn: 0, force:false, Inflight: 75, pagedInMessages.size 75, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 25, memUsage:78675, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@3fbdb1c3
24
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@7b77c3d
17:34:24.497 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@3d40cf8f
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@6b9c2669
25
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@3d40cf8f
17:34:24.500 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@5776e9b3
17:34:24.501 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=74, pending=0 toPageIn: 0, force:false, Inflight: 74, pagedInMessages.size 74, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 26, memUsage:77626, maxPageSize:200
17:34:24.501 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=74, pending=0 toPageIn: 0, force:false, Inflight: 74, pagedInMessages.size 74, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 26, memUsage:77626, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@5176937
26
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@5776e9b3
17:34:24.502 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=73, pending=0 toPageIn: 0, force:false, Inflight: 73, pagedInMessages.size 73, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 27, memUsage:76577, maxPageSize:200
17:34:24.503 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=73, pending=0 toPageIn: 0, force:false, Inflight: 73, pagedInMessages.size 73, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 27, memUsage:76577, maxPageSize:200
17:34:24.503 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@3e10f2ad
17:34:24.505 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=72, pending=0 toPageIn: 0, force:false, Inflight: 72, pagedInMessages.size 72, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 28, memUsage:75528, maxPageSize:200
17:34:24.505 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=72, pending=0 toPageIn: 0, force:false, Inflight: 72, pagedInMessages.size 72, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 28, memUsage:75528, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@34352468
27
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@3e10f2ad
17:34:24.506 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@546e682c
17:34:24.516 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=71, pending=0 toPageIn: 0, force:false, Inflight: 71, pagedInMessages.size 71, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 29, memUsage:74479, maxPageSize:200
17:34:24.516 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=71, pending=0 toPageIn: 0, force:false, Inflight: 71, pagedInMessages.size 71, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 29, memUsage:74479, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@6a0eed47
28
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@546e682c
17:34:24.521 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@53b2ff31
17:34:24.523 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=70, pending=0 toPageIn: 0, force:false, Inflight: 70, pagedInMessages.size 70, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 30, memUsage:73430, maxPageSize:200
17:34:24.523 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=70, pending=0 toPageIn: 0, force:false, Inflight: 70, pagedInMessages.size 70, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 30, memUsage:73430, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@4e39874b
29
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@53b2ff31
17:34:24.525 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@30c737d3
17:34:24.538 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=69, pending=0 toPageIn: 0, force:false, Inflight: 69, pagedInMessages.size 69, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 31, memUsage:72381, maxPageSize:200
17:34:24.538 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=69, pending=0 toPageIn: 0, force:false, Inflight: 69, pagedInMessages.size 69, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 31, memUsage:72381, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@32c6ed5f
30
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@30c737d3
17:34:24.539 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@565eee56
17:34:24.540 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=68, pending=0 toPageIn: 0, force:false, Inflight: 68, pagedInMessages.size 68, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 32, memUsage:71332, maxPageSize:200
17:34:24.544 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=68, pending=0 toPageIn: 0, force:false, Inflight: 68, pagedInMessages.size 68, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 32, memUsage:71332, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@620af174
31
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@565eee56
17:34:24.547 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@6b7a3b49
17:34:24.562 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=67, pending=0 toPageIn: 0, force:false, Inflight: 67, pagedInMessages.size 67, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 33, memUsage:70283, maxPageSize:200
17:34:24.562 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=67, pending=0 toPageIn: 0, force:false, Inflight: 67, pagedInMessages.size 67, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 33, memUsage:70283, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@6ed39f6c
32
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@6b7a3b49
17:34:24.563 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@4f5ef0be
17:34:24.566 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=66, pending=0 toPageIn: 0, force:false, Inflight: 66, pagedInMessages.size 66, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 34, memUsage:69234, maxPageSize:200
17:34:24.566 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=66, pending=0 toPageIn: 0, force:false, Inflight: 66, pagedInMessages.size 66, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 34, memUsage:69234, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@7a6a2970
33
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@4f5ef0be
17:34:24.567 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@40f0e507
17:34:24.568 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=65, pending=0 toPageIn: 0, force:false, Inflight: 65, pagedInMessages.size 65, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 35, memUsage:68185, maxPageSize:200
17:34:24.569 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=65, pending=0 toPageIn: 0, force:false, Inflight: 65, pagedInMessages.size 65, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 35, memUsage:68185, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@32aa2a8a
34
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@40f0e507
17:34:24.569 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@ac9e761
17:34:24.570 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=64, pending=0 toPageIn: 0, force:false, Inflight: 64, pagedInMessages.size 64, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 36, memUsage:67136, maxPageSize:200
17:34:24.571 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=64, pending=0 toPageIn: 0, force:false, Inflight: 64, pagedInMessages.size 64, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 36, memUsage:67136, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@21436ee1
35
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@ac9e761
17:34:24.581 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@66dc7f13
17:34:24.592 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=63, pending=0 toPageIn: 0, force:false, Inflight: 63, pagedInMessages.size 63, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 37, memUsage:66087, maxPageSize:200
17:34:24.593 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=63, pending=0 toPageIn: 0, force:false, Inflight: 63, pagedInMessages.size 63, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 37, memUsage:66087, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@5c1e738
36
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@66dc7f13
17:34:24.601 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@4076fa0e
17:34:24.609 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=62, pending=0 toPageIn: 0, force:false, Inflight: 62, pagedInMessages.size 62, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 38, memUsage:65038, maxPageSize:200
17:34:24.609 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=62, pending=0 toPageIn: 0, force:false, Inflight: 62, pagedInMessages.size 62, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 38, memUsage:65038, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@7af8a087
37
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@4076fa0e
17:34:24.611 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@7fd97c2c
17:34:24.612 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=61, pending=0 toPageIn: 0, force:false, Inflight: 61, pagedInMessages.size 61, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 39, memUsage:63989, maxPageSize:200
17:34:24.612 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=61, pending=0 toPageIn: 0, force:false, Inflight: 61, pagedInMessages.size 61, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 39, memUsage:63989, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@752bbcc8
38
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@7fd97c2c
17:34:24.613 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@27a8ee9
17:34:24.614 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=60, pending=0 toPageIn: 0, force:false, Inflight: 60, pagedInMessages.size 60, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 40, memUsage:62940, maxPageSize:200
17:34:24.614 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=60, pending=0 toPageIn: 0, force:false, Inflight: 60, pagedInMessages.size 60, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 40, memUsage:62940, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@3db9eab9
39
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@27a8ee9
17:34:24.615 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@9b5c93e
17:34:24.616 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=59, pending=0 toPageIn: 0, force:false, Inflight: 59, pagedInMessages.size 59, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 41, memUsage:61891, maxPageSize:200
17:34:24.617 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=59, pending=0 toPageIn: 0, force:false, Inflight: 59, pagedInMessages.size 59, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 41, memUsage:61891, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@21d0f93c
40
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@9b5c93e
17:34:24.625 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@770b2629
17:34:24.627 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=58, pending=0 toPageIn: 0, force:false, Inflight: 58, pagedInMessages.size 58, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 42, memUsage:60842, maxPageSize:200
17:34:24.628 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=58, pending=0 toPageIn: 0, force:false, Inflight: 58, pagedInMessages.size 58, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 42, memUsage:60842, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@515e653
41
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@770b2629
17:34:24.629 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@224e33f6
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@471379a
42
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@224e33f6
17:34:24.639 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=57, pending=0 toPageIn: 0, force:false, Inflight: 57, pagedInMessages.size 57, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 43, memUsage:59793, maxPageSize:200
17:34:24.649 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=57, pending=0 toPageIn: 0, force:false, Inflight: 57, pagedInMessages.size 57, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 43, memUsage:59793, maxPageSize:200
17:34:24.641 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@2a656353
17:34:24.651 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=56, pending=0 toPageIn: 0, force:false, Inflight: 56, pagedInMessages.size 56, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 44, memUsage:58744, maxPageSize:200
17:34:24.651 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=56, pending=0 toPageIn: 0, force:false, Inflight: 56, pagedInMessages.size 56, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 44, memUsage:58744, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@683f32
43
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@2a656353
17:34:24.651 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@53ea6d4a
17:34:24.652 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=55, pending=0 toPageIn: 0, force:false, Inflight: 55, pagedInMessages.size 55, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 45, memUsage:57695, maxPageSize:200
17:34:24.652 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=55, pending=0 toPageIn: 0, force:false, Inflight: 55, pagedInMessages.size 55, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 45, memUsage:57695, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@5eaa4d4a
44
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@53ea6d4a
17:34:24.653 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@5fd4d237
17:34:24.654 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=54, pending=0 toPageIn: 0, force:false, Inflight: 54, pagedInMessages.size 54, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 46, memUsage:56646, maxPageSize:200
17:34:24.655 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=54, pending=0 toPageIn: 0, force:false, Inflight: 54, pagedInMessages.size 54, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 46, memUsage:56646, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@1e04f750
45
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@5fd4d237
17:34:24.655 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@1e8459e7
17:34:24.656 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=53, pending=0 toPageIn: 0, force:false, Inflight: 53, pagedInMessages.size 53, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 47, memUsage:55597, maxPageSize:200
17:34:24.656 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=53, pending=0 toPageIn: 0, force:false, Inflight: 53, pagedInMessages.size 53, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 47, memUsage:55597, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@12c89760
46
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@1e8459e7
17:34:24.658 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@6bf4ba64
17:34:24.660 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=52, pending=0 toPageIn: 0, force:false, Inflight: 52, pagedInMessages.size 52, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 48, memUsage:54548, maxPageSize:200
17:34:24.661 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=52, pending=0 toPageIn: 0, force:false, Inflight: 52, pagedInMessages.size 52, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 48, memUsage:54548, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@52f37e3d
47
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@6bf4ba64
17:34:24.661 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@6e044ee5
17:34:24.662 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=51, pending=0 toPageIn: 0, force:false, Inflight: 51, pagedInMessages.size 51, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 49, memUsage:53499, maxPageSize:200
17:34:24.663 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=51, pending=0 toPageIn: 0, force:false, Inflight: 51, pagedInMessages.size 51, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 49, memUsage:53499, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@3821a7d2
48
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@6e044ee5
17:34:24.671 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@76c81d28
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus#codehaus-parent;4 ...[0m
17:34:24.678 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=50, pending=0 toPageIn: 0, force:false, Inflight: 50, pagedInMessages.size 50, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 50, memUsage:52450, maxPageSize:200
17:34:24.678 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=50, pending=0 toPageIn: 0, force:false, Inflight: 50, pagedInMessages.size 50, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 50, memUsage:52450, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@3f83975a
49
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@76c81d28
17:34:24.688 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@73bc9529
17:34:24.693 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=49, pending=0 toPageIn: 0, force:false, Inflight: 49, pagedInMessages.size 49, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 51, memUsage:51401, maxPageSize:200
17:34:24.694 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=49, pending=0 toPageIn: 0, force:false, Inflight: 49, pagedInMessages.size 49, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 51, memUsage:51401, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@4696a3bb
50
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@73bc9529
17:34:24.708 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@7001c71c
17:34:24.719 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=48, pending=0 toPageIn: 0, force:false, Inflight: 48, pagedInMessages.size 48, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 52, memUsage:50352, maxPageSize:200
17:34:24.719 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=48, pending=0 toPageIn: 0, force:false, Inflight: 48, pagedInMessages.size 48, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 52, memUsage:50352, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@539bb701
51
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@7001c71c
17:34:24.734 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@44996586
17:34:24.738 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=47, pending=0 toPageIn: 0, force:false, Inflight: 47, pagedInMessages.size 47, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 53, memUsage:49303, maxPageSize:200
17:34:24.739 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=47, pending=0 toPageIn: 0, force:false, Inflight: 47, pagedInMessages.size 47, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 53, memUsage:49303, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@37618dd5
52
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@44996586
17:34:24.741 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@49268502
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@470b0098
53
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@49268502
17:34:24.742 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@48b1f8aa
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@7305cb4c
54
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@48b1f8aa
17:34:24.744 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@ef65ebb
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@1166803d
55
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@ef65ebb
17:34:24.746 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@56555e13
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@b57a03e
56
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@56555e13
17:34:24.750 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@37682469
17:34:24.751 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=46, pending=0 toPageIn: 0, force:false, Inflight: 46, pagedInMessages.size 46, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 54, memUsage:48254, maxPageSize:200
17:34:24.752 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=46, pending=0 toPageIn: 0, force:false, Inflight: 45, pagedInMessages.size 46, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 54, memUsage:48254, maxPageSize:200
17:34:24.752 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=45, pending=0 toPageIn: 0, force:false, Inflight: 45, pagedInMessages.size 45, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 55, memUsage:47205, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@122a2dd1
57
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@37682469
17:34:24.753 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=45, pending=0 toPageIn: 0, force:false, Inflight: 45, pagedInMessages.size 45, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 55, memUsage:47205, maxPageSize:200
17:34:24.754 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@6e734c41
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@589357e1
58
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@6e734c41
17:34:24.758 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=44, pending=0 toPageIn: 0, force:false, Inflight: 44, pagedInMessages.size 44, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 56, memUsage:46156, maxPageSize:200
17:34:24.758 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=44, pending=0 toPageIn: 0, force:false, Inflight: 44, pagedInMessages.size 44, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 56, memUsage:46156, maxPageSize:200
17:34:24.759 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=43, pending=0 toPageIn: 0, force:false, Inflight: 43, pagedInMessages.size 43, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 57, memUsage:45107, maxPageSize:200
17:34:24.759 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@2eae7bf6
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@6da99f57
17:34:24.762 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=43, pending=0 toPageIn: 0, force:false, Inflight: 43, pagedInMessages.size 43, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 57, memUsage:45107, maxPageSize:200
59
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@2eae7bf6
17:34:24.765 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@19ccc7e7
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@5b22b760
60
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@19ccc7e7
17:34:24.768 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@60e1639
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@277c7288
61
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@60e1639
17:34:24.770 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
17:34:24.771 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=42, pending=0 toPageIn: 0, force:false, Inflight: 42, pagedInMessages.size 42, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 58, memUsage:44058, maxPageSize:200
17:34:24.771 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=41, pending=0 toPageIn: 0, force:false, Inflight: 40, pagedInMessages.size 41, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 59, memUsage:43009, maxPageSize:200
17:34:24.771 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=41, pending=0 toPageIn: 0, force:false, Inflight: 40, pagedInMessages.size 41, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 59, memUsage:43009, maxPageSize:200
17:34:24.772 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=41, pending=0 toPageIn: 0, force:false, Inflight: 40, pagedInMessages.size 41, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 59, memUsage:43009, maxPageSize:200
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@58f06a7f
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@16a75fb6
62
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@58f06a7f
17:34:24.776 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=41, pending=0 toPageIn: 0, force:false, Inflight: 40, pagedInMessages.size 41, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 59, memUsage:43009, maxPageSize:200
17:34:24.776 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
17:34:24.780 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=40, pending=0 toPageIn: 0, force:false, Inflight: 40, pagedInMessages.size 40, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 60, memUsage:41960, maxPageSize:200
17:34:24.780 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=40, pending=0 toPageIn: 0, force:false, Inflight: 39, pagedInMessages.size 40, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 60, memUsage:41960, maxPageSize:200
17:34:24.780 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=39, pending=0 toPageIn: 0, force:false, Inflight: 39, pagedInMessages.size 39, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 61, memUsage:40911, maxPageSize:200
17:34:24.781 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=39, pending=0 toPageIn: 0, force:false, Inflight: 39, pagedInMessages.size 39, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 61, memUsage:40911, maxPageSize:200
17:34:24.781 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=38, pending=0 toPageIn: 0, force:false, Inflight: 38, pagedInMessages.size 38, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 62, memUsage:39862, maxPageSize:200
17:34:24.781 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=38, pending=0 toPageIn: 0, force:false, Inflight: 38, pagedInMessages.size 38, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 62, memUsage:39862, maxPageSize:200
17:34:24.782 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=37, pending=0 toPageIn: 0, force:false, Inflight: 37, pagedInMessages.size 37, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 63, memUsage:38813, maxPageSize:200
17:34:24.782 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=37, pending=0 toPageIn: 0, force:false, Inflight: 37, pagedInMessages.size 37, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 63, memUsage:38813, maxPageSize:200
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@60ee3c85
17:34:24.806 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=36, pending=0 toPageIn: 0, force:false, Inflight: 36, pagedInMessages.size 36, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 64, memUsage:37764, maxPageSize:200
17:34:24.806 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=36, pending=0 toPageIn: 0, force:false, Inflight: 36, pagedInMessages.size 36, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 64, memUsage:37764, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@2442fa22
63
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@60ee3c85
17:34:24.809 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@7fbadf47
17:34:24.810 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=35, pending=0 toPageIn: 0, force:false, Inflight: 35, pagedInMessages.size 35, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 65, memUsage:36715, maxPageSize:200
17:34:24.810 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=35, pending=0 toPageIn: 0, force:false, Inflight: 35, pagedInMessages.size 35, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 65, memUsage:36715, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@53cc75e9
64
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@7fbadf47
17:34:24.811 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@42577101
17:34:24.812 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=34, pending=0 toPageIn: 0, force:false, Inflight: 34, pagedInMessages.size 34, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 66, memUsage:35666, maxPageSize:200
17:34:24.812 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=34, pending=0 toPageIn: 0, force:false, Inflight: 34, pagedInMessages.size 34, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 66, memUsage:35666, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@71770083
65
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@42577101
17:34:24.812 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@581eb90d
17:34:24.813 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=33, pending=0 toPageIn: 0, force:false, Inflight: 33, pagedInMessages.size 33, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 67, memUsage:34617, maxPageSize:200
17:34:24.814 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=33, pending=0 toPageIn: 0, force:false, Inflight: 33, pagedInMessages.size 33, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 67, memUsage:34617, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@68cdfcda
66
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@581eb90d
17:34:24.814 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@11eb57bb
17:34:24.815 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=32, pending=0 toPageIn: 0, force:false, Inflight: 32, pagedInMessages.size 32, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 68, memUsage:33568, maxPageSize:200
17:34:24.815 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=32, pending=0 toPageIn: 0, force:false, Inflight: 32, pagedInMessages.size 32, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 68, memUsage:33568, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@58d12e1d
67
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@11eb57bb
17:34:24.816 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@752a32db
17:34:24.817 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=31, pending=0 toPageIn: 0, force:false, Inflight: 31, pagedInMessages.size 31, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 69, memUsage:32519, maxPageSize:200
17:34:24.817 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=31, pending=0 toPageIn: 0, force:false, Inflight: 31, pagedInMessages.size 31, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 69, memUsage:32519, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@72062b88
68
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@752a32db
17:34:24.817 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@399becfc
17:34:24.818 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=30, pending=0 toPageIn: 0, force:false, Inflight: 30, pagedInMessages.size 30, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 70, memUsage:31470, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@686b8c14
69
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@399becfc
17:34:24.818 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=30, pending=0 toPageIn: 0, force:false, Inflight: 30, pagedInMessages.size 30, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 70, memUsage:31470, maxPageSize:200
17:34:24.819 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@4c73d728
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@feaff45
70
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@4c73d728
17:34:24.819 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=29, pending=0 toPageIn: 0, force:false, Inflight: 29, pagedInMessages.size 29, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 71, memUsage:30421, maxPageSize:200
17:34:24.820 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=29, pending=0 toPageIn: 0, force:false, Inflight: 29, pagedInMessages.size 29, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 71, memUsage:30421, maxPageSize:200
17:34:24.820 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@69f00e48
17:34:24.821 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=28, pending=0 toPageIn: 0, force:false, Inflight: 28, pagedInMessages.size 28, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 72, memUsage:29372, maxPageSize:200
17:34:24.822 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=28, pending=0 toPageIn: 0, force:false, Inflight: 28, pagedInMessages.size 28, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 72, memUsage:29372, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@5dcf344e
71
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@69f00e48
17:34:24.822 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@f577248
17:34:24.824 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=27, pending=0 toPageIn: 0, force:false, Inflight: 27, pagedInMessages.size 27, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 73, memUsage:28323, maxPageSize:200
17:34:24.824 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=27, pending=0 toPageIn: 0, force:false, Inflight: 27, pagedInMessages.size 27, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 73, memUsage:28323, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@571fa430
72
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@f577248
17:34:24.825 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@3ef472d5
17:34:24.826 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=26, pending=0 toPageIn: 0, force:false, Inflight: 26, pagedInMessages.size 26, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 74, memUsage:27274, maxPageSize:200
17:34:24.826 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=26, pending=0 toPageIn: 0, force:false, Inflight: 26, pagedInMessages.size 26, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 74, memUsage:27274, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@1a3d4c01
73
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@3ef472d5
17:34:24.827 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@2eccb83c
17:34:24.828 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=25, pending=0 toPageIn: 0, force:false, Inflight: 25, pagedInMessages.size 25, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 75, memUsage:26225, maxPageSize:200
17:34:24.828 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=25, pending=0 toPageIn: 0, force:false, Inflight: 25, pagedInMessages.size 25, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 75, memUsage:26225, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@4d8a7f1
74
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@2eccb83c
17:34:24.829 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@19a71f65
17:34:24.830 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=24, pending=0 toPageIn: 0, force:false, Inflight: 24, pagedInMessages.size 24, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 76, memUsage:25176, maxPageSize:200
17:34:24.831 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=24, pending=0 toPageIn: 0, force:false, Inflight: 24, pagedInMessages.size 24, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 76, memUsage:25176, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@690a0514
75
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@19a71f65
17:34:24.832 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@224c4d51
17:34:24.833 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=23, pending=0 toPageIn: 0, force:false, Inflight: 23, pagedInMessages.size 23, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 77, memUsage:24127, maxPageSize:200
17:34:24.833 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=23, pending=0 toPageIn: 0, force:false, Inflight: 23, pagedInMessages.size 23, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 77, memUsage:24127, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@636a91c6
76
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@224c4d51
17:34:24.834 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@4217f6f9
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@7b8c790a
77
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@4217f6f9
17:34:24.836 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@3b6a85ef
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@cb9c7e5
78
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@3b6a85ef
17:34:24.837 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@71e458b5
17:34:24.844 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=22, pending=0 toPageIn: 0, force:false, Inflight: 21, pagedInMessages.size 22, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 78, memUsage:23078, maxPageSize:200
17:34:24.844 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=22, pending=0 toPageIn: 0, force:false, Inflight: 21, pagedInMessages.size 22, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 78, memUsage:23078, maxPageSize:200
17:34:24.854 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=21, pending=0 toPageIn: 0, force:false, Inflight: 21, pagedInMessages.size 21, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 79, memUsage:22029, maxPageSize:200
17:34:24.854 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=21, pending=0 toPageIn: 0, force:false, Inflight: 21, pagedInMessages.size 21, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 79, memUsage:22029, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@69382baa
79
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@71e458b5
17:34:24.856 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@6129e9f
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@4456f757
80
17:34:24.862 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=20, pending=0 toPageIn: 0, force:false, Inflight: 20, pagedInMessages.size 20, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 80, memUsage:20980, maxPageSize:200
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@6129e9f
17:34:24.863 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=20, pending=0 toPageIn: 0, force:false, Inflight: 20, pagedInMessages.size 20, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 80, memUsage:20980, maxPageSize:200
17:34:24.865 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=19, pending=0 toPageIn: 0, force:false, Inflight: 19, pagedInMessages.size 19, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 81, memUsage:19931, maxPageSize:200
17:34:24.865 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=19, pending=0 toPageIn: 0, force:false, Inflight: 19, pagedInMessages.size 19, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 81, memUsage:19931, maxPageSize:200
17:34:24.866 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@17a43e98
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@3f6922bd
81
17:34:24.872 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=18, pending=0 toPageIn: 0, force:false, Inflight: 18, pagedInMessages.size 18, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 82, memUsage:18882, maxPageSize:200
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@17a43e98
17:34:24.872 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=18, pending=0 toPageIn: 0, force:false, Inflight: 18, pagedInMessages.size 18, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 82, memUsage:18882, maxPageSize:200
17:34:24.872 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@2d1db5a9
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@5e821312
82
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@2d1db5a9
17:34:24.873 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@68e4b6a4
17:34:24.873 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=17, pending=0 toPageIn: 0, force:false, Inflight: 17, pagedInMessages.size 17, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 83, memUsage:17833, maxPageSize:200
17:34:24.873 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=17, pending=0 toPageIn: 0, force:false, Inflight: 16, pagedInMessages.size 17, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 83, memUsage:17833, maxPageSize:200
17:34:24.873 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=16, pending=0 toPageIn: 0, force:false, Inflight: 16, pagedInMessages.size 16, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 84, memUsage:16784, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@1e6e0dcf
83
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@68e4b6a4
17:34:24.873 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
17:34:24.875 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=16, pending=0 toPageIn: 0, force:false, Inflight: 16, pagedInMessages.size 16, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 84, memUsage:16784, maxPageSize:200
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@5e1e5356
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@104ac104
84
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@5e1e5356
17:34:24.877 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=15, pending=0 toPageIn: 0, force:false, Inflight: 15, pagedInMessages.size 15, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 85, memUsage:15735, maxPageSize:200
17:34:24.878 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
17:34:24.878 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=15, pending=0 toPageIn: 0, force:false, Inflight: 15, pagedInMessages.size 15, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 85, memUsage:15735, maxPageSize:200
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@5d56043f
17:34:24.879 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=14, pending=0 toPageIn: 0, force:false, Inflight: 14, pagedInMessages.size 14, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 86, memUsage:14686, maxPageSize:200
17:34:24.879 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=14, pending=0 toPageIn: 0, force:false, Inflight: 14, pagedInMessages.size 14, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 86, memUsage:14686, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@33b87a2f
85
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@5d56043f
17:34:24.880 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@1f900bed
17:34:24.881 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=13, pending=0 toPageIn: 0, force:false, Inflight: 13, pagedInMessages.size 13, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 87, memUsage:13637, maxPageSize:200
17:34:24.881 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=13, pending=0 toPageIn: 0, force:false, Inflight: 13, pagedInMessages.size 13, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 87, memUsage:13637, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@5994abfa
86
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@1f900bed
17:34:24.882 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@340e2b0b
17:34:24.883 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=12, pending=0 toPageIn: 0, force:false, Inflight: 12, pagedInMessages.size 12, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 88, memUsage:12588, maxPageSize:200
17:34:24.884 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=12, pending=0 toPageIn: 0, force:false, Inflight: 12, pagedInMessages.size 12, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 88, memUsage:12588, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@441756a7
87
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@340e2b0b
17:34:24.885 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@5b47e2ab
17:34:24.886 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=11, pending=0 toPageIn: 0, force:false, Inflight: 11, pagedInMessages.size 11, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 89, memUsage:11539, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@27705942
88
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@5b47e2ab
17:34:24.886 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@62e368d4
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@1c3fa841
89
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@62e368d4
17:34:24.888 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
17:34:24.888 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 0, force:false, Inflight: 10, pagedInMessages.size 10, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 90, memUsage:10490, maxPageSize:200
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@780943d7
17:34:24.888 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 0, force:false, Inflight: 10, pagedInMessages.size 10, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 90, memUsage:10490, maxPageSize:200
17:34:24.888 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 0, force:false, Inflight: 10, pagedInMessages.size 10, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 90, memUsage:10490, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@5d96bfdd
90
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@780943d7
17:34:24.889 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@244ad973
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@45d6001b
91
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@244ad973
17:34:24.890 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@77f3f48d
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@1f73d5f9
92
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@77f3f48d
17:34:24.900 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 8, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 91, memUsage:9441, maxPageSize:200
17:34:24.901 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 8, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 91, memUsage:9441, maxPageSize:200
17:34:24.901 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
17:34:24.901 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=7, pending=0 toPageIn: 0, force:false, Inflight: 7, pagedInMessages.size 7, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 93, memUsage:7343, maxPageSize:200
17:34:24.901 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=7, pending=0 toPageIn: 0, force:false, Inflight: 7, pagedInMessages.size 7, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 93, memUsage:7343, maxPageSize:200
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@6d801625
17:34:24.902 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=7, pending=0 toPageIn: 0, force:false, Inflight: 7, pagedInMessages.size 7, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 93, memUsage:7343, maxPageSize:200
17:34:24.902 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=7, pending=0 toPageIn: 0, force:false, Inflight: 7, pagedInMessages.size 7, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 93, memUsage:7343, maxPageSize:200
17:34:24.908 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=6, pending=0 toPageIn: 0, force:false, Inflight: 6, pagedInMessages.size 6, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 94, memUsage:6294, maxPageSize:200
17:34:24.908 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=6, pending=0 toPageIn: 0, force:false, Inflight: 6, pagedInMessages.size 6, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 94, memUsage:6294, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@18231556
93
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@6d801625
17:34:24.913 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@701cdd43
17:34:24.914 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=5, pending=0 toPageIn: 0, force:false, Inflight: 5, pagedInMessages.size 5, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 95, memUsage:5245, maxPageSize:200
17:34:24.914 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=5, pending=0 toPageIn: 0, force:false, Inflight: 5, pagedInMessages.size 5, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 95, memUsage:5245, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@714112a4
94
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@701cdd43
17:34:24.918 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@1c1d0397
17:34:24.934 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=4, pending=0 toPageIn: 0, force:false, Inflight: 4, pagedInMessages.size 4, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 96, memUsage:4196, maxPageSize:200
17:34:24.934 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=4, pending=0 toPageIn: 0, force:false, Inflight: 4, pagedInMessages.size 4, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 96, memUsage:4196, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@1c943ce7
95
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@1c1d0397
17:34:24.935 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@af41cf3
17:34:24.936 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=3, pending=0 toPageIn: 0, force:false, Inflight: 3, pagedInMessages.size 3, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 97, memUsage:3147, maxPageSize:200
17:34:24.936 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=3, pending=0 toPageIn: 0, force:false, Inflight: 3, pagedInMessages.size 3, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 97, memUsage:3147, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@73d9fb3b
96
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@af41cf3
17:34:24.936 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@7ac5f6c
17:34:24.937 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=2, pending=0 toPageIn: 0, force:false, Inflight: 2, pagedInMessages.size 2, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 98, memUsage:2098, maxPageSize:200
17:34:24.937 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=2, pending=0 toPageIn: 0, force:false, Inflight: 2, pagedInMessages.size 2, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 98, memUsage:2098, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@3ae2387a
97
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@7ac5f6c
17:34:24.937 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@105bb851
[0m[[0minfo[0m] [0mPassed: Total 56, Failed 0, Errors 0, Passed 56[0m
17:34:24.938 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=1, pending=0 toPageIn: 0, force:false, Inflight: 1, pagedInMessages.size 1, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 99, memUsage:1049, maxPageSize:200
17:34:24.938 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=1, pending=0 toPageIn: 0, force:false, Inflight: 1, pagedInMessages.size 1, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 99, memUsage:1049, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@2c679942
98
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@105bb851
17:34:24.938 [pool-5-thread-7] WARN  forklift.consumer.Consumer - Attempt to inject field failed because resource file none was not found
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@49d5f49d
17:34:24.939 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 100, memUsage:0, maxPageSize:200
17:34:24.939 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=1, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 100, memUsage:0, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@625f2435
99
GOT IT WHOA !!!!......................................... forklift.consumer.MessageRunnable@49d5f49d
[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-compress;1.8.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-compress;1.8.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-parent;33 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-parent;33 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;13 ...[0m
17:34:25.582 [ActiveMQ Journal Checkpoint Worker] DEBUG o.a.a.store.kahadb.MessageDatabase - Checkpoint started.
17:34:25.663 [ActiveMQ Journal Checkpoint Worker] DEBUG o.a.a.store.kahadb.MessageDatabase - Checkpoint done.
[A[2K[0m[[0minfo[0m] [0mResolving org.tukaani#xz;1.5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.tukaani#xz;1.5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.xerial.snappy#snappy-java;1.1.1.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.xerial.snappy#snappy-java;1.1.1.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-io#commons-io;2.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.novocode#junit-interface;0.11 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving junit#junit;4.11 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.hamcrest#hamcrest-core;1.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#test-interface;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-net#commons-net;3.6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-net#commons-net;3.6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-parent;42 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-parent;42 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;18 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;18 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.mockito#mockito-core;1.9.5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.mockito#mockito-core;1.9.5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.objenesis#objenesis;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.objenesis#objenesis;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving io.confluent#kafka-schema-registry;3.1.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving io.confluent#kafka-schema-registry;3.1.1 ...[0m
17:34:27.440 [pool-5-thread-7] INFO  forklift.consumer.Consumer - Consumer shutting down
17:34:27.440 [pool-5-thread-7] DEBUG o.a.activemq.ActiveMQMessageConsumer - remove: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:2:1, lastDeliveredSequenceId: 104
17:34:27.442 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q1,endpoint=Consumer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-3_1,consumerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4_1_2_1
17:34:27.443 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost removing consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:2:1 for destination: queue://q1
17:34:27.443 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.activemq.broker.region.Queue - queue://q1 remove sub: QueueSubscription: consumer=ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:2:1, destinations=1, dispatched=0, delivered=0, pending=0, lastDeliveredSeqId: 104, dequeues: 100, dispatched: 100, inflight: 0, groups: 0
17:34:27.452 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q1, subscriptions=0, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 100, dequeueCount: 100, memUsage:0, maxPageSize:200
17:34:27.453 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:27.453 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:27.460 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.TempQueue_ActiveMQ.Advisory.TempTopic,endpoint=Consumer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-3_1,consumerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4_1_-1_1
17:34:27.460 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost removing consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1:-1:1 for destination: ActiveMQ.Advisory.TempQueue,ActiveMQ.Advisory.TempTopic
17:34:27.461 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.TransportConnection - remove connection id: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4:1
17:34:27.461 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q1,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-3_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-4_1_1_1
17:34:27.462 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:27.462 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:27.466 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:27.467 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:27.476 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@23f91e8b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 43] is shutdown: true and terminated: true took: 0.000 seconds.
17:34:27.477 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@4770114b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0] is shutdown: true and terminated: true took: 0.000 seconds.
17:34:27.477 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Stopped tcp://127.0.0.1:61618
17:34:27.477 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@7ba8cd37[Running, pool size = 2, active threads = 0, queued tasks = 0, completed tasks = 2]
17:34:27.479 [pool-5-thread-7] DEBUG o.a.a.transport.tcp.TcpTransport - Stopping transport tcp:///127.0.0.1:61618@38926
17:34:27.480 [pool-5-thread-7] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@435a107b[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:27.481 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,connector=clientConnectors,connectorName=tcp_//localhost_61618,connectionViewType=clientId,connectionName=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-3_1
17:34:27.481 [ActiveMQ Transport: tcp:///127.0.0.1:38926@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,connector=clientConnectors,connectorName=tcp_//localhost_61618,connectionViewType=remoteAddress,connectionName=tcp_//127.0.0.1_38926
17:34:27.482 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.broker.TransportConnection - Stopping connection: tcp://127.0.0.1:38926
17:34:27.482 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.transport.tcp.TcpTransport - Stopping transport tcp:///127.0.0.1:38926@61618
17:34:27.482 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@6e82b5d5[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:27.504 [ActiveMQ Task-1] DEBUG o.a.a.transport.tcp.TcpTransport - Closed socket Socket[addr=/127.0.0.1,port=61618,localport=38926]
17:34:27.504 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@435a107b[Running, pool size = 1, active threads = 0, queued tasks = 0, completed tasks = 1]
17:34:27.511 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:1) is shutting down
17:34:27.512 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,connector=clientConnectors,connectorName=tcp_//localhost_61618
17:34:27.513 [ActiveMQ Task-1] DEBUG o.a.a.transport.tcp.TcpTransport - Closed socket Socket[addr=/127.0.0.1,port=38926,localport=61618]
17:34:27.515 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@6e82b5d5[Running, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 0]
17:34:27.515 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.broker.TransportConnection - Stopped transport: tcp://127.0.0.1:38926
17:34:27.516 [pool-5-thread-7] INFO  o.a.a.broker.TransportConnector - Connector tcp://localhost:61618 stopped
17:34:27.522 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.broker.TransportConnection - Connection Stopped: tcp://127.0.0.1:38926
17:34:27.523 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.MasterBroker
17:34:27.523 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Connection
17:34:27.524 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q1
17:34:27.524 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Queue
17:34:27.524 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Producer.Queue.q1
17:34:27.524 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Consumer.Queue.q1
17:34:27.525 [pool-5-thread-7] INFO  o.a.a.s.kahadb.plist.PListStoreImpl - PListStore:[/tmp/1496424858575-0/localhost/tmp_storage] stopped
17:34:27.525 [pool-5-thread-7] INFO  o.a.a.store.kahadb.KahaDBStore - Stopping async queue tasks
17:34:27.525 [pool-5-thread-7] INFO  o.a.a.store.kahadb.KahaDBStore - Stopping async topic tasks
17:34:27.525 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: org.apache.activemq.store.kahadb.KahaDBStore$StoreTaskExecutor@612c4d0b[Running, pool size = 1, active threads = 0, queued tasks = 0, completed tasks = 100]
17:34:27.526 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: org.apache.activemq.store.kahadb.KahaDBStore$StoreTaskExecutor@ab6cbd6[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:27.526 [pool-5-thread-7] INFO  o.a.a.store.kahadb.KahaDBStore - Stopped KahaDB
17:34:27.527 [pool-5-thread-7] DEBUG o.a.a.store.kahadb.MessageDatabase - Checkpoint started.
17:34:27.530 [pool-5-thread-7] DEBUG o.a.a.store.kahadb.MessageDatabase - Checkpoint done.
17:34:27.539 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ScheduledThreadPoolExecutor@19cd0df8[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0] is shutdown: true and terminated: true took: 0.002 seconds.
17:34:27.541 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.Executors$DelegatedScheduledExecutorService@723fba7b is shutdown: true and terminated: true took: 0.000 seconds.
17:34:27.559 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,service=PersistenceAdapter,instanceName=KahaDBPersistenceAdapter[/tmp/1496424858575-0/localhost/KahaDB]
17:34:27.559 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,service=Health
17:34:27.559 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost
17:34:27.559 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,service=Log4JConfiguration
17:34:27.560 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Stopping jmx connector
17:34:27.565 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unexported JMX RMI Registry
17:34:27.588 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@281f73f2[Shutting down, pool size = 1, active threads = 0, queued tasks = 0, completed tasks = 254] is shutdown: true and terminated: false took: 0.001 seconds.
17:34:27.588 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@19855a50[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:27.589 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:1) uptime 9.013 seconds
17:34:27.589 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:1) is shutdown
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest forklift.activemq.test.[33mMessagingTest[0m.[36mtest[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 1 total, 9.672s[0m[0m
17:34:27.634 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Creating RMIRegistry on port 1099
17:34:27.637 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Probably not using JRE 1.4: mx4j.tools.naming.NamingService
17:34:27.638 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Created JMXConnectorServer javax.management.remote.rmi.RMIConnectorServer@97f7f1f
17:34:27.648 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Using Persistence Adapter: KahaDBPersistenceAdapter[/tmp/1496424867632-0/localhost/KahaDB]
17:34:27.660 [JMX connector] DEBUG o.a.a.broker.jmx.ManagementContext - Starting JMXConnectorServer...
17:34:27.661 [pool-5-thread-7] DEBUG o.a.a.store.kahadb.KahaDBStore - Store OpenWire version configured as: 11
17:34:27.744 [JMX connector] INFO  o.a.a.broker.jmx.ManagementContext - JMX consoles can connect to service:jmx:rmi:///jndi/rmi://localhost:1099/jmxrmi
[0m[[0minfo[0m] [0mResolving io.confluent#kafka-schema-registry-parent;3.1.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.kafka#kafka_2.11;0.10.1.0-cp2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.kafka#kafka_2.11;0.10.1.0-cp2 ...[0m
17:34:28.381 [pool-5-thread-7] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:28.396 [pool-5-thread-7] INFO  o.a.a.s.kahadb.plist.PListStoreImpl - PListStore:[/tmp/1496424867632-0/localhost/tmp_storage] started
17:34:28.397 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:2) is starting
17:34:28.399 [pool-5-thread-7] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:28.400 [pool-5-thread-7] INFO  o.a.a.t.TransportServerThreadSupport - Listening for connections at: tcp://localhost:61618
17:34:28.400 [pool-5-thread-7] INFO  o.a.a.broker.TransportConnector - Connector tcp://localhost:61618 started
17:34:28.400 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:2) started
17:34:28.400 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - For help or more information please see: http://activemq.apache.org
17:34:28.400 [pool-5-thread-7] WARN  o.a.activemq.broker.BrokerService - Store limit is 102400 mb (current store usage is 0 mb). The data directory: /tmp/1496424867632-0/localhost/KahaDB only has 14179 mb of usable space. - resetting to maximum available disk space: 14179 mb
17:34:28.401 [pool-5-thread-7] WARN  o.a.activemq.broker.BrokerService - Temporary Store limit is 51200 mb (current store usage is 0 mb). The data directory: /tmp/1496424867632-0/localhost only has 14179 mb of usable space. - resetting to maximum available disk space: 14179 mb
17:34:28.401 [pool-5-thread-7] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.MasterBroker
17:34:28.401 [pool-5-thread-7] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ BrokerService[localhost] Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@69cee4ac[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:28.428 [pool-5-thread-7] DEBUG ForkLift - Creating ForkLift
17:34:28.428 [pool-5-thread-7] DEBUG ForkLift - Init complete!
17:34:28.428 [pool-5-thread-7] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@15aef5dd[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:28.428 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Reconnect was triggered but transport is not started yet. Wait for start to connect the transport.
17:34:28.428 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Started unconnected
17:34:28.429 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Waking up reconnect task
17:34:28.433 [ActiveMQ Task-1] DEBUG o.a.a.t.failover.FailoverTransport - urlList connectionList:[tcp://127.0.0.1:61618], from: [tcp://127.0.0.1:61618]
17:34:28.434 [ActiveMQ Task-1] DEBUG o.a.a.t.failover.FailoverTransport - Attempting 0th connect to: tcp://127.0.0.1:61618
17:34:28.438 [ActiveMQ Task-1] DEBUG o.a.a.transport.WireFormatNegotiator - Sending: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:28.439 [ActiveMQ Task-1] DEBUG o.a.a.t.failover.FailoverTransport - Connection established
17:34:28.439 [ActiveMQ Task-1] INFO  o.a.a.t.failover.FailoverTransport - Successfully connected to tcp://127.0.0.1:61618
17:34:28.440 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.transport.WireFormatNegotiator - Sending: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:28.461 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.transport.InactivityMonitor - Using min of local: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]} and remote: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:28.463 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.transport.WireFormatNegotiator - Received WireFormat: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:28.463 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:38972@61618 before negotiation: OpenWireFormat{version=12, cacheEnabled=false, stackTraceEnabled=false, tightEncodingEnabled=false, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:28.464 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:38972@61618 after negotiation: OpenWireFormat{version=12, cacheEnabled=true, stackTraceEnabled=true, tightEncodingEnabled=true, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:28.470 [ActiveMQ Transport: tcp:///127.0.0.1:61618@38972] DEBUG o.a.a.transport.InactivityMonitor - Using min of local: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]} and remote: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:28.470 [ActiveMQ Transport: tcp:///127.0.0.1:61618@38972] DEBUG o.a.a.transport.WireFormatNegotiator - Received WireFormat: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:28.470 [ActiveMQ Transport: tcp:///127.0.0.1:61618@38972] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:61618@38972 before negotiation: OpenWireFormat{version=12, cacheEnabled=false, stackTraceEnabled=false, tightEncodingEnabled=false, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:28.470 [ActiveMQ Transport: tcp:///127.0.0.1:61618@38972] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:61618@38972 after negotiation: OpenWireFormat{version=12, cacheEnabled=true, stackTraceEnabled=true, tightEncodingEnabled=true, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:28.473 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnection - Setting up new connection id: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7:1, address: tcp://127.0.0.1:38972, info: ConnectionInfo {commandId = 1, responseRequired = true, connectionId = ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7:1, clientId = ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-6:1, clientIp = null, userName = , password = *****, brokerPath = null, brokerMasterConnector = false, manageable = true, clientMaster = true, faultTolerant = true, failoverReconnect = false}
17:34:28.473 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:28.473 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:28.474 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Connection
17:34:28.511 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7:1:-1:1 for destination: ActiveMQ.Advisory.TempQueue,ActiveMQ.Advisory.TempTopic
17:34:28.549 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: queue://q2
17:34:28.567 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:28.567 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:28.567 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:28.567 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:28.568 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:28.606 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 0, dequeueCount: 0, memUsage:0, maxPageSize:200
17:34:28.606 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:28.606 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:28.606 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Queue
17:34:28.613 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:28.613 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:28.614 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Producer.Queue.q2
17:34:28.620 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7:1:1:1:1 sent to queue://q2
17:34:28.670 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=1, pending=0 toPageIn: 1, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 1, dequeueCount: 0, memUsage:2154, maxPageSize:200
17:34:28.752 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7:1:1:1:2 sent to queue://q2
17:34:28.753 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=2, pending=0 toPageIn: 2, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 2, dequeueCount: 0, memUsage:2154, maxPageSize:200
17:34:28.755 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7:1:1:1:3 sent to queue://q2
17:34:28.755 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=3, pending=0 toPageIn: 3, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 3, dequeueCount: 0, memUsage:4308, maxPageSize:200
17:34:28.760 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7:1:1:1:4 sent to queue://q2
17:34:28.765 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=4, pending=0 toPageIn: 4, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 4, dequeueCount: 0, memUsage:4308, maxPageSize:200
17:34:28.766 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7:1:1:1:5 sent to queue://q2
17:34:28.767 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=5, pending=0 toPageIn: 5, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 5, dequeueCount: 0, memUsage:6462, maxPageSize:200
17:34:28.778 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7:1:1:1:6 sent to queue://q2
17:34:28.778 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=6, pending=0 toPageIn: 6, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 6, dequeueCount: 0, memUsage:7539, maxPageSize:200
17:34:28.781 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7:1:1:1:7 sent to queue://q2
17:34:28.781 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=7, pending=0 toPageIn: 7, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 7, dequeueCount: 0, memUsage:8616, maxPageSize:200
17:34:28.783 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7:1:1:1:8 sent to queue://q2
17:34:28.783 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=8, pending=0 toPageIn: 8, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 8, dequeueCount: 0, memUsage:9693, maxPageSize:200
17:34:28.794 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7:1:1:1:9 sent to queue://q2
17:34:28.794 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=9, pending=0 toPageIn: 9, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 9, dequeueCount: 0, memUsage:10770, maxPageSize:200
17:34:28.796 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7:1:1:1:10 sent to queue://q2
17:34:28.796 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=10, pending=0 toPageIn: 10, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 0, memUsage:11847, maxPageSize:200
17:34:28.798 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7:1:2:1 for destination: queue://q2
17:34:28.801 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.activemq.broker.region.Queue - queue://q2 add sub: QueueSubscription: consumer=ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7:1:2:1, destinations=0, dispatched=0, delivered=0, pending=0, dequeues: 0, dispatched: 0, inflight: 0
17:34:28.801 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 10, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 0, memUsage:10770, maxPageSize:200
17:34:28.818 [ActiveMQ Transport: tcp:///127.0.0.1:61618@38972] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Session Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@1efcff2[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:28.829 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:28.829 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:28.829 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Consumer.Queue.q2
17:34:28.862 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:28.862 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@11b284f1
ball -:- 0 || true
Bar -:- FOO
JMSCorrelationsID -:- 0
17:34:28.903 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 1, memUsage:9693, maxPageSize:200
17:34:28.904 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 1, memUsage:9693, maxPageSize:200
17:34:28.904 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-6_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7_1_3_1
17:34:28.905 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:28.906 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:28.908 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:28.908 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@248fa331
ball -:- 1 || true
Bar -:- FOO
JMSCorrelationsID -:- 1
17:34:28.913 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=8, pending=0 toPageIn: 0, force:false, Inflight: 8, pagedInMessages.size 8, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 2, memUsage:8616, maxPageSize:200
17:34:28.913 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=8, pending=0 toPageIn: 0, force:false, Inflight: 8, pagedInMessages.size 8, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 2, memUsage:8616, maxPageSize:200
17:34:28.917 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-6_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7_1_4_1
17:34:28.917 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:28.917 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:28.919 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:28.919 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@60e872be
ball -:- 2 || true
Bar -:- FOO
JMSCorrelationsID -:- 2
17:34:28.924 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=7, pending=0 toPageIn: 0, force:false, Inflight: 7, pagedInMessages.size 7, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 3, memUsage:7539, maxPageSize:200
17:34:28.925 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=7, pending=0 toPageIn: 0, force:false, Inflight: 7, pagedInMessages.size 7, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 3, memUsage:7539, maxPageSize:200
17:34:28.925 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-6_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7_1_5_1
17:34:28.925 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:28.926 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:28.927 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:28.932 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@4a83ffd5
ball -:- 3 || true
Bar -:- FOO
JMSCorrelationsID -:- 3
17:34:28.942 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=6, pending=0 toPageIn: 0, force:false, Inflight: 6, pagedInMessages.size 6, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 4, memUsage:6462, maxPageSize:200
17:34:28.942 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=6, pending=0 toPageIn: 0, force:false, Inflight: 6, pagedInMessages.size 6, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 4, memUsage:6462, maxPageSize:200
17:34:28.942 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-6_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7_1_6_1
17:34:28.943 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:28.943 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:28.945 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:28.945 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@4bb854ce
ball -:- 4 || true
Bar -:- FOO
JMSCorrelationsID -:- 4
17:34:28.953 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=5, pending=0 toPageIn: 0, force:false, Inflight: 5, pagedInMessages.size 5, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 5, memUsage:5385, maxPageSize:200
17:34:28.953 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=5, pending=0 toPageIn: 0, force:false, Inflight: 5, pagedInMessages.size 5, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 5, memUsage:5385, maxPageSize:200
17:34:28.953 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-6_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7_1_7_1
17:34:28.954 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:28.964 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:28.966 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:28.966 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@6fa849bd
ball -:- 5 || true
Bar -:- FOO
JMSCorrelationsID -:- 5
[A[2K[0m[[0minfo[0m] [0mResolving net.sf.jopt-simple#jopt-simple;4.9 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving net.sf.jopt-simple#jopt-simple;4.9 ...[0m
17:34:28.985 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=4, pending=0 toPageIn: 0, force:false, Inflight: 4, pagedInMessages.size 4, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 6, memUsage:4308, maxPageSize:200
17:34:28.985 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=4, pending=0 toPageIn: 0, force:false, Inflight: 4, pagedInMessages.size 4, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 6, memUsage:4308, maxPageSize:200
17:34:28.986 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-6_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7_1_8_1
17:34:28.986 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:28.987 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:28.990 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:28.990 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@3bb37f5e
ball -:- 6 || true
Bar -:- FOO
JMSCorrelationsID -:- 6
17:34:29.009 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=3, pending=0 toPageIn: 0, force:false, Inflight: 3, pagedInMessages.size 3, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 7, memUsage:3231, maxPageSize:200
17:34:29.010 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=3, pending=0 toPageIn: 0, force:false, Inflight: 3, pagedInMessages.size 3, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 7, memUsage:3231, maxPageSize:200
17:34:29.010 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-6_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7_1_9_1
17:34:29.010 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:29.010 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:29.012 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:29.013 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@2f610312
ball -:- 7 || true
Bar -:- FOO
JMSCorrelationsID -:- 7
17:34:29.019 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=2, pending=0 toPageIn: 0, force:false, Inflight: 2, pagedInMessages.size 2, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 8, memUsage:2154, maxPageSize:200
17:34:29.032 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=2, pending=0 toPageIn: 0, force:false, Inflight: 2, pagedInMessages.size 2, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 8, memUsage:2154, maxPageSize:200
17:34:29.033 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-6_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7_1_10_1
17:34:29.033 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:29.033 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:29.037 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:29.049 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@1fa3bf65
ball -:- 8 || true
Bar -:- FOO
JMSCorrelationsID -:- 8
17:34:29.062 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=1, pending=0 toPageIn: 0, force:false, Inflight: 1, pagedInMessages.size 1, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 9, memUsage:1077, maxPageSize:200
17:34:29.063 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=1, pending=0 toPageIn: 0, force:false, Inflight: 1, pagedInMessages.size 1, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 9, memUsage:1077, maxPageSize:200
17:34:29.063 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-6_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7_1_11_1
17:34:29.063 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:29.063 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:29.066 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:29.066 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@702650bb
ball -:- 9 || true
Bar -:- FOO
JMSCorrelationsID -:- 9
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.oss#oss-parent;7 ...[0m
17:34:29.073 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 10, memUsage:0, maxPageSize:200
17:34:29.073 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 10, memUsage:0, maxPageSize:200
17:34:29.073 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-6_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7_1_12_1
17:34:29.074 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:29.074 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
[A[2K[0m[[0minfo[0m] [0mResolving com.yammer.metrics#metrics-core;2.2.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.yammer.metrics#metrics-core;2.2.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.yammer.metrics#metrics-parent;2.2.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.yammer.metrics#metrics-parent;2.2.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-library;2.11.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang.modules#scala-parser-combinators_2.11;1.0.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang.modules#scala-parser-combinators_2.11;1.0.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey.ext#jersey-bean-validation;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey.ext#jersey-bean-validation;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey.ext#project;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey.ext#project;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey#project;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey#project;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving net.java#jvnet-parent;4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.hk2#hk2-bom;2.4.0-b25 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.hk2#hk2-bom;2.4.0-b25 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving net.java#jvnet-parent;5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving net.java#jvnet-parent;5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.hk2.external#javax.inject;2.4.0-b25 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.hk2.external#javax.inject;2.4.0-b25 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.hk2#external;2.4.0-b25 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.hk2#external;2.4.0-b25 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.hk2#hk2-parent;2.4.0-b25 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.hk2#hk2-parent;2.4.0-b25 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.hk2#hk2-bom;2.4.0-b25 ...[0m
17:34:31.568 [pool-5-thread-7] INFO  forklift.consumer.Consumer - Consumer shutting down
17:34:31.568 [pool-5-thread-7] DEBUG o.a.activemq.ActiveMQMessageConsumer - remove: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7:1:2:1, lastDeliveredSequenceId: 14
17:34:31.569 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Consumer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-6_1,consumerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7_1_2_1
17:34:31.569 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost removing consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7:1:2:1 for destination: queue://q2
17:34:31.569 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.activemq.broker.region.Queue - queue://q2 remove sub: QueueSubscription: consumer=ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7:1:2:1, destinations=1, dispatched=0, delivered=0, pending=0, lastDeliveredSeqId: 14, dequeues: 10, dispatched: 10, inflight: 0, groups: 0
17:34:31.570 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:31.570 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:31.570 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.TempQueue_ActiveMQ.Advisory.TempTopic,endpoint=Consumer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-6_1,consumerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7_1_-1_1
17:34:31.570 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost removing consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7:1:-1:1 for destination: ActiveMQ.Advisory.TempQueue,ActiveMQ.Advisory.TempTopic
17:34:31.570 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnection - remove connection id: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7:1
17:34:31.570 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-6_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-7_1_1_1
17:34:31.570 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:31.571 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:31.571 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:31.571 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:31.571 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 10, memUsage:0, maxPageSize:200
17:34:31.574 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@1efcff2[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 1] is shutdown: true and terminated: false took: 0.000 seconds.
17:34:31.575 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@41df4fdb[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0] is shutdown: true and terminated: true took: 0.000 seconds.
17:34:31.575 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Stopped tcp://127.0.0.1:61618
17:34:31.575 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@15aef5dd[Running, pool size = 2, active threads = 0, queued tasks = 0, completed tasks = 2]
17:34:31.575 [pool-5-thread-7] DEBUG o.a.a.transport.tcp.TcpTransport - Stopping transport tcp:///127.0.0.1:61618@38972
17:34:31.575 [pool-5-thread-7] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@1ac8e704[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:31.575 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,connector=clientConnectors,connectorName=tcp_//localhost_61618,connectionViewType=clientId,connectionName=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-6_1
17:34:31.575 [ActiveMQ Transport: tcp:///127.0.0.1:38972@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,connector=clientConnectors,connectorName=tcp_//localhost_61618,connectionViewType=remoteAddress,connectionName=tcp_//127.0.0.1_38972
17:34:31.576 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.broker.TransportConnection - Stopping connection: tcp://127.0.0.1:38972
17:34:31.576 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.transport.tcp.TcpTransport - Stopping transport tcp:///127.0.0.1:38972@61618
17:34:31.576 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@506c26e[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:31.581 [ActiveMQ Task-1] DEBUG o.a.a.transport.tcp.TcpTransport - Closed socket Socket[addr=/127.0.0.1,port=61618,localport=38972]
17:34:31.582 [ActiveMQ Task-1] DEBUG o.a.a.transport.tcp.TcpTransport - Closed socket Socket[addr=/127.0.0.1,port=38972,localport=61618]
17:34:31.582 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@506c26e[Running, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 0]
17:34:31.582 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.broker.TransportConnection - Stopped transport: tcp://127.0.0.1:38972
17:34:31.583 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.broker.TransportConnection - Connection Stopped: tcp://127.0.0.1:38972
17:34:31.584 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@1ac8e704[Running, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 0]
17:34:31.584 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:2) is shutting down
17:34:31.584 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,connector=clientConnectors,connectorName=tcp_//localhost_61618
17:34:31.589 [pool-5-thread-7] INFO  o.a.a.broker.TransportConnector - Connector tcp://localhost:61618 stopped
17:34:31.590 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.MasterBroker
17:34:31.590 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Connection
17:34:31.590 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2
17:34:31.590 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Queue
17:34:31.590 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Producer.Queue.q2
17:34:31.590 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Consumer.Queue.q2
17:34:31.590 [pool-5-thread-7] INFO  o.a.a.s.kahadb.plist.PListStoreImpl - PListStore:[/tmp/1496424867632-0/localhost/tmp_storage] stopped
17:34:31.590 [pool-5-thread-7] INFO  o.a.a.store.kahadb.KahaDBStore - Stopping async queue tasks
17:34:31.591 [pool-5-thread-7] INFO  o.a.a.store.kahadb.KahaDBStore - Stopping async topic tasks
17:34:31.591 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: org.apache.activemq.store.kahadb.KahaDBStore$StoreTaskExecutor@62e23865[Running, pool size = 1, active threads = 0, queued tasks = 0, completed tasks = 10]
17:34:31.591 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: org.apache.activemq.store.kahadb.KahaDBStore$StoreTaskExecutor@39746782[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:31.591 [pool-5-thread-7] INFO  o.a.a.store.kahadb.KahaDBStore - Stopped KahaDB
17:34:31.591 [pool-5-thread-7] DEBUG o.a.a.store.kahadb.MessageDatabase - Checkpoint started.
17:34:31.611 [pool-5-thread-7] DEBUG o.a.a.store.kahadb.MessageDatabase - Checkpoint done.
17:34:31.664 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ScheduledThreadPoolExecutor@6a9e559e[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0] is shutdown: true and terminated: true took: 0.003 seconds.
17:34:31.672 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.Executors$DelegatedScheduledExecutorService@47c10df is shutdown: true and terminated: true took: 0.004 seconds.
17:34:31.688 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,service=PersistenceAdapter,instanceName=KahaDBPersistenceAdapter[/tmp/1496424867632-0/localhost/KahaDB]
17:34:31.689 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost
17:34:31.689 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,service=Health
17:34:31.689 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,service=Log4JConfiguration
17:34:31.689 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Stopping jmx connector
17:34:31.701 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unexported JMX RMI Registry
17:34:31.709 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@69cee4ac[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 37] is shutdown: true and terminated: true took: 0.001 seconds.
17:34:31.709 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@9767e69[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:31.709 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:2) uptime 4.076 seconds
17:34:31.709 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:2) is shutdown
17:34:31.725 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Creating RMIRegistry on port 1099
17:34:31.726 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Probably not using JRE 1.4: mx4j.tools.naming.NamingService
17:34:31.727 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Created JMXConnectorServer javax.management.remote.rmi.RMIConnectorServer@7542f860
17:34:31.734 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Using Persistence Adapter: KahaDBPersistenceAdapter[/tmp/1496424871716-0/localhost/KahaDB]
17:34:31.735 [JMX connector] DEBUG o.a.a.broker.jmx.ManagementContext - Starting JMXConnectorServer...
17:34:31.735 [pool-5-thread-7] DEBUG o.a.a.store.kahadb.KahaDBStore - Store OpenWire version configured as: 11
17:34:31.766 [JMX connector] INFO  o.a.a.broker.jmx.ManagementContext - JMX consoles can connect to service:jmx:rmi:///jndi/rmi://localhost:1099/jmxrmi
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey.core#jersey-common;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey.core#jersey-common;2.19 ...[0m
17:34:32.236 [pool-5-thread-7] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey#project;2.19 ...[0m
17:34:32.256 [pool-5-thread-7] INFO  o.a.a.s.kahadb.plist.PListStoreImpl - PListStore:[/tmp/1496424871716-0/localhost/tmp_storage] started
17:34:32.263 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:3) is starting
17:34:32.281 [pool-5-thread-7] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.284 [pool-5-thread-7] INFO  o.a.a.t.TransportServerThreadSupport - Listening for connections at: tcp://localhost:61618
17:34:32.285 [pool-5-thread-7] INFO  o.a.a.broker.TransportConnector - Connector tcp://localhost:61618 started
17:34:32.285 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:3) started
17:34:32.285 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - For help or more information please see: http://activemq.apache.org
17:34:32.285 [pool-5-thread-7] WARN  o.a.activemq.broker.BrokerService - Store limit is 102400 mb (current store usage is 0 mb). The data directory: /tmp/1496424871716-0/localhost/KahaDB only has 14178 mb of usable space. - resetting to maximum available disk space: 14178 mb
17:34:32.286 [pool-5-thread-7] WARN  o.a.activemq.broker.BrokerService - Temporary Store limit is 51200 mb (current store usage is 0 mb). The data directory: /tmp/1496424871716-0/localhost only has 14178 mb of usable space. - resetting to maximum available disk space: 14178 mb
17:34:32.286 [pool-5-thread-7] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.MasterBroker
17:34:32.286 [pool-5-thread-7] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ BrokerService[localhost] Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@7f0d25f8[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
[A[2K[0m[[0minfo[0m] [0mResolving javax.ws.rs#javax.ws.rs-api;2.0.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving javax.ws.rs#javax.ws.rs-api;2.0.1 ...[0m
17:34:32.311 [pool-5-thread-7] DEBUG ForkLift - Creating ForkLift
17:34:32.314 [pool-5-thread-7] DEBUG ForkLift - Init complete!
17:34:32.314 [pool-5-thread-7] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@6946035c[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:32.315 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Reconnect was triggered but transport is not started yet. Wait for start to connect the transport.
17:34:32.315 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Started unconnected
17:34:32.315 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Waking up reconnect task
17:34:32.327 [ActiveMQ Task-1] DEBUG o.a.a.t.failover.FailoverTransport - urlList connectionList:[tcp://127.0.0.1:61618], from: [tcp://127.0.0.1:61618]
17:34:32.328 [ActiveMQ Task-1] DEBUG o.a.a.t.failover.FailoverTransport - Attempting 0th connect to: tcp://127.0.0.1:61618
17:34:32.333 [ActiveMQ Task-1] DEBUG o.a.a.transport.WireFormatNegotiator - Sending: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:32.335 [ActiveMQ Task-1] DEBUG o.a.a.t.failover.FailoverTransport - Connection established
17:34:32.335 [ActiveMQ Task-1] INFO  o.a.a.t.failover.FailoverTransport - Successfully connected to tcp://127.0.0.1:61618
17:34:32.353 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.transport.WireFormatNegotiator - Sending: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:32.360 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.transport.InactivityMonitor - Using min of local: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]} and remote: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:32.356 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.transport.WireFormatNegotiator - Received WireFormat: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:32.388 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:38994@61618 before negotiation: OpenWireFormat{version=12, cacheEnabled=false, stackTraceEnabled=false, tightEncodingEnabled=false, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:32.389 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:38994@61618 after negotiation: OpenWireFormat{version=12, cacheEnabled=true, stackTraceEnabled=true, tightEncodingEnabled=true, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:32.382 [ActiveMQ Transport: tcp:///127.0.0.1:61618@38994] DEBUG o.a.a.transport.InactivityMonitor - Using min of local: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]} and remote: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:32.404 [ActiveMQ Transport: tcp:///127.0.0.1:61618@38994] DEBUG o.a.a.transport.WireFormatNegotiator - Received WireFormat: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:32.404 [ActiveMQ Transport: tcp:///127.0.0.1:61618@38994] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:61618@38994 before negotiation: OpenWireFormat{version=12, cacheEnabled=false, stackTraceEnabled=false, tightEncodingEnabled=false, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:32.405 [ActiveMQ Transport: tcp:///127.0.0.1:61618@38994] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:61618@38994 after negotiation: OpenWireFormat{version=12, cacheEnabled=true, stackTraceEnabled=true, tightEncodingEnabled=true, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:32.415 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnection - Setting up new connection id: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10:1, address: tcp://127.0.0.1:38994, info: ConnectionInfo {commandId = 1, responseRequired = true, connectionId = ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10:1, clientId = ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-9:1, clientIp = null, userName = , password = *****, brokerPath = null, brokerMasterConnector = false, manageable = true, clientMaster = true, faultTolerant = true, failoverReconnect = false}
[A[2K[0m[[0minfo[0m] [0mResolving net.java#jvnet-parent;5 ...[0m
17:34:32.440 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.440 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.441 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Connection
17:34:32.452 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10:1:-1:1 for destination: ActiveMQ.Advisory.TempQueue,ActiveMQ.Advisory.TempTopic
[A[2K[0m[[0minfo[0m] [0mResolving javax.annotation#javax.annotation-api;1.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving javax.annotation#javax.annotation-api;1.2 ...[0m
17:34:32.506 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: queue://q2
17:34:32.517 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:32.517 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:32.517 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:32.517 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:32.517 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:32.543 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 0, dequeueCount: 0, memUsage:0, maxPageSize:200
17:34:32.543 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.543 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.543 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Queue
[A[2K[0m[[0minfo[0m] [0mResolving net.java#jvnet-parent;3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving net.java#jvnet-parent;3 ...[0m
17:34:32.596 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.597 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.597 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Producer.Queue.q2
17:34:32.609 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10:1:1:1:1 sent to queue://q2
17:34:32.624 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=1, pending=0 toPageIn: 1, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 1, dequeueCount: 0, memUsage:2118, maxPageSize:200
17:34:32.655 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10:1:1:1:2 sent to queue://q2
17:34:32.656 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=2, pending=0 toPageIn: 2, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 2, dequeueCount: 0, memUsage:3177, maxPageSize:200
17:34:32.657 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10:1:1:1:3 sent to queue://q2
17:34:32.657 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=3, pending=0 toPageIn: 3, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 3, dequeueCount: 0, memUsage:4236, maxPageSize:200
17:34:32.659 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10:1:1:1:4 sent to queue://q2
17:34:32.660 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=4, pending=0 toPageIn: 4, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 4, dequeueCount: 0, memUsage:5295, maxPageSize:200
17:34:32.661 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10:1:1:1:5 sent to queue://q2
17:34:32.662 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=5, pending=0 toPageIn: 5, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 5, dequeueCount: 0, memUsage:6354, maxPageSize:200
17:34:32.670 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10:1:1:1:6 sent to queue://q2
17:34:32.671 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=6, pending=0 toPageIn: 6, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 6, dequeueCount: 0, memUsage:7413, maxPageSize:200
17:34:32.673 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10:1:1:1:7 sent to queue://q2
17:34:32.673 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=7, pending=0 toPageIn: 7, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 7, dequeueCount: 0, memUsage:8472, maxPageSize:200
17:34:32.676 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10:1:1:1:8 sent to queue://q2
17:34:32.677 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=8, pending=0 toPageIn: 8, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 8, dequeueCount: 0, memUsage:9531, maxPageSize:200
17:34:32.680 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10:1:1:1:9 sent to queue://q2
17:34:32.680 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=9, pending=0 toPageIn: 9, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 9, dequeueCount: 0, memUsage:10590, maxPageSize:200
17:34:32.686 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10:1:1:1:10 sent to queue://q2
17:34:32.687 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=10, pending=0 toPageIn: 10, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 0, memUsage:11649, maxPageSize:200
17:34:32.699 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10:1:2:1 for destination: queue://q2
17:34:32.701 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.activemq.broker.region.Queue - queue://q2 add sub: QueueSubscription: consumer=ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10:1:2:1, destinations=0, dispatched=0, delivered=0, pending=0, dequeues: 0, dispatched: 0, inflight: 0
17:34:32.702 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 10, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 0, memUsage:10590, maxPageSize:200
17:34:32.704 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.705 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.705 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Consumer.Queue.q2
17:34:32.706 [ActiveMQ Transport: tcp:///127.0.0.1:61618@38994] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Session Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@3709e2f3[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:32.743 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.743 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@625f0d34
8db4a6dc979c486daa02e5363d09992f -:- 0
17:34:32.783 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-9_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10_1_3_1
17:34:32.783 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.784 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 1, memUsage:9531, maxPageSize:200
17:34:32.784 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 1, memUsage:9531, maxPageSize:200
17:34:32.784 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.787 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.787 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@b713a52
4a5d5ef5fe644bbbb8cfb201dea43b23 -:- 1
17:34:32.789 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=8, pending=0 toPageIn: 0, force:false, Inflight: 8, pagedInMessages.size 8, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 2, memUsage:8472, maxPageSize:200
17:34:32.790 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=8, pending=0 toPageIn: 0, force:false, Inflight: 8, pagedInMessages.size 8, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 2, memUsage:8472, maxPageSize:200
17:34:32.790 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-9_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10_1_4_1
17:34:32.791 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.792 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.798 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.798 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@993cc35
beae6dd4e3b943bcbeebc1b5de4b6397 -:- 2
17:34:32.821 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=7, pending=0 toPageIn: 0, force:false, Inflight: 7, pagedInMessages.size 7, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 3, memUsage:7413, maxPageSize:200
17:34:32.821 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=7, pending=0 toPageIn: 0, force:false, Inflight: 7, pagedInMessages.size 7, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 3, memUsage:7413, maxPageSize:200
17:34:32.821 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-9_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10_1_5_1
17:34:32.821 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.821 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.823 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.823 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@4d295557
fba0c9976c9e4f39a64e81559c47dad8 -:- 3
17:34:32.837 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=6, pending=0 toPageIn: 0, force:false, Inflight: 6, pagedInMessages.size 6, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 4, memUsage:6354, maxPageSize:200
17:34:32.838 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=6, pending=0 toPageIn: 0, force:false, Inflight: 6, pagedInMessages.size 6, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 4, memUsage:6354, maxPageSize:200
17:34:32.838 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-9_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10_1_6_1
17:34:32.838 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.838 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.840 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.840 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@33b442ef
1c2930f8d5964fda9f787f7e19751c6e -:- 4
17:34:32.843 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=5, pending=0 toPageIn: 0, force:false, Inflight: 5, pagedInMessages.size 5, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 5, memUsage:5295, maxPageSize:200
17:34:32.843 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=5, pending=0 toPageIn: 0, force:false, Inflight: 5, pagedInMessages.size 5, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 5, memUsage:5295, maxPageSize:200
17:34:32.844 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-9_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10_1_7_1
17:34:32.844 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.844 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.846 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.846 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@2d706c5
5b6e8926168349c6a04188c8bab47948 -:- 5
17:34:32.885 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=4, pending=0 toPageIn: 0, force:false, Inflight: 4, pagedInMessages.size 4, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 6, memUsage:4236, maxPageSize:200
17:34:32.885 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=4, pending=0 toPageIn: 0, force:false, Inflight: 4, pagedInMessages.size 4, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 6, memUsage:4236, maxPageSize:200
17:34:32.886 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-9_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10_1_8_1
17:34:32.886 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.886 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.888 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.888 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@26bcf411
825d02a98435416caaa91cde247e8f43 -:- 6
17:34:32.893 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=3, pending=0 toPageIn: 0, force:false, Inflight: 3, pagedInMessages.size 3, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 7, memUsage:3177, maxPageSize:200
17:34:32.893 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=3, pending=0 toPageIn: 0, force:false, Inflight: 3, pagedInMessages.size 3, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 7, memUsage:3177, maxPageSize:200
17:34:32.893 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-9_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10_1_9_1
17:34:32.893 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.893 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.899 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.899 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@23d64f9d
34422f22bb5f41a2bb87d15725741dd2 -:- 7
17:34:32.917 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=2, pending=0 toPageIn: 0, force:false, Inflight: 2, pagedInMessages.size 2, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 8, memUsage:2118, maxPageSize:200
17:34:32.918 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=2, pending=0 toPageIn: 0, force:false, Inflight: 2, pagedInMessages.size 2, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 8, memUsage:2118, maxPageSize:200
17:34:32.918 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-9_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10_1_10_1
17:34:32.918 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.918 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.920 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.920 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@1ae91f67
1d80725aec7440e2af70350cdc5825cf -:- 8
17:34:32.922 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=1, pending=0 toPageIn: 0, force:false, Inflight: 1, pagedInMessages.size 1, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 9, memUsage:1059, maxPageSize:200
17:34:32.923 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=1, pending=0 toPageIn: 0, force:false, Inflight: 1, pagedInMessages.size 1, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 9, memUsage:1059, maxPageSize:200
17:34:32.923 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-9_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10_1_11_1
17:34:32.923 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.923 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.929 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.929 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@7eb0301d
975255ef7143488288597a34da4c617e -:- 9
17:34:32.932 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 10, memUsage:0, maxPageSize:200
17:34:32.932 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 10, memUsage:0, maxPageSize:200
17:34:32.932 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-9_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10_1_12_1
17:34:32.933 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:32.933 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey.bundles.repackaged#jersey-guava;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey.bundles.repackaged#jersey-guava;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey.bundles.repackaged#project;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey.bundles.repackaged#project;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey.bundles#project;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey.bundles#project;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey#project;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.hk2#hk2-api;2.4.0-b25 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.hk2#hk2-api;2.4.0-b25 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.hk2#hk2-parent;2.4.0-b25 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.hk2#hk2-utils;2.4.0-b25 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.hk2#hk2-utils;2.4.0-b25 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.hk2#hk2-parent;2.4.0-b25 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.hk2.external#aopalliance-repackaged;2.4.0-b25 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.hk2.external#aopalliance-repackaged;2.4.0-b25 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.hk2#external;2.4.0-b25 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.hk2#hk2-locator;2.4.0-b25 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.hk2#hk2-locator;2.4.0-b25 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.hk2#hk2-parent;2.4.0-b25 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.hk2#osgi-resource-locator;1.0.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.hk2#osgi-resource-locator;1.0.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish#pom;8 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish#pom;8 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey.core#jersey-server;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey.core#jersey-server;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey#project;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey.core#jersey-client;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey.core#jersey-client;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey#project;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey.media#jersey-media-jaxb;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey.media#jersey-media-jaxb;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey.media#project;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey.media#project;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey#project;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving javax.validation#validation-api;1.1.0.Final ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving javax.validation#validation-api;1.1.0.Final ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.hibernate#hibernate-validator;5.1.2.Final ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.hibernate#hibernate-validator;5.1.2.Final ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.hibernate#hibernate-validator-parent;5.1.2.Final ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.hibernate#hibernate-validator-parent;5.1.2.Final ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.jboss.arquillian#arquillian-bom;1.0.2.Final ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.jboss.arquillian#arquillian-bom;1.0.2.Final ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.jboss.shrinkwrap#shrinkwrap-bom;1.0.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.jboss.shrinkwrap#shrinkwrap-bom;1.0.1 ...[0m
17:34:35.430 [pool-5-thread-7] INFO  forklift.consumer.Consumer - Consumer shutting down
17:34:35.430 [pool-5-thread-7] DEBUG o.a.activemq.ActiveMQMessageConsumer - remove: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10:1:2:1, lastDeliveredSequenceId: 14
17:34:35.431 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Consumer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-9_1,consumerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10_1_2_1
17:34:35.431 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost removing consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10:1:2:1 for destination: queue://q2
17:34:35.432 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.activemq.broker.region.Queue - queue://q2 remove sub: QueueSubscription: consumer=ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10:1:2:1, destinations=1, dispatched=0, delivered=0, pending=0, lastDeliveredSeqId: 14, dequeues: 10, dispatched: 10, inflight: 0, groups: 0
17:34:35.432 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 10, memUsage:0, maxPageSize:200
17:34:35.433 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:35.438 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:35.445 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.TempQueue_ActiveMQ.Advisory.TempTopic,endpoint=Consumer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-9_1,consumerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10_1_-1_1
17:34:35.446 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost removing consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10:1:-1:1 for destination: ActiveMQ.Advisory.TempQueue,ActiveMQ.Advisory.TempTopic
17:34:35.446 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnection - remove connection id: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10:1
17:34:35.457 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-9_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-10_1_1_1
17:34:35.457 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:35.460 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:35.461 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:35.461 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:35.470 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@3709e2f3[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 2] is shutdown: true and terminated: false took: 0.001 seconds.
17:34:35.470 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@66aee356[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0] is shutdown: true and terminated: true took: 0.000 seconds.
17:34:35.470 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Stopped tcp://127.0.0.1:61618
17:34:35.471 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@6946035c[Running, pool size = 2, active threads = 0, queued tasks = 0, completed tasks = 2]
17:34:35.471 [pool-5-thread-7] DEBUG o.a.a.transport.tcp.TcpTransport - Stopping transport tcp:///127.0.0.1:61618@38994
17:34:35.471 [pool-5-thread-7] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@4e54e4f2[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:35.477 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,connector=clientConnectors,connectorName=tcp_//localhost_61618,connectionViewType=clientId,connectionName=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-9_1
17:34:35.478 [ActiveMQ Transport: tcp:///127.0.0.1:38994@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,connector=clientConnectors,connectorName=tcp_//localhost_61618,connectionViewType=remoteAddress,connectionName=tcp_//127.0.0.1_38994
17:34:35.478 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.broker.TransportConnection - Stopping connection: tcp://127.0.0.1:38994
17:34:35.478 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.transport.tcp.TcpTransport - Stopping transport tcp:///127.0.0.1:38994@61618
17:34:35.478 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@6f02cae8[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:35.494 [ActiveMQ Task-1] DEBUG o.a.a.transport.tcp.TcpTransport - Closed socket Socket[addr=/127.0.0.1,port=38994,localport=61618]
17:34:35.495 [ActiveMQ Task-1] DEBUG o.a.a.transport.tcp.TcpTransport - Closed socket Socket[addr=/127.0.0.1,port=61618,localport=38994]
17:34:35.495 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@4e54e4f2[Running, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 0]
17:34:35.495 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:3) is shutting down
17:34:35.496 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,connector=clientConnectors,connectorName=tcp_//localhost_61618
17:34:35.501 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@6f02cae8[Running, pool size = 1, active threads = 0, queued tasks = 0, completed tasks = 1]
17:34:35.501 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.broker.TransportConnection - Stopped transport: tcp://127.0.0.1:38994
17:34:35.501 [pool-5-thread-7] INFO  o.a.a.broker.TransportConnector - Connector tcp://localhost:61618 stopped
17:34:35.502 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.broker.TransportConnection - Connection Stopped: tcp://127.0.0.1:38994
17:34:35.505 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.MasterBroker
17:34:35.505 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Connection
17:34:35.505 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2
17:34:35.505 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Queue
17:34:35.506 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Producer.Queue.q2
17:34:35.506 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Consumer.Queue.q2
17:34:35.506 [pool-5-thread-7] INFO  o.a.a.s.kahadb.plist.PListStoreImpl - PListStore:[/tmp/1496424871716-0/localhost/tmp_storage] stopped
17:34:35.506 [pool-5-thread-7] INFO  o.a.a.store.kahadb.KahaDBStore - Stopping async queue tasks
17:34:35.506 [pool-5-thread-7] INFO  o.a.a.store.kahadb.KahaDBStore - Stopping async topic tasks
17:34:35.506 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: org.apache.activemq.store.kahadb.KahaDBStore$StoreTaskExecutor@3a4c3fed[Running, pool size = 1, active threads = 0, queued tasks = 0, completed tasks = 10]
17:34:35.506 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: org.apache.activemq.store.kahadb.KahaDBStore$StoreTaskExecutor@ed23104[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:35.506 [pool-5-thread-7] INFO  o.a.a.store.kahadb.KahaDBStore - Stopped KahaDB
17:34:35.506 [pool-5-thread-7] DEBUG o.a.a.store.kahadb.MessageDatabase - Checkpoint started.
17:34:35.535 [pool-5-thread-7] DEBUG o.a.a.store.kahadb.MessageDatabase - Checkpoint done.
17:34:35.557 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ScheduledThreadPoolExecutor@77dd3294[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0] is shutdown: true and terminated: true took: 0.000 seconds.
17:34:35.558 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.Executors$DelegatedScheduledExecutorService@5e670772 is shutdown: true and terminated: true took: 0.000 seconds.
17:34:35.559 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,service=PersistenceAdapter,instanceName=KahaDBPersistenceAdapter[/tmp/1496424871716-0/localhost/KahaDB]
17:34:35.559 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost
17:34:35.559 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,service=Health
17:34:35.559 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,service=Log4JConfiguration
17:34:35.563 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Stopping jmx connector
17:34:35.590 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unexported JMX RMI Registry
17:34:35.591 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@7f0d25f8[Shutting down, pool size = 1, active threads = 0, queued tasks = 0, completed tasks = 36] is shutdown: true and terminated: false took: 0.001 seconds.
17:34:35.591 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@306c1806[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:35.591 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:3) uptime 3.871 seconds
17:34:35.591 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:3) is shutdown
17:34:35.617 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Creating RMIRegistry on port 1099
17:34:35.621 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Probably not using JRE 1.4: mx4j.tools.naming.NamingService
17:34:35.622 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Created JMXConnectorServer javax.management.remote.rmi.RMIConnectorServer@48011b3f
17:34:35.627 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Using Persistence Adapter: KahaDBPersistenceAdapter[/tmp/1496424875613-0/localhost/KahaDB]
17:34:35.629 [pool-5-thread-7] DEBUG o.a.a.store.kahadb.KahaDBStore - Store OpenWire version configured as: 11
17:34:35.630 [JMX connector] DEBUG o.a.a.broker.jmx.ManagementContext - Starting JMXConnectorServer...
17:34:35.692 [JMX connector] INFO  o.a.a.broker.jmx.ManagementContext - JMX consoles can connect to service:jmx:rmi:///jndi/rmi://localhost:1099/jmxrmi
[A[2K[0m[[0minfo[0m] [0mResolving org.jboss.shrinkwrap.resolver#shrinkwrap-resolver-bom;1.0.0-beta-7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.jboss.shrinkwrap.resolver#shrinkwrap-resolver-bom;1.0.0-beta-7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.jboss.shrinkwrap.descriptors#shrinkwrap-descriptors-bom;2.0.0-alpha-3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.jboss.shrinkwrap.descriptors#shrinkwrap-descriptors-bom;2.0.0-alpha-3 ...[0m
17:34:36.361 [pool-5-thread-7] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:36.371 [pool-5-thread-7] INFO  o.a.a.s.kahadb.plist.PListStoreImpl - PListStore:[/tmp/1496424875613-0/localhost/tmp_storage] started
17:34:36.386 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:4) is starting
17:34:36.393 [pool-5-thread-7] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.396 [pool-5-thread-7] INFO  o.a.a.t.TransportServerThreadSupport - Listening for connections at: tcp://localhost:61618
17:34:36.404 [pool-5-thread-7] INFO  o.a.a.broker.TransportConnector - Connector tcp://localhost:61618 started
17:34:36.405 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:4) started
17:34:36.405 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - For help or more information please see: http://activemq.apache.org
17:34:36.405 [pool-5-thread-7] WARN  o.a.activemq.broker.BrokerService - Store limit is 102400 mb (current store usage is 0 mb). The data directory: /tmp/1496424875613-0/localhost/KahaDB only has 14180 mb of usable space. - resetting to maximum available disk space: 14180 mb
17:34:36.405 [pool-5-thread-7] WARN  o.a.activemq.broker.BrokerService - Temporary Store limit is 51200 mb (current store usage is 0 mb). The data directory: /tmp/1496424875613-0/localhost only has 14180 mb of usable space. - resetting to maximum available disk space: 14180 mb
17:34:36.405 [pool-5-thread-7] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.MasterBroker
17:34:36.406 [pool-5-thread-7] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ BrokerService[localhost] Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@29a47ba9[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:36.410 [pool-5-thread-7] DEBUG ForkLift - Creating ForkLift
17:34:36.411 [pool-5-thread-7] DEBUG ForkLift - Init complete!
17:34:36.411 [pool-5-thread-7] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@7f3f56bb[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:36.411 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Reconnect was triggered but transport is not started yet. Wait for start to connect the transport.
17:34:36.411 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Started unconnected
17:34:36.411 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Waking up reconnect task
17:34:36.414 [ActiveMQ Task-1] DEBUG o.a.a.t.failover.FailoverTransport - urlList connectionList:[tcp://127.0.0.1:61618], from: [tcp://127.0.0.1:61618]
17:34:36.414 [ActiveMQ Task-1] DEBUG o.a.a.t.failover.FailoverTransport - Attempting 0th connect to: tcp://127.0.0.1:61618
17:34:36.422 [ActiveMQ Task-1] DEBUG o.a.a.transport.WireFormatNegotiator - Sending: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:36.422 [ActiveMQ Task-1] DEBUG o.a.a.t.failover.FailoverTransport - Connection established
17:34:36.422 [ActiveMQ Task-1] INFO  o.a.a.t.failover.FailoverTransport - Successfully connected to tcp://127.0.0.1:61618
17:34:36.426 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.transport.WireFormatNegotiator - Sending: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:36.443 [ActiveMQ Transport: tcp:///127.0.0.1:61618@39052] DEBUG o.a.a.transport.InactivityMonitor - Using min of local: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]} and remote: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:36.448 [ActiveMQ Transport: tcp:///127.0.0.1:61618@39052] DEBUG o.a.a.transport.WireFormatNegotiator - Received WireFormat: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:36.448 [ActiveMQ Transport: tcp:///127.0.0.1:61618@39052] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:61618@39052 before negotiation: OpenWireFormat{version=12, cacheEnabled=false, stackTraceEnabled=false, tightEncodingEnabled=false, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:36.449 [ActiveMQ Transport: tcp:///127.0.0.1:61618@39052] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:61618@39052 after negotiation: OpenWireFormat{version=12, cacheEnabled=true, stackTraceEnabled=true, tightEncodingEnabled=true, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:36.452 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.transport.InactivityMonitor - Using min of local: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]} and remote: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:36.452 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.transport.WireFormatNegotiator - Received WireFormat: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:36.452 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:39052@61618 before negotiation: OpenWireFormat{version=12, cacheEnabled=false, stackTraceEnabled=false, tightEncodingEnabled=false, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:36.453 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:39052@61618 after negotiation: OpenWireFormat{version=12, cacheEnabled=true, stackTraceEnabled=true, tightEncodingEnabled=true, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:36.454 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnection - Setting up new connection id: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13:1, address: tcp://127.0.0.1:39052, info: ConnectionInfo {commandId = 1, responseRequired = true, connectionId = ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13:1, clientId = ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-12:1, clientIp = null, userName = , password = *****, brokerPath = null, brokerMasterConnector = false, manageable = true, clientMaster = true, faultTolerant = true, failoverReconnect = false}
17:34:36.463 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.464 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.473 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Connection
17:34:36.536 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13:1:-1:1 for destination: ActiveMQ.Advisory.TempQueue,ActiveMQ.Advisory.TempTopic
17:34:36.548 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: queue://q2
17:34:36.557 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:36.557 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:36.558 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:36.558 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:36.558 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:36.579 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 0, dequeueCount: 0, memUsage:0, maxPageSize:200
17:34:36.579 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.579 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.579 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Queue
17:34:36.593 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.593 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.593 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Producer.Queue.q2
17:34:36.636 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13:1:1:1:1 sent to queue://q2
17:34:36.646 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=1, pending=0 toPageIn: 1, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 1, dequeueCount: 0, memUsage:2152, maxPageSize:200
17:34:36.658 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13:1:1:1:2 sent to queue://q2
17:34:36.658 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=2, pending=0 toPageIn: 2, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 2, dequeueCount: 0, memUsage:4304, maxPageSize:200
17:34:36.709 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13:1:1:1:3 sent to queue://q2
17:34:36.712 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13:1:1:1:4 sent to queue://q2
17:34:36.712 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=4, pending=0 toPageIn: 4, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 4, dequeueCount: 0, memUsage:5380, maxPageSize:200
17:34:36.712 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=4, pending=0 toPageIn: 4, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 4, dequeueCount: 0, memUsage:5380, maxPageSize:200
17:34:36.714 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13:1:1:1:5 sent to queue://q2
17:34:36.714 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=5, pending=0 toPageIn: 5, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 5, dequeueCount: 0, memUsage:7532, maxPageSize:200
17:34:36.737 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13:1:1:1:6 sent to queue://q2
17:34:36.737 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=6, pending=0 toPageIn: 6, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 6, dequeueCount: 0, memUsage:8608, maxPageSize:200
17:34:36.745 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13:1:1:1:7 sent to queue://q2
17:34:36.745 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=7, pending=0 toPageIn: 7, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 7, dequeueCount: 0, memUsage:9684, maxPageSize:200
17:34:36.749 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13:1:1:1:8 sent to queue://q2
17:34:36.749 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=8, pending=0 toPageIn: 8, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 8, dequeueCount: 0, memUsage:10760, maxPageSize:200
17:34:36.757 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13:1:1:1:9 sent to queue://q2
17:34:36.758 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=9, pending=0 toPageIn: 9, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 9, dequeueCount: 0, memUsage:11836, maxPageSize:200
17:34:36.759 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13:1:1:1:10 sent to queue://q2
17:34:36.760 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=10, pending=0 toPageIn: 10, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 0, memUsage:12912, maxPageSize:200
17:34:36.782 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13:1:2:1 for destination: queue://q2
17:34:36.785 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.activemq.broker.region.Queue - queue://q2 add sub: QueueSubscription: consumer=ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13:1:2:1, destinations=0, dispatched=0, delivered=0, pending=0, dequeues: 0, dispatched: 0, inflight: 0
17:34:36.786 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 10, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 0, memUsage:10760, maxPageSize:200
17:34:36.786 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.786 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.786 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Consumer.Queue.q2
17:34:36.796 [pool-5-thread-7] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Session Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@1925ef73[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:36.804 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.804 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@7e5e84b3
0 -:- 0 || false
bar -:- FOO
JMSCorrelationsID -:- 0
17:34:36.817 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-12_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13_1_3_1
17:34:36.817 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.817 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.819 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.819 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@39138e0
1 -:- 1 || false
bar -:- FOO
JMSCorrelationsID -:- 1
17:34:36.820 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-12_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13_1_4_1
17:34:36.821 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=8, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 1, memUsage:9684, maxPageSize:200
17:34:36.821 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.821 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.821 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=8, pending=0 toPageIn: 0, force:false, Inflight: 8, pagedInMessages.size 8, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 2, memUsage:8608, maxPageSize:200
17:34:36.821 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=8, pending=0 toPageIn: 0, force:false, Inflight: 8, pagedInMessages.size 8, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 2, memUsage:8608, maxPageSize:200
17:34:36.821 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=8, pending=0 toPageIn: 0, force:false, Inflight: 8, pagedInMessages.size 8, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 2, memUsage:8608, maxPageSize:200
17:34:36.825 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=8, pending=0 toPageIn: 0, force:false, Inflight: 8, pagedInMessages.size 8, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 2, memUsage:8608, maxPageSize:200
17:34:36.826 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.826 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@6bb74b12
2 -:- 2 || false
bar -:- FOO
JMSCorrelationsID -:- 2
17:34:36.829 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-12_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13_1_5_1
17:34:36.829 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=7, pending=0 toPageIn: 0, force:false, Inflight: 7, pagedInMessages.size 7, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 3, memUsage:7532, maxPageSize:200
17:34:36.829 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=7, pending=0 toPageIn: 0, force:false, Inflight: 7, pagedInMessages.size 7, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 3, memUsage:7532, maxPageSize:200
17:34:36.829 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=7, pending=0 toPageIn: 0, force:false, Inflight: 7, pagedInMessages.size 7, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 3, memUsage:7532, maxPageSize:200
17:34:36.829 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.829 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.831 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.831 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@1c553679
3 -:- 3 || false
bar -:- FOO
JMSCorrelationsID -:- 3
17:34:36.833 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=6, pending=0 toPageIn: 0, force:false, Inflight: 6, pagedInMessages.size 6, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 4, memUsage:6456, maxPageSize:200
17:34:36.833 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=6, pending=0 toPageIn: 0, force:false, Inflight: 6, pagedInMessages.size 6, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 4, memUsage:6456, maxPageSize:200
17:34:36.834 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-12_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13_1_6_1
17:34:36.834 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.834 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.836 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.836 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@1d79423f
4 -:- 4 || false
bar -:- FOO
JMSCorrelationsID -:- 4
17:34:36.838 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=5, pending=0 toPageIn: 0, force:false, Inflight: 5, pagedInMessages.size 5, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 5, memUsage:5380, maxPageSize:200
17:34:36.838 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=5, pending=0 toPageIn: 0, force:false, Inflight: 5, pagedInMessages.size 5, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 5, memUsage:5380, maxPageSize:200
17:34:36.838 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-12_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13_1_7_1
17:34:36.839 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.839 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.840 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.840 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@742c5182
5 -:- 5 || false
bar -:- FOO
JMSCorrelationsID -:- 5
17:34:36.842 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=4, pending=0 toPageIn: 0, force:false, Inflight: 4, pagedInMessages.size 4, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 6, memUsage:4304, maxPageSize:200
17:34:36.842 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-12_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13_1_8_1
17:34:36.842 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=4, pending=0 toPageIn: 0, force:false, Inflight: 4, pagedInMessages.size 4, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 6, memUsage:4304, maxPageSize:200
17:34:36.842 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.842 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.844 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.844 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@54583e9f
6 -:- 6 || false
bar -:- FOO
JMSCorrelationsID -:- 6
17:34:36.845 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=3, pending=0 toPageIn: 0, force:false, Inflight: 3, pagedInMessages.size 3, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 7, memUsage:3228, maxPageSize:200
17:34:36.845 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=3, pending=0 toPageIn: 0, force:false, Inflight: 3, pagedInMessages.size 3, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 7, memUsage:3228, maxPageSize:200
17:34:36.846 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-12_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13_1_9_1
17:34:36.846 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.846 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.847 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.847 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@79a3af1e
7 -:- 7 || false
bar -:- FOO
JMSCorrelationsID -:- 7
17:34:36.849 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=2, pending=0 toPageIn: 0, force:false, Inflight: 2, pagedInMessages.size 2, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 8, memUsage:2152, maxPageSize:200
17:34:36.849 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=2, pending=0 toPageIn: 0, force:false, Inflight: 2, pagedInMessages.size 2, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 8, memUsage:2152, maxPageSize:200
17:34:36.849 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-12_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13_1_10_1
17:34:36.849 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.849 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.857 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.857 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@50a29aea
8 -:- 8 || false
bar -:- FOO
JMSCorrelationsID -:- 8
17:34:36.859 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-12_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13_1_11_1
17:34:36.859 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=1, pending=0 toPageIn: 0, force:false, Inflight: 1, pagedInMessages.size 1, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 9, memUsage:1076, maxPageSize:200
17:34:36.860 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=1, pending=0 toPageIn: 0, force:false, Inflight: 1, pagedInMessages.size 1, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 9, memUsage:1076, maxPageSize:200
17:34:36.860 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=1, pending=0 toPageIn: 0, force:false, Inflight: 1, pagedInMessages.size 1, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 9, memUsage:1076, maxPageSize:200
17:34:36.860 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.860 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.862 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.862 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@71543106
9 -:- 9 || false
bar -:- FOO
JMSCorrelationsID -:- 9
17:34:36.863 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 10, memUsage:0, maxPageSize:200
17:34:36.863 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 10, memUsage:0, maxPageSize:200
17:34:36.863 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-12_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13_1_12_1
17:34:36.863 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:36.863 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
[A[2K[0m[[0minfo[0m] [0mResolving org.jboss.logging#jboss-logging;3.1.3.GA ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.jboss.logging#jboss-logging;3.1.3.GA ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.jboss#jboss-parent;9 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.jboss#jboss-parent;9 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml#classmate;1.0.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml#classmate;1.0.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.oss#oss-parent;7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving javax.el#javax.el-api;2.2.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving javax.el#javax.el-api;2.2.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving net.java#jvnet-parent;1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving net.java#jvnet-parent;1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.web#javax.el;2.2.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.web#javax.el;2.2.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving net.java#jvnet-parent;1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving io.confluent#rest-utils;3.1.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving io.confluent#rest-utils;3.1.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving io.confluent#rest-utils-parent;3.1.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving io.confluent#rest-utils-parent;3.1.1 ...[0m
17:34:39.363 [pool-5-thread-7] INFO  forklift.consumer.Consumer - Consumer shutting down
17:34:39.363 [pool-5-thread-7] DEBUG o.a.activemq.ActiveMQMessageConsumer - remove: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13:1:2:1, lastDeliveredSequenceId: 14
17:34:39.363 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Consumer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-12_1,consumerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13_1_2_1
17:34:39.364 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost removing consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13:1:2:1 for destination: queue://q2
17:34:39.391 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.activemq.broker.region.Queue - queue://q2 remove sub: QueueSubscription: consumer=ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13:1:2:1, destinations=1, dispatched=0, delivered=0, pending=0, lastDeliveredSeqId: 14, dequeues: 10, dispatched: 10, inflight: 0, groups: 0
17:34:39.392 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 10, memUsage:0, maxPageSize:200
17:34:39.393 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:39.393 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:39.396 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.TempQueue_ActiveMQ.Advisory.TempTopic,endpoint=Consumer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-12_1,consumerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13_1_-1_1
17:34:39.396 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost removing consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13:1:-1:1 for destination: ActiveMQ.Advisory.TempQueue,ActiveMQ.Advisory.TempTopic
17:34:39.397 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnection - remove connection id: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13:1
17:34:39.397 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-12_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-13_1_1_1
17:34:39.401 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:39.401 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:39.401 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:39.401 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:39.401 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@1925ef73[Shutting down, pool size = 1, active threads = 0, queued tasks = 0, completed tasks = 4] is shutdown: true and terminated: false took: 0.000 seconds.
17:34:39.401 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,connector=clientConnectors,connectorName=tcp_//localhost_61618,connectionViewType=clientId,connectionName=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-12_1
17:34:39.402 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@70808001[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0] is shutdown: true and terminated: true took: 0.000 seconds.
17:34:39.403 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Stopped tcp://127.0.0.1:61618
17:34:39.404 [ActiveMQ Transport: tcp:///127.0.0.1:39052@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,connector=clientConnectors,connectorName=tcp_//localhost_61618,connectionViewType=remoteAddress,connectionName=tcp_//127.0.0.1_39052
17:34:39.404 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@7f3f56bb[Running, pool size = 2, active threads = 0, queued tasks = 0, completed tasks = 2]
17:34:39.404 [pool-5-thread-7] DEBUG o.a.a.transport.tcp.TcpTransport - Stopping transport tcp:///127.0.0.1:61618@39052
17:34:39.404 [pool-5-thread-7] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@7ede4099[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:39.405 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.a.broker.TransportConnection - Stopping connection: tcp://127.0.0.1:39052
17:34:39.405 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.a.transport.tcp.TcpTransport - Stopping transport tcp:///127.0.0.1:39052@61618
17:34:39.405 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@6e4c60b8[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:39.405 [ActiveMQ Task-1] DEBUG o.a.a.transport.tcp.TcpTransport - Closed socket Socket[addr=/127.0.0.1,port=61618,localport=39052]
17:34:39.406 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@7ede4099[Running, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 0]
17:34:39.416 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:4) is shutting down
17:34:39.417 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,connector=clientConnectors,connectorName=tcp_//localhost_61618
17:34:39.420 [pool-5-thread-7] INFO  o.a.a.broker.TransportConnector - Connector tcp://localhost:61618 stopped
17:34:39.420 [ActiveMQ Task-1] DEBUG o.a.a.transport.tcp.TcpTransport - Closed socket Socket[addr=/127.0.0.1,port=39052,localport=61618]
17:34:39.423 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@6e4c60b8[Running, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 0]
17:34:39.423 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.a.broker.TransportConnection - Stopped transport: tcp://127.0.0.1:39052
17:34:39.423 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.a.broker.TransportConnection - Connection Stopped: tcp://127.0.0.1:39052
17:34:39.424 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.MasterBroker
17:34:39.424 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Connection
17:34:39.424 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2
17:34:39.424 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Queue
17:34:39.424 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Producer.Queue.q2
17:34:39.424 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Consumer.Queue.q2
17:34:39.424 [pool-5-thread-7] INFO  o.a.a.s.kahadb.plist.PListStoreImpl - PListStore:[/tmp/1496424875613-0/localhost/tmp_storage] stopped
17:34:39.425 [pool-5-thread-7] INFO  o.a.a.store.kahadb.KahaDBStore - Stopping async queue tasks
17:34:39.425 [pool-5-thread-7] INFO  o.a.a.store.kahadb.KahaDBStore - Stopping async topic tasks
17:34:39.425 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: org.apache.activemq.store.kahadb.KahaDBStore$StoreTaskExecutor@3d04cef3[Running, pool size = 1, active threads = 0, queued tasks = 0, completed tasks = 10]
17:34:39.425 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: org.apache.activemq.store.kahadb.KahaDBStore$StoreTaskExecutor@bf99247[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:39.425 [pool-5-thread-7] INFO  o.a.a.store.kahadb.KahaDBStore - Stopped KahaDB
17:34:39.425 [pool-5-thread-7] DEBUG o.a.a.store.kahadb.MessageDatabase - Checkpoint started.
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey#jersey-bom;2.19 ...[0m
17:34:39.442 [pool-5-thread-7] DEBUG o.a.a.store.kahadb.MessageDatabase - Checkpoint done.
17:34:39.462 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ScheduledThreadPoolExecutor@15cdd12d[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0] is shutdown: true and terminated: true took: 0.000 seconds.
17:34:39.466 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.Executors$DelegatedScheduledExecutorService@2d39418e is shutdown: true and terminated: true took: 0.002 seconds.
17:34:39.467 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,service=PersistenceAdapter,instanceName=KahaDBPersistenceAdapter[/tmp/1496424875613-0/localhost/KahaDB]
17:34:39.467 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost
17:34:39.467 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,service=Health
17:34:39.467 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,service=Log4JConfiguration
17:34:39.467 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Stopping jmx connector
17:34:39.472 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unexported JMX RMI Registry
17:34:39.475 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@29a47ba9[Shutting down, pool size = 1, active threads = 0, queued tasks = 0, completed tasks = 33] is shutdown: true and terminated: false took: 0.003 seconds.
17:34:39.475 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@245e985b[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:39.476 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:4) uptime 3.862 seconds
17:34:39.476 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:4) is shutdown
17:34:39.497 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Creating RMIRegistry on port 1099
17:34:39.498 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Probably not using JRE 1.4: mx4j.tools.naming.NamingService
17:34:39.499 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Created JMXConnectorServer javax.management.remote.rmi.RMIConnectorServer@38b36e17
17:34:39.508 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Using Persistence Adapter: KahaDBPersistenceAdapter[/tmp/1496424879492-0/localhost/KahaDB]
17:34:39.509 [JMX connector] DEBUG o.a.a.broker.jmx.ManagementContext - Starting JMXConnectorServer...
17:34:39.511 [pool-5-thread-7] DEBUG o.a.a.store.kahadb.KahaDBStore - Store OpenWire version configured as: 11
17:34:39.562 [JMX connector] INFO  o.a.a.broker.jmx.ManagementContext - JMX consoles can connect to service:jmx:rmi:///jndi/rmi://localhost:1099/jmxrmi
[A[2K[0m[[0minfo[0m] [0mResolving io.confluent#common-metrics;3.1.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving io.confluent#common-metrics;3.1.1 ...[0m
17:34:40.038 [pool-5-thread-7] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:40.045 [pool-5-thread-7] INFO  o.a.a.s.kahadb.plist.PListStoreImpl - PListStore:[/tmp/1496424879492-0/localhost/tmp_storage] started
17:34:40.053 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:5) is starting
17:34:40.055 [pool-5-thread-7] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.056 [pool-5-thread-7] INFO  o.a.a.t.TransportServerThreadSupport - Listening for connections at: tcp://localhost:61618
17:34:40.056 [pool-5-thread-7] INFO  o.a.a.broker.TransportConnector - Connector tcp://localhost:61618 started
17:34:40.056 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:5) started
17:34:40.056 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - For help or more information please see: http://activemq.apache.org
17:34:40.056 [pool-5-thread-7] WARN  o.a.activemq.broker.BrokerService - Store limit is 102400 mb (current store usage is 0 mb). The data directory: /tmp/1496424879492-0/localhost/KahaDB only has 14179 mb of usable space. - resetting to maximum available disk space: 14179 mb
17:34:40.056 [pool-5-thread-7] WARN  o.a.activemq.broker.BrokerService - Temporary Store limit is 51200 mb (current store usage is 0 mb). The data directory: /tmp/1496424879492-0/localhost only has 14179 mb of usable space. - resetting to maximum available disk space: 14179 mb
17:34:40.057 [pool-5-thread-7] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.MasterBroker
17:34:40.058 [pool-5-thread-7] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ BrokerService[localhost] Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@2e615b4d[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:40.065 [pool-5-thread-7] DEBUG ForkLift - Creating ForkLift
17:34:40.065 [pool-5-thread-7] DEBUG ForkLift - Init complete!
17:34:40.065 [pool-5-thread-7] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@36925e41[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:40.065 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Reconnect was triggered but transport is not started yet. Wait for start to connect the transport.
17:34:40.065 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Started unconnected
17:34:40.065 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Waking up reconnect task
17:34:40.069 [ActiveMQ Task-1] DEBUG o.a.a.t.failover.FailoverTransport - urlList connectionList:[tcp://127.0.0.1:61618], from: [tcp://127.0.0.1:61618]
17:34:40.070 [ActiveMQ Task-1] DEBUG o.a.a.t.failover.FailoverTransport - Attempting 0th connect to: tcp://127.0.0.1:61618
17:34:40.073 [ActiveMQ Task-1] DEBUG o.a.a.transport.WireFormatNegotiator - Sending: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:40.073 [ActiveMQ Task-1] DEBUG o.a.a.t.failover.FailoverTransport - Connection established
17:34:40.073 [ActiveMQ Task-1] INFO  o.a.a.t.failover.FailoverTransport - Successfully connected to tcp://127.0.0.1:61618
17:34:40.078 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.transport.WireFormatNegotiator - Sending: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:40.087 [ActiveMQ Transport: tcp:///127.0.0.1:61618@39074] DEBUG o.a.a.transport.InactivityMonitor - Using min of local: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]} and remote: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:40.087 [ActiveMQ Transport: tcp:///127.0.0.1:61618@39074] DEBUG o.a.a.transport.WireFormatNegotiator - Received WireFormat: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:40.088 [ActiveMQ Transport: tcp:///127.0.0.1:61618@39074] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:61618@39074 before negotiation: OpenWireFormat{version=12, cacheEnabled=false, stackTraceEnabled=false, tightEncodingEnabled=false, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:40.088 [ActiveMQ Transport: tcp:///127.0.0.1:61618@39074] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:61618@39074 after negotiation: OpenWireFormat{version=12, cacheEnabled=true, stackTraceEnabled=true, tightEncodingEnabled=true, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:40.095 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.transport.InactivityMonitor - Using min of local: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]} and remote: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:40.095 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.transport.WireFormatNegotiator - Received WireFormat: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:40.096 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:39074@61618 before negotiation: OpenWireFormat{version=12, cacheEnabled=false, stackTraceEnabled=false, tightEncodingEnabled=false, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:40.096 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:39074@61618 after negotiation: OpenWireFormat{version=12, cacheEnabled=true, stackTraceEnabled=true, tightEncodingEnabled=true, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:40.101 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnection - Setting up new connection id: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16:1, address: tcp://127.0.0.1:39074, info: ConnectionInfo {commandId = 1, responseRequired = true, connectionId = ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16:1, clientId = ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-15:1, clientIp = null, userName = , password = *****, brokerPath = null, brokerMasterConnector = false, manageable = true, clientMaster = true, faultTolerant = true, failoverReconnect = false}
17:34:40.101 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.101 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.101 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Connection
17:34:40.152 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16:1:-1:1 for destination: ActiveMQ.Advisory.TempQueue,ActiveMQ.Advisory.TempTopic
17:34:40.174 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: queue://q2
17:34:40.178 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:40.178 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:40.178 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:40.178 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:40.178 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
[A[2K[0m[[0minfo[0m] [0mResolving io.confluent#common;3.1.1 ...[0m
17:34:40.295 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 0, dequeueCount: 0, memUsage:0, maxPageSize:200
17:34:40.295 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.295 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.295 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Queue
17:34:40.317 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.317 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.317 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Producer.Queue.q2
17:34:40.360 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16:1:1:1:1 sent to queue://q2
17:34:40.392 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=1, pending=0 toPageIn: 1, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 1, dequeueCount: 0, memUsage:2126, maxPageSize:200
17:34:40.435 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16:1:1:1:2 sent to queue://q2
17:34:40.435 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=2, pending=0 toPageIn: 2, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 2, dequeueCount: 0, memUsage:3189, maxPageSize:200
17:34:40.439 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16:1:1:1:3 sent to queue://q2
17:34:40.439 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=3, pending=0 toPageIn: 3, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 3, dequeueCount: 0, memUsage:4252, maxPageSize:200
17:34:40.446 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16:1:1:1:4 sent to queue://q2
17:34:40.446 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=4, pending=0 toPageIn: 4, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 4, dequeueCount: 0, memUsage:5315, maxPageSize:200
17:34:40.458 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16:1:1:1:5 sent to queue://q2
17:34:40.458 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=5, pending=0 toPageIn: 5, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 5, dequeueCount: 0, memUsage:6378, maxPageSize:200
17:34:40.460 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16:1:1:1:6 sent to queue://q2
17:34:40.460 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=6, pending=0 toPageIn: 6, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 6, dequeueCount: 0, memUsage:7441, maxPageSize:200
17:34:40.465 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16:1:1:1:7 sent to queue://q2
17:34:40.466 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=7, pending=0 toPageIn: 7, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 7, dequeueCount: 0, memUsage:8504, maxPageSize:200
17:34:40.478 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16:1:1:1:8 sent to queue://q2
17:34:40.478 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=8, pending=0 toPageIn: 8, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 8, dequeueCount: 0, memUsage:9567, maxPageSize:200
17:34:40.481 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16:1:1:1:9 sent to queue://q2
17:34:40.482 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=9, pending=0 toPageIn: 9, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 9, dequeueCount: 0, memUsage:10630, maxPageSize:200
17:34:40.483 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16:1:1:1:10 sent to queue://q2
17:34:40.484 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=10, pending=0 toPageIn: 10, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 0, memUsage:11693, maxPageSize:200
17:34:40.491 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16:1:2:1 for destination: queue://q2
17:34:40.495 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.activemq.broker.region.Queue - queue://q2 add sub: QueueSubscription: consumer=ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16:1:2:1, destinations=0, dispatched=0, delivered=0, pending=0, dequeues: 0, dispatched: 0, inflight: 0
17:34:40.504 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 10, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 0, memUsage:10630, maxPageSize:200
17:34:40.507 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.507 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.507 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Consumer.Queue.q2
17:34:40.510 [ActiveMQ Transport: tcp:///127.0.0.1:61618@39074] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Session Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@7c010439[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:40.540 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.541 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@1fd6f664
fbf7aa5d102e4b56b4c82185d520c2dc -:- 0
17:34:40.561 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-15_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16_1_3_1
17:34:40.563 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.563 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.565 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.566 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@627404d2
de9398fa544040eab7e9c668fc5381e0 -:- 1
17:34:40.568 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-15_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16_1_4_1
17:34:40.614 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.614 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey.containers#jersey-container-servlet;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey.containers#jersey-container-servlet;2.19 ...[0m
17:34:40.624 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=8, pending=0 toPageIn: 0, force:false, Inflight: 8, pagedInMessages.size 8, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 2, memUsage:8504, maxPageSize:200
17:34:40.625 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=8, pending=0 toPageIn: 0, force:false, Inflight: 8, pagedInMessages.size 8, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 2, memUsage:8504, maxPageSize:200
17:34:40.625 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=8, pending=0 toPageIn: 0, force:false, Inflight: 8, pagedInMessages.size 8, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 2, memUsage:8504, maxPageSize:200
17:34:40.625 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=8, pending=0 toPageIn: 0, force:false, Inflight: 8, pagedInMessages.size 8, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 2, memUsage:8504, maxPageSize:200
17:34:40.628 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.628 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.628 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=8, pending=0 toPageIn: 0, force:false, Inflight: 8, pagedInMessages.size 8, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 2, memUsage:8504, maxPageSize:200
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@67bec70e
d863de1a58a74376b67c2c372278a7cb -:- 2
17:34:40.648 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-15_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16_1_5_1
17:34:40.648 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.648 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.654 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.654 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@700fd45a
34ee7bf354634f939bc7632613ea40f6 -:- 3
17:34:40.656 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=7, pending=0 toPageIn: 0, force:false, Inflight: 7, pagedInMessages.size 7, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 3, memUsage:7441, maxPageSize:200
17:34:40.656 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=7, pending=0 toPageIn: 0, force:false, Inflight: 7, pagedInMessages.size 7, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 3, memUsage:7441, maxPageSize:200
17:34:40.659 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=6, pending=0 toPageIn: 0, force:false, Inflight: 6, pagedInMessages.size 6, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 4, memUsage:6378, maxPageSize:200
17:34:40.660 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=6, pending=0 toPageIn: 0, force:false, Inflight: 6, pagedInMessages.size 6, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 4, memUsage:6378, maxPageSize:200
17:34:40.660 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-15_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16_1_6_1
17:34:40.660 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.660 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.662 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.662 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@35d58bd5
093193e5e95b48a4b34bd57289fab055 -:- 4
17:34:40.664 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=5, pending=0 toPageIn: 0, force:false, Inflight: 5, pagedInMessages.size 5, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 5, memUsage:5315, maxPageSize:200
17:34:40.668 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=5, pending=0 toPageIn: 0, force:false, Inflight: 5, pagedInMessages.size 5, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 5, memUsage:5315, maxPageSize:200
17:34:40.669 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-15_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16_1_7_1
17:34:40.669 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.669 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.671 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.671 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@7181ea66
9b2867bc91f049e28116cc7b39ffbbdb -:- 5
17:34:40.692 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=4, pending=0 toPageIn: 0, force:false, Inflight: 4, pagedInMessages.size 4, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 6, memUsage:4252, maxPageSize:200
17:34:40.693 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=4, pending=0 toPageIn: 0, force:false, Inflight: 4, pagedInMessages.size 4, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 6, memUsage:4252, maxPageSize:200
17:34:40.693 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-15_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16_1_8_1
17:34:40.693 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.693 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.695 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.695 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@59176fda
011d0b386b914b7e8c217a027be13d04 -:- 6
17:34:40.716 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=3, pending=0 toPageIn: 0, force:false, Inflight: 3, pagedInMessages.size 3, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 7, memUsage:3189, maxPageSize:200
17:34:40.717 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-15_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16_1_9_1
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey.containers#project;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey.containers#project;2.19 ...[0m
17:34:40.745 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=3, pending=0 toPageIn: 0, force:false, Inflight: 3, pagedInMessages.size 3, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 7, memUsage:3189, maxPageSize:200
17:34:40.745 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=3, pending=0 toPageIn: 0, force:false, Inflight: 3, pagedInMessages.size 3, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 7, memUsage:3189, maxPageSize:200
17:34:40.745 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.745 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.749 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.750 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@4a928233
55499acafc604aeaa447624e77148459 -:- 7
17:34:40.778 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=2, pending=0 toPageIn: 0, force:false, Inflight: 2, pagedInMessages.size 2, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 8, memUsage:2126, maxPageSize:200
17:34:40.779 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=2, pending=0 toPageIn: 0, force:false, Inflight: 2, pagedInMessages.size 2, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 8, memUsage:2126, maxPageSize:200
17:34:40.779 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-15_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16_1_10_1
17:34:40.787 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.788 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey#project;2.19 ...[0m
17:34:40.827 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.827 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@460b0a07
ad597430a45b440eafe08040f266d8b1 -:- 8
17:34:40.845 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=1, pending=0 toPageIn: 0, force:false, Inflight: 1, pagedInMessages.size 1, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 9, memUsage:1063, maxPageSize:200
17:34:40.845 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=1, pending=0 toPageIn: 0, force:false, Inflight: 1, pagedInMessages.size 1, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 9, memUsage:1063, maxPageSize:200
17:34:40.846 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-15_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16_1_11_1
17:34:40.846 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.846 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.854 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.854 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@58c81979
f464e9c2484f4b0890cb83f9ce39de45 -:- 9
17:34:40.901 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 10, memUsage:0, maxPageSize:200
17:34:40.901 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 10, memUsage:0, maxPageSize:200
17:34:40.902 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-15_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16_1_12_1
17:34:40.902 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:40.902 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey.containers#jersey-container-servlet-core;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey.containers#jersey-container-servlet-core;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.glassfish.jersey.containers#project;2.19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-jmx;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-jmx;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-project;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-project;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-parent;23 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-parent;23 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-util;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-util;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-project;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-server;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-server;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-project;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving javax.servlet#javax.servlet-api;3.1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving javax.servlet#javax.servlet-api;3.1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving net.java#jvnet-parent;3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-http;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-http;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-project;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-io;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-io;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-project;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-servlet;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-servlet;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-project;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-security;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-security;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-project;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-servlets;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-servlets;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-project;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-continuation;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-continuation;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-project;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-jaas;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-jaas;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.eclipse.jetty#jetty-project;9.2.12.v20150709 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.jaxrs#jackson-jaxrs-json-provider;2.5.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.jaxrs#jackson-jaxrs-json-provider;2.5.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.jaxrs#jackson-jaxrs-providers;2.5.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.jaxrs#jackson-jaxrs-providers;2.5.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson#jackson-parent;2.5.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson#jackson-parent;2.5.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml#oss-parent;19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml#oss-parent;19 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.jaxrs#jackson-jaxrs-base;2.5.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.jaxrs#jackson-jaxrs-base;2.5.4 ...[0m
17:34:43.378 [pool-5-thread-7] INFO  forklift.consumer.Consumer - Consumer shutting down
17:34:43.378 [pool-5-thread-7] DEBUG o.a.activemq.ActiveMQMessageConsumer - remove: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16:1:2:1, lastDeliveredSequenceId: 14
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.jaxrs#jackson-jaxrs-providers;2.5.4 ...[0m
17:34:43.380 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Consumer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-15_1,consumerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16_1_2_1
17:34:43.380 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost removing consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16:1:2:1 for destination: queue://q2
17:34:43.380 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.activemq.broker.region.Queue - queue://q2 remove sub: QueueSubscription: consumer=ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16:1:2:1, destinations=1, dispatched=0, delivered=0, pending=0, lastDeliveredSeqId: 14, dequeues: 10, dispatched: 10, inflight: 0, groups: 0
17:34:43.381 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 10, memUsage:0, maxPageSize:200
17:34:43.381 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:43.381 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:43.381 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.TempQueue_ActiveMQ.Advisory.TempTopic,endpoint=Consumer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-15_1,consumerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16_1_-1_1
17:34:43.381 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost removing consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16:1:-1:1 for destination: ActiveMQ.Advisory.TempQueue,ActiveMQ.Advisory.TempTopic
17:34:43.382 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnection - remove connection id: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16:1
17:34:43.382 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-15_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-16_1_1_1
17:34:43.382 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:43.382 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:43.382 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:43.382 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:43.392 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@7c010439[Shutting down, pool size = 1, active threads = 0, queued tasks = 0, completed tasks = 2] is shutdown: true and terminated: false took: 0.000 seconds.
17:34:43.392 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,connector=clientConnectors,connectorName=tcp_//localhost_61618,connectionViewType=clientId,connectionName=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-15_1
17:34:43.396 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@44993909[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0] is shutdown: true and terminated: true took: 0.000 seconds.
17:34:43.397 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Stopped tcp://127.0.0.1:61618
17:34:43.397 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@36925e41[Running, pool size = 2, active threads = 0, queued tasks = 0, completed tasks = 2]
17:34:43.397 [pool-5-thread-7] DEBUG o.a.a.transport.tcp.TcpTransport - Stopping transport tcp:///127.0.0.1:61618@39074
17:34:43.398 [pool-5-thread-7] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@638b2f8b[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:43.398 [ActiveMQ Transport: tcp:///127.0.0.1:39074@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,connector=clientConnectors,connectorName=tcp_//localhost_61618,connectionViewType=remoteAddress,connectionName=tcp_//127.0.0.1_39074
17:34:43.398 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.broker.TransportConnection - Stopping connection: tcp://127.0.0.1:39074
17:34:43.398 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.transport.tcp.TcpTransport - Stopping transport tcp:///127.0.0.1:39074@61618
17:34:43.398 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@6105fc05[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:43.401 [ActiveMQ Task-1] DEBUG o.a.a.transport.tcp.TcpTransport - Closed socket Socket[addr=/127.0.0.1,port=61618,localport=39074]
17:34:43.401 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@638b2f8b[Running, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 0]
17:34:43.423 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:5) is shutting down
17:34:43.424 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,connector=clientConnectors,connectorName=tcp_//localhost_61618
17:34:43.424 [ActiveMQ Task-1] DEBUG o.a.a.transport.tcp.TcpTransport - Closed socket Socket[addr=/127.0.0.1,port=39074,localport=61618]
17:34:43.424 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@6105fc05[Running, pool size = 1, active threads = 0, queued tasks = 0, completed tasks = 1]
17:34:43.425 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.broker.TransportConnection - Stopped transport: tcp://127.0.0.1:39074
17:34:43.425 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.broker.TransportConnection - Connection Stopped: tcp://127.0.0.1:39074
17:34:43.429 [pool-5-thread-7] INFO  o.a.a.broker.TransportConnector - Connector tcp://localhost:61618 stopped
17:34:43.429 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.MasterBroker
17:34:43.429 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Connection
17:34:43.429 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2
17:34:43.430 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Queue
17:34:43.430 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Producer.Queue.q2
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.module#jackson-module-jaxb-annotations;2.5.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.module#jackson-module-jaxb-annotations;2.5.4 ...[0m
17:34:43.432 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Consumer.Queue.q2
17:34:43.432 [pool-5-thread-7] INFO  o.a.a.s.kahadb.plist.PListStoreImpl - PListStore:[/tmp/1496424879492-0/localhost/tmp_storage] stopped
17:34:43.432 [pool-5-thread-7] INFO  o.a.a.store.kahadb.KahaDBStore - Stopping async queue tasks
17:34:43.432 [pool-5-thread-7] INFO  o.a.a.store.kahadb.KahaDBStore - Stopping async topic tasks
17:34:43.433 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: org.apache.activemq.store.kahadb.KahaDBStore$StoreTaskExecutor@6d413a27[Running, pool size = 1, active threads = 0, queued tasks = 0, completed tasks = 10]
17:34:43.433 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: org.apache.activemq.store.kahadb.KahaDBStore$StoreTaskExecutor@19a5bae3[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:43.433 [pool-5-thread-7] INFO  o.a.a.store.kahadb.KahaDBStore - Stopped KahaDB
17:34:43.433 [pool-5-thread-7] DEBUG o.a.a.store.kahadb.MessageDatabase - Checkpoint started.
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson#jackson-parent;2.5.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.zookeeper#zookeeper;3.4.9 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.zookeeper#zookeeper;3.4.9 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving log4j#log4j;1.2.16 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving log4j#log4j;1.2.16 ...[0m
17:34:43.503 [pool-5-thread-7] DEBUG o.a.a.store.kahadb.MessageDatabase - Checkpoint done.
17:34:43.505 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ScheduledThreadPoolExecutor@34d809d0[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0] is shutdown: true and terminated: true took: 0.000 seconds.
17:34:43.506 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.Executors$DelegatedScheduledExecutorService@4051a9f is shutdown: true and terminated: true took: 0.000 seconds.
17:34:43.506 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,service=PersistenceAdapter,instanceName=KahaDBPersistenceAdapter[/tmp/1496424879492-0/localhost/KahaDB]
17:34:43.506 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost
17:34:43.506 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,service=Health
17:34:43.506 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,service=Log4JConfiguration
17:34:43.506 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Stopping jmx connector
17:34:43.508 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unexported JMX RMI Registry
17:34:43.508 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@2e615b4d[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 34] is shutdown: true and terminated: true took: 0.000 seconds.
17:34:43.509 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@2ebca0d8[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:43.509 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:5) uptime 4.017 seconds
17:34:43.509 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:5) is shutdown
17:34:43.521 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Creating RMIRegistry on port 1099
17:34:43.525 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Probably not using JRE 1.4: mx4j.tools.naming.NamingService
17:34:43.526 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Created JMXConnectorServer javax.management.remote.rmi.RMIConnectorServer@67ec6ffc
17:34:43.535 [JMX connector] DEBUG o.a.a.broker.jmx.ManagementContext - Starting JMXConnectorServer...
17:34:43.535 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Using Persistence Adapter: KahaDBPersistenceAdapter[/tmp/1496424883516-0/localhost/KahaDB]
17:34:43.537 [pool-5-thread-7] DEBUG o.a.a.store.kahadb.KahaDBStore - Store OpenWire version configured as: 11
17:34:43.542 [JMX connector] INFO  o.a.a.broker.jmx.ManagementContext - JMX consoles can connect to service:jmx:rmi:///jndi/rmi://localhost:1099/jmxrmi
[A[2K[0m[[0minfo[0m] [0mResolving io.netty#netty;3.10.5.Final ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving io.netty#netty;3.10.5.Final ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.oss#oss-parent;9 ...[0m
17:34:43.975 [pool-5-thread-7] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:43.982 [pool-5-thread-7] INFO  o.a.a.s.kahadb.plist.PListStoreImpl - PListStore:[/tmp/1496424883516-0/localhost/tmp_storage] started
17:34:43.983 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:6) is starting
17:34:43.985 [pool-5-thread-7] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:43.988 [pool-5-thread-7] INFO  o.a.a.t.TransportServerThreadSupport - Listening for connections at: tcp://localhost:61618
17:34:43.989 [pool-5-thread-7] INFO  o.a.a.broker.TransportConnector - Connector tcp://localhost:61618 started
17:34:43.990 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:6) started
17:34:43.990 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - For help or more information please see: http://activemq.apache.org
17:34:43.990 [pool-5-thread-7] WARN  o.a.activemq.broker.BrokerService - Store limit is 102400 mb (current store usage is 0 mb). The data directory: /tmp/1496424883516-0/localhost/KahaDB only has 14176 mb of usable space. - resetting to maximum available disk space: 14176 mb
17:34:43.990 [pool-5-thread-7] WARN  o.a.activemq.broker.BrokerService - Temporary Store limit is 51200 mb (current store usage is 0 mb). The data directory: /tmp/1496424883516-0/localhost only has 14176 mb of usable space. - resetting to maximum available disk space: 14176 mb
17:34:43.990 [pool-5-thread-7] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.MasterBroker
17:34:43.990 [pool-5-thread-7] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ BrokerService[localhost] Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@4034e95f[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:43.994 [pool-5-thread-7] DEBUG ForkLift - Creating ForkLift
17:34:43.994 [pool-5-thread-7] DEBUG ForkLift - Init complete!
17:34:43.994 [pool-5-thread-7] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@77f4a52f[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:43.994 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Reconnect was triggered but transport is not started yet. Wait for start to connect the transport.
17:34:43.994 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Started unconnected
17:34:43.994 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Waking up reconnect task
17:34:44.001 [ActiveMQ Task-1] DEBUG o.a.a.t.failover.FailoverTransport - urlList connectionList:[tcp://127.0.0.1:61618], from: [tcp://127.0.0.1:61618]
17:34:44.002 [ActiveMQ Task-1] DEBUG o.a.a.t.failover.FailoverTransport - Attempting 0th connect to: tcp://127.0.0.1:61618
17:34:44.008 [ActiveMQ Task-1] DEBUG o.a.a.transport.WireFormatNegotiator - Sending: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:44.009 [ActiveMQ Task-1] DEBUG o.a.a.t.failover.FailoverTransport - Connection established
17:34:44.009 [ActiveMQ Task-1] INFO  o.a.a.t.failover.FailoverTransport - Successfully connected to tcp://127.0.0.1:61618
17:34:44.016 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.transport.WireFormatNegotiator - Sending: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:44.031 [ActiveMQ Transport: tcp:///127.0.0.1:61618@39092] DEBUG o.a.a.transport.InactivityMonitor - Using min of local: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]} and remote: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:44.045 [ActiveMQ Transport: tcp:///127.0.0.1:61618@39092] DEBUG o.a.a.transport.WireFormatNegotiator - Received WireFormat: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:44.045 [ActiveMQ Transport: tcp:///127.0.0.1:61618@39092] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:61618@39092 before negotiation: OpenWireFormat{version=12, cacheEnabled=false, stackTraceEnabled=false, tightEncodingEnabled=false, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:44.045 [ActiveMQ Transport: tcp:///127.0.0.1:61618@39092] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:61618@39092 after negotiation: OpenWireFormat{version=12, cacheEnabled=true, stackTraceEnabled=true, tightEncodingEnabled=true, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:44.051 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.transport.InactivityMonitor - Using min of local: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]} and remote: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:44.051 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.transport.WireFormatNegotiator - Received WireFormat: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:44.051 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:39092@61618 before negotiation: OpenWireFormat{version=12, cacheEnabled=false, stackTraceEnabled=false, tightEncodingEnabled=false, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:44.051 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:39092@61618 after negotiation: OpenWireFormat{version=12, cacheEnabled=true, stackTraceEnabled=true, tightEncodingEnabled=true, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:44.063 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnection - Setting up new connection id: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19:1, address: tcp://127.0.0.1:39092, info: ConnectionInfo {commandId = 1, responseRequired = true, connectionId = ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19:1, clientId = ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-18:1, clientIp = null, userName = , password = *****, brokerPath = null, brokerMasterConnector = false, manageable = true, clientMaster = true, faultTolerant = true, failoverReconnect = false}
17:34:44.063 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.064 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.067 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Connection
17:34:44.081 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19:1:-1:1 for destination: ActiveMQ.Advisory.TempQueue,ActiveMQ.Advisory.TempTopic
17:34:44.087 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: queue://q2
17:34:44.088 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:44.088 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:44.088 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:44.089 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:44.089 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:44.149 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 0, dequeueCount: 0, memUsage:0, maxPageSize:200
17:34:44.149 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.149 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.149 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Queue
17:34:44.155 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.155 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.155 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Producer.Queue.q2
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-compiler;2.11.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-reflect;2.11.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang.modules#scala-xml_2.11;1.0.2 ...[0m
17:34:44.340 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19:1:1:1:1 sent to queue://q2
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang.modules#scala-parser-combinators_2.11;1.0.2 ...[0m
17:34:44.362 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=1, pending=0 toPageIn: 1, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 1, dequeueCount: 0, memUsage:2162, maxPageSize:200
[A[2K[0m[[0minfo[0m] [0mResolving jline#jline;2.12 ...[0m
17:34:44.383 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19:1:1:1:2 sent to queue://q2
17:34:44.387 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=2, pending=0 toPageIn: 2, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 2, dequeueCount: 0, memUsage:3243, maxPageSize:200
17:34:44.390 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19:1:1:1:3 sent to queue://q2
17:34:44.391 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=3, pending=0 toPageIn: 3, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 3, dequeueCount: 0, memUsage:4324, maxPageSize:200
17:34:44.413 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19:1:1:1:4 sent to queue://q2
17:34:44.414 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=4, pending=0 toPageIn: 4, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 4, dequeueCount: 0, memUsage:5405, maxPageSize:200
17:34:44.419 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19:1:1:1:5 sent to queue://q2
17:34:44.421 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=5, pending=0 toPageIn: 5, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 5, dequeueCount: 0, memUsage:6486, maxPageSize:200
17:34:44.424 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19:1:1:1:6 sent to queue://q2
17:34:44.425 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=6, pending=0 toPageIn: 6, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 6, dequeueCount: 0, memUsage:7567, maxPageSize:200
17:34:44.428 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19:1:1:1:7 sent to queue://q2
17:34:44.429 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=7, pending=0 toPageIn: 7, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 7, dequeueCount: 0, memUsage:8648, maxPageSize:200
17:34:44.431 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19:1:1:1:8 sent to queue://q2
17:34:44.433 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=8, pending=0 toPageIn: 8, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 8, dequeueCount: 0, memUsage:9729, maxPageSize:200
17:34:44.435 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19:1:1:1:9 sent to queue://q2
17:34:44.440 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=9, pending=0 toPageIn: 9, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 9, dequeueCount: 0, memUsage:10810, maxPageSize:200
17:34:44.441 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19:1:1:1:10 sent to queue://q2
17:34:44.442 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=10, pending=0 toPageIn: 10, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 0, memUsage:11891, maxPageSize:200
17:34:44.466 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19:1:2:1 for destination: queue://q2
17:34:44.467 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.activemq.broker.region.Queue - queue://q2 add sub: QueueSubscription: consumer=ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19:1:2:1, destinations=0, dispatched=0, delivered=0, pending=0, dequeues: 0, dispatched: 0, inflight: 0
17:34:44.467 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 10, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 0, memUsage:10810, maxPageSize:200
17:34:44.468 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.479 [ActiveMQ Transport: tcp:///127.0.0.1:61618@39092] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Session Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@12ab3b7f[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:44.492 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.493 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Consumer.Queue.q2
[0m[[0minfo[0m] [0mdownloading http://packages.confluent.io/maven/org/apache/kafka/kafka-clients/0.10.1.1-cp1/kafka-clients-0.10.1.1-cp1.jar ...[0m
17:34:44.503 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.503 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@24d24a47
437619ee52e6473eb488921e9c970d4d -:- 0
17:34:44.508 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 1, memUsage:9729, maxPageSize:200
17:34:44.508 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 1, memUsage:9729, maxPageSize:200
17:34:44.509 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-18_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19_1_3_1
17:34:44.509 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.509 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.525 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.526 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@ec81ff8
82b38efbeae04aee9213d85d08937565 -:- 1
17:34:44.527 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=8, pending=0 toPageIn: 0, force:false, Inflight: 8, pagedInMessages.size 8, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 2, memUsage:8648, maxPageSize:200
17:34:44.527 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=8, pending=0 toPageIn: 0, force:false, Inflight: 8, pagedInMessages.size 8, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 2, memUsage:8648, maxPageSize:200
17:34:44.528 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-18_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19_1_4_1
17:34:44.528 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.529 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.530 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.530 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@51ecb669
9a69d7f2f42d46b79bd693569eb14a3d -:- 2
17:34:44.531 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=7, pending=0 toPageIn: 0, force:false, Inflight: 7, pagedInMessages.size 7, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 3, memUsage:7567, maxPageSize:200
17:34:44.532 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=7, pending=0 toPageIn: 0, force:false, Inflight: 7, pagedInMessages.size 7, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 3, memUsage:7567, maxPageSize:200
17:34:44.532 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-18_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19_1_5_1
17:34:44.532 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.532 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.533 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.533 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@35dc0e6
cd50794077744939b1994f7fe75473d2 -:- 3
17:34:44.540 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=6, pending=0 toPageIn: 0, force:false, Inflight: 6, pagedInMessages.size 6, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 4, memUsage:6486, maxPageSize:200
17:34:44.541 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=6, pending=0 toPageIn: 0, force:false, Inflight: 6, pagedInMessages.size 6, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 4, memUsage:6486, maxPageSize:200
17:34:44.541 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-18_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19_1_6_1
17:34:44.543 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.543 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.545 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.545 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@21c1893
dd2be4768a5e45548dda2e62e839f5ea -:- 4
17:34:44.551 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=5, pending=0 toPageIn: 0, force:false, Inflight: 5, pagedInMessages.size 5, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 5, memUsage:5405, maxPageSize:200
17:34:44.551 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=5, pending=0 toPageIn: 0, force:false, Inflight: 5, pagedInMessages.size 5, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 5, memUsage:5405, maxPageSize:200
17:34:44.551 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-18_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19_1_7_1
17:34:44.551 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.551 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.552 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.553 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@3e89961
d9ef48625ace46e09a49b65b60f93ab8 -:- 5
17:34:44.554 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=4, pending=0 toPageIn: 0, force:false, Inflight: 4, pagedInMessages.size 4, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 6, memUsage:4324, maxPageSize:200
17:34:44.554 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=4, pending=0 toPageIn: 0, force:false, Inflight: 4, pagedInMessages.size 4, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 6, memUsage:4324, maxPageSize:200
17:34:44.555 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-18_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19_1_8_1
17:34:44.555 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.555 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.577 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.577 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@6ad0b6b7
57e5a5aec48a4040b8e21884272b6c61 -:- 6
17:34:44.583 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=3, pending=0 toPageIn: 0, force:false, Inflight: 3, pagedInMessages.size 3, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 7, memUsage:3243, maxPageSize:200
17:34:44.584 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=3, pending=0 toPageIn: 0, force:false, Inflight: 3, pagedInMessages.size 3, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 7, memUsage:3243, maxPageSize:200
17:34:44.585 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-18_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19_1_9_1
17:34:44.586 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.586 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.591 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.591 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@3a89e2d2
1416e31c7d414ac1a101cbc43f127b7e -:- 7
17:34:44.598 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=2, pending=0 toPageIn: 0, force:false, Inflight: 2, pagedInMessages.size 2, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 8, memUsage:2162, maxPageSize:200
17:34:44.598 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=2, pending=0 toPageIn: 0, force:false, Inflight: 2, pagedInMessages.size 2, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 8, memUsage:2162, maxPageSize:200
17:34:44.598 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-18_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19_1_10_1
17:34:44.611 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.611 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.612 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.612 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@acbb29c
ebb288e0ce0f4c21bf59f87c23a9ef9e -:- 8
17:34:44.614 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=1, pending=0 toPageIn: 0, force:false, Inflight: 1, pagedInMessages.size 1, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 9, memUsage:1081, maxPageSize:200
17:34:44.614 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=1, pending=0 toPageIn: 0, force:false, Inflight: 1, pagedInMessages.size 1, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 9, memUsage:1081, maxPageSize:200
17:34:44.614 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-18_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19_1_11_1
17:34:44.615 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.615 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.617 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.617 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
pool-5-thread-7forklift.connectors.ActiveMQForkliftMessage@68a76bf4
fa1ae05e7f9e4ecb9d1d2fb7ca889198 -:- 9
17:34:44.622 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 10, memUsage:0, maxPageSize:200
17:34:44.622 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=1, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 10, memUsage:0, maxPageSize:200
17:34:44.622 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-18_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19_1_12_1
17:34:44.623 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:44.623 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.kafka#kafka-clients;0.10.1.1-cp1!kafka-clients.jar (235ms)[0m
[0m[[0minfo[0m] [0mdownloading http://packages.confluent.io/maven/io/confluent/kafka-avro-serializer/3.1.1/kafka-avro-serializer-3.1.1.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] io.confluent#kafka-avro-serializer;3.1.1!kafka-avro-serializer.jar (75ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/avro/avro/1.8.1/avro-1.8.1.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.avro#avro;1.8.1!avro.jar(bundle) (703ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/net/jpountz/lz4/lz4/1.3.0/lz4-1.3.0.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] net.jpountz.lz4#lz4;1.3.0!lz4.jar (142ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.2.6/snappy-java-1.1.2.6.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.1.2.6!snappy-java.jar(bundle) (557ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.21/slf4j-api-1.7.21.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.slf4j#slf4j-api;1.7.21!slf4j-api.jar (34ms)[0m
[0m[[0minfo[0m] [0mdownloading http://packages.confluent.io/maven/io/confluent/kafka-schema-registry-client/3.1.1/kafka-schema-registry-client-3.1.1.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] io.confluent#kafka-schema-registry-client;3.1.1!kafka-schema-registry-client.jar (72ms)[0m
[0m[[0minfo[0m] [0mdownloading http://packages.confluent.io/maven/io/confluent/common-config/3.1.1/common-config-3.1.1.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] io.confluent#common-config;3.1.1!common-config.jar (75ms)[0m
[0m[[0minfo[0m] [0mdownloading http://packages.confluent.io/maven/io/confluent/common-utils/3.1.1/common-utils-3.1.1.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] io.confluent#common-utils;3.1.1!common-utils.jar (91ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/101tec/zkclient/0.9/zkclient-0.9.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.101tec#zkclient;0.9!zkclient.jar (46ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/zookeeper/zookeeper/3.4.8/zookeeper-3.4.8.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.zookeeper#zookeeper;3.4.8!zookeeper.jar (307ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/jline/jline/0.9.94/jline-0.9.94.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] jline#jline;0.9.94!jline.jar (41ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/io/netty/netty/3.7.0.Final/netty-3.7.0.Final.jar ...[0m
17:34:47.118 [pool-5-thread-7] INFO  forklift.consumer.Consumer - Consumer shutting down
17:34:47.119 [pool-5-thread-7] DEBUG o.a.activemq.ActiveMQMessageConsumer - remove: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19:1:2:1, lastDeliveredSequenceId: 14
17:34:47.119 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Consumer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-18_1,consumerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19_1_2_1
17:34:47.120 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost removing consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19:1:2:1 for destination: queue://q2
17:34:47.120 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.activemq.broker.region.Queue - queue://q2 remove sub: QueueSubscription: consumer=ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19:1:2:1, destinations=1, dispatched=0, delivered=0, pending=0, lastDeliveredSeqId: 14, dequeues: 10, dispatched: 10, inflight: 0, groups: 0
17:34:47.120 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://q2, subscriptions=0, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 10, memUsage:0, maxPageSize:200
17:34:47.121 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:47.121 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:47.121 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.TempQueue_ActiveMQ.Advisory.TempTopic,endpoint=Consumer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-18_1,consumerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19_1_-1_1
17:34:47.121 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost removing consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19:1:-1:1 for destination: ActiveMQ.Advisory.TempQueue,ActiveMQ.Advisory.TempTopic
17:34:47.121 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnection - remove connection id: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19:1
17:34:47.122 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-18_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-19_1_1_1
17:34:47.122 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:47.122 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:47.122 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:47.122 [ActiveMQ Transport: tcp:///127.0.0.1:39092@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:47.123 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@12ab3b7f[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 1] is shutdown: true and terminated: true took: 0.000 seconds.
17:34:47.124 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@7c88b243[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0] is shutdown: true and terminated: true took: 0.000 seconds.
17:34:47.124 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Stopped tcp://127.0.0.1:61618
17:34:47.124 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@77f4a52f[Running, pool size = 2, active threads = 0, queued tasks = 0, completed tasks = 2]
17:34:47.124 [pool-5-thread-7] DEBUG o.a.a.transport.tcp.TcpTransport - Stopping transport tcp:///127.0.0.1:61618@39092
17:34:47.124 [pool-5-thread-7] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@61e330c3[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:47.125 [ActiveMQ Task-1] DEBUG o.a.a.transport.tcp.TcpTransport - Closed socket Socket[addr=/127.0.0.1,port=61618,localport=39092]
17:34:47.126 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@61e330c3[Running, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 0]
17:34:47.126 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:6) is shutting down
17:34:47.129 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,connector=clientConnectors,connectorName=tcp_//localhost_61618
17:34:47.131 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,connector=clientConnectors,connectorName=tcp_//localhost_61618,connectionViewType=clientId,connectionName=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-18_1
17:34:47.131 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.broker.TransportConnection - Stopping connection: tcp://127.0.0.1:39092
17:34:47.131 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,connector=clientConnectors,connectorName=tcp_//localhost_61618,connectionViewType=remoteAddress,connectionName=tcp_//127.0.0.1_39092
17:34:47.131 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.transport.tcp.TcpTransport - Stopping transport tcp:///127.0.0.1:39092@61618
17:34:47.135 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@1050c003[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:47.132 [ActiveMQ Transport Server Thread Handler: tcp://127.0.0.1:61618] INFO  o.a.a.t.tcp.TcpTransportServer - socketQueue interrupted - stopping
17:34:47.135 [ActiveMQ Transport Server Thread Handler: tcp://127.0.0.1:61618] INFO  o.a.a.broker.TransportConnector - Could not accept connection during shutdown  : java.lang.InterruptedException
17:34:47.165 [ActiveMQ Task-1] DEBUG o.a.a.transport.tcp.TcpTransport - Closed socket Socket[addr=/127.0.0.1,port=39092,localport=61618]
17:34:47.165 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@1050c003[Running, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 0]
17:34:47.165 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.broker.TransportConnection - Stopped transport: tcp://127.0.0.1:39092
17:34:47.165 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.broker.TransportConnection - Connection Stopped: tcp://127.0.0.1:39092
17:34:47.165 [pool-5-thread-7] INFO  o.a.a.broker.TransportConnector - Connector tcp://localhost:61618 stopped
17:34:47.166 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.MasterBroker
17:34:47.166 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Connection
17:34:47.167 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=q2
17:34:47.167 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Queue
17:34:47.167 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Producer.Queue.q2
17:34:47.167 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Consumer.Queue.q2
17:34:47.167 [pool-5-thread-7] INFO  o.a.a.s.kahadb.plist.PListStoreImpl - PListStore:[/tmp/1496424883516-0/localhost/tmp_storage] stopped
17:34:47.167 [pool-5-thread-7] INFO  o.a.a.store.kahadb.KahaDBStore - Stopping async queue tasks
17:34:47.168 [pool-5-thread-7] INFO  o.a.a.store.kahadb.KahaDBStore - Stopping async topic tasks
17:34:47.168 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: org.apache.activemq.store.kahadb.KahaDBStore$StoreTaskExecutor@28dd9c77[Running, pool size = 1, active threads = 0, queued tasks = 0, completed tasks = 10]
17:34:47.168 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: org.apache.activemq.store.kahadb.KahaDBStore$StoreTaskExecutor@6c7826c7[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:47.168 [pool-5-thread-7] INFO  o.a.a.store.kahadb.KahaDBStore - Stopped KahaDB
17:34:47.168 [pool-5-thread-7] DEBUG o.a.a.store.kahadb.MessageDatabase - Checkpoint started.
17:34:47.175 [pool-5-thread-7] DEBUG o.a.a.store.kahadb.MessageDatabase - Checkpoint done.
17:34:47.188 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ScheduledThreadPoolExecutor@250b8dd4[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0] is shutdown: true and terminated: true took: 0.001 seconds.
17:34:47.190 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.Executors$DelegatedScheduledExecutorService@382df572 is shutdown: true and terminated: true took: 0.001 seconds.
17:34:47.191 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,service=PersistenceAdapter,instanceName=KahaDBPersistenceAdapter[/tmp/1496424883516-0/localhost/KahaDB]
17:34:47.198 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost
17:34:47.198 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,service=Health
17:34:47.198 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,service=Log4JConfiguration
17:34:47.199 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Stopping jmx connector
17:34:47.205 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unexported JMX RMI Registry
17:34:47.206 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@4034e95f[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 37] is shutdown: true and terminated: true took: 0.001 seconds.
17:34:47.206 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@745ccf7e[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:47.206 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:6) uptime 3.690 seconds
17:34:47.206 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:6) is shutdown
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest forklift.activemq.test.[33mProducerTest[0m.[36mtestPresets[0m started[0m
[0m[[0minfo[0m] [0mTest forklift.activemq.test.[33mProducerTest[0m.[36mtestSendKeyValueMessage[0m started[0m
[0m[[0minfo[0m] [0mTest forklift.activemq.test.[33mProducerTest[0m.[36mtestSendTripleThreat[0m started[0m
[0m[[0minfo[0m] [0mTest forklift.activemq.test.[33mProducerTest[0m.[36mtestSendStringMessage[0m started[0m
[0m[[0minfo[0m] [0mTest forklift.activemq.test.[33mProducerTest[0m.[36mtestSendObjectMessage[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 5 total, 19.581s[0m[0m
17:34:47.230 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Creating RMIRegistry on port 1099
17:34:47.231 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Probably not using JRE 1.4: mx4j.tools.naming.NamingService
17:34:47.232 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Created JMXConnectorServer javax.management.remote.rmi.RMIConnectorServer@5d93e798
17:34:47.237 [JMX connector] DEBUG o.a.a.broker.jmx.ManagementContext - Starting JMXConnectorServer...
17:34:47.256 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Using Persistence Adapter: KahaDBPersistenceAdapter[/tmp/1496424887224-0/localhost/KahaDB]
17:34:47.257 [JMX connector] INFO  o.a.a.broker.jmx.ManagementContext - JMX consoles can connect to service:jmx:rmi:///jndi/rmi://localhost:1099/jmxrmi
17:34:47.271 [pool-5-thread-7] DEBUG o.a.a.store.kahadb.KahaDBStore - Store OpenWire version configured as: 11
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] io.netty#netty;3.7.0.Final!netty.jar(bundle) (680ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/thoughtworks/paranamer/paranamer/2.7/paranamer-2.7.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.thoughtworks.paranamer#paranamer;2.7!paranamer.jar(bundle) (32ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/commons/commons-compress/1.8.1/commons-compress-1.8.1.jar ...[0m
17:34:47.743 [pool-5-thread-7] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:47.753 [pool-5-thread-7] INFO  o.a.a.s.kahadb.plist.PListStoreImpl - PListStore:[/tmp/1496424887224-0/localhost/tmp_storage] started
17:34:47.760 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:7) is starting
17:34:47.764 [pool-5-thread-7] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:47.768 [pool-5-thread-7] INFO  o.a.a.t.TransportServerThreadSupport - Listening for connections at: tcp://localhost:61618
17:34:47.769 [pool-5-thread-7] INFO  o.a.a.broker.TransportConnector - Connector tcp://localhost:61618 started
17:34:47.769 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:7) started
17:34:47.769 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - For help or more information please see: http://activemq.apache.org
17:34:47.770 [pool-5-thread-7] WARN  o.a.activemq.broker.BrokerService - Store limit is 102400 mb (current store usage is 0 mb). The data directory: /tmp/1496424887224-0/localhost/KahaDB only has 14170 mb of usable space. - resetting to maximum available disk space: 14170 mb
17:34:47.770 [pool-5-thread-7] WARN  o.a.activemq.broker.BrokerService - Temporary Store limit is 51200 mb (current store usage is 0 mb). The data directory: /tmp/1496424887224-0/localhost only has 14170 mb of usable space. - resetting to maximum available disk space: 14170 mb
17:34:47.770 [pool-5-thread-7] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.MasterBroker
17:34:47.771 [pool-5-thread-7] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ BrokerService[localhost] Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@3f8db61c[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:47.778 [pool-5-thread-7] DEBUG ForkLift - Creating ForkLift
17:34:47.779 [pool-5-thread-7] DEBUG ForkLift - Init complete!
17:34:47.782 [pool-5-thread-7] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@7fb13847[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:47.783 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Reconnect was triggered but transport is not started yet. Wait for start to connect the transport.
17:34:47.783 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Started unconnected
17:34:47.783 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Waking up reconnect task
17:34:47.785 [ActiveMQ Task-1] DEBUG o.a.a.t.failover.FailoverTransport - urlList connectionList:[tcp://127.0.0.1:61618], from: [tcp://127.0.0.1:61618]
17:34:47.786 [ActiveMQ Task-1] DEBUG o.a.a.t.failover.FailoverTransport - Attempting 0th connect to: tcp://127.0.0.1:61618
17:34:47.793 [ActiveMQ Task-1] DEBUG o.a.a.transport.WireFormatNegotiator - Sending: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:47.793 [ActiveMQ Task-1] DEBUG o.a.a.t.failover.FailoverTransport - Connection established
17:34:47.794 [ActiveMQ Task-1] INFO  o.a.a.t.failover.FailoverTransport - Successfully connected to tcp://127.0.0.1:61618
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.commons#commons-compress;1.8.1!commons-compress.jar (192ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/tukaani/xz/1.5/xz-1.5.jar ...[0m
17:34:47.848 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.transport.WireFormatNegotiator - Sending: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:47.852 [ActiveMQ Transport: tcp:///127.0.0.1:61618@39132] DEBUG o.a.a.transport.InactivityMonitor - Using min of local: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]} and remote: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.tukaani#xz;1.5!xz.jar (50ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/zookeeper/zookeeper/3.4.9/zookeeper-3.4.9.jar ...[0m
17:34:47.856 [ActiveMQ Transport: tcp:///127.0.0.1:61618@39132] DEBUG o.a.a.transport.WireFormatNegotiator - Received WireFormat: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:47.856 [ActiveMQ Transport: tcp:///127.0.0.1:61618@39132] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:61618@39132 before negotiation: OpenWireFormat{version=12, cacheEnabled=false, stackTraceEnabled=false, tightEncodingEnabled=false, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:47.879 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.transport.InactivityMonitor - Using min of local: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]} and remote: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:47.879 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.transport.WireFormatNegotiator - Received WireFormat: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:47.879 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:39132@61618 before negotiation: OpenWireFormat{version=12, cacheEnabled=false, stackTraceEnabled=false, tightEncodingEnabled=false, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:47.879 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:39132@61618 after negotiation: OpenWireFormat{version=12, cacheEnabled=true, stackTraceEnabled=true, tightEncodingEnabled=true, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:47.884 [ActiveMQ Transport: tcp:///127.0.0.1:61618@39132] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:61618@39132 after negotiation: OpenWireFormat{version=12, cacheEnabled=true, stackTraceEnabled=true, tightEncodingEnabled=true, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:47.887 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnection - Setting up new connection id: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1, address: tcp://127.0.0.1:39132, info: ConnectionInfo {commandId = 1, responseRequired = true, connectionId = ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1, clientId = ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-21:1, clientIp = null, userName = , password = *****, brokerPath = null, brokerMasterConnector = false, manageable = true, clientMaster = true, faultTolerant = true, failoverReconnect = false}
17:34:47.887 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:47.887 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:47.887 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Connection
17:34:47.961 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1:-1:1 for destination: ActiveMQ.Advisory.TempQueue,ActiveMQ.Advisory.TempTopic
17:34:47.974 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: queue://response
17:34:47.985 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:47.985 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:47.985 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:47.985 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:47.985 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:47.994 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=0, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 0, dequeueCount: 0, memUsage:0, maxPageSize:200
17:34:47.995 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:47.995 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:47.995 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Queue
17:34:47.999 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:47.999 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:47.999 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Producer.Queue.response
17:34:48.012 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1:1:1:1 sent to queue://response
17:34:48.053 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=0, memory=0%, size=1, pending=0 toPageIn: 1, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 1, dequeueCount: 0, memUsage:2134, maxPageSize:200
17:34:48.097 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1:1:1:2 sent to queue://response
17:34:48.097 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=0, memory=0%, size=2, pending=0 toPageIn: 2, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 2, dequeueCount: 0, memUsage:3201, maxPageSize:200
17:34:48.099 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1:1:1:3 sent to queue://response
17:34:48.099 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=0, memory=0%, size=3, pending=0 toPageIn: 3, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 3, dequeueCount: 0, memUsage:3201, maxPageSize:200
17:34:48.100 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1:1:1:4 sent to queue://response
17:34:48.101 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=0, memory=0%, size=4, pending=0 toPageIn: 4, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 4, dequeueCount: 0, memUsage:4268, maxPageSize:200
17:34:48.102 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1:1:1:5 sent to queue://response
17:34:48.102 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=0, memory=0%, size=5, pending=0 toPageIn: 5, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 5, dequeueCount: 0, memUsage:6402, maxPageSize:200
17:34:48.115 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1:1:1:6 sent to queue://response
17:34:48.115 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=0, memory=0%, size=6, pending=0 toPageIn: 6, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 6, dequeueCount: 0, memUsage:6402, maxPageSize:200
17:34:48.117 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1:1:1:7 sent to queue://response
17:34:48.117 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=0, memory=0%, size=7, pending=0 toPageIn: 7, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 7, dequeueCount: 0, memUsage:8536, maxPageSize:200
17:34:48.126 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1:1:1:8 sent to queue://response
17:34:48.126 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=0, memory=0%, size=8, pending=0 toPageIn: 8, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 8, dequeueCount: 0, memUsage:9603, maxPageSize:200
17:34:48.129 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1:1:1:9 sent to queue://response
17:34:48.129 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=0, memory=0%, size=9, pending=0 toPageIn: 9, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 9, dequeueCount: 0, memUsage:9603, maxPageSize:200
17:34:48.133 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1:1:1:10 sent to queue://response
17:34:48.133 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=0, memory=0%, size=10, pending=0 toPageIn: 10, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 0, memUsage:11737, maxPageSize:200
17:34:48.142 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=response,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-21_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22_1_1_1
17:34:48.142 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.142 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.143 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1:2:1 for destination: queue://response
17:34:48.144 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.activemq.broker.region.Queue - queue://response add sub: QueueSubscription: consumer=ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1:2:1, destinations=0, dispatched=0, delivered=0, pending=0, dequeues: 0, dispatched: 0, inflight: 0
17:34:48.145 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 10, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 0, memUsage:10670, maxPageSize:200
17:34:48.146 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.146 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.146 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Consumer.Queue.response
17:34:48.149 [ActiveMQ Transport: tcp:///127.0.0.1:61618@39132] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Session Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@1d981696[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:48.276 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 1, memUsage:9603, maxPageSize:200
17:34:48.276 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 1, memUsage:9603, maxPageSize:200
17:34:48.340 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.341 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
Sending: {"name":"Dude","age":22}
17:34:48.345 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1:3:1:1 sent to queue://response
17:34:48.346 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 1, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 11, dequeueCount: 1, memUsage:11707, maxPageSize:200
17:34:48.349 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=response,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-21_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22_1_3_1
17:34:48.350 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.350 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.351 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 11, dequeueCount: 2, memUsage:9588, maxPageSize:200
17:34:48.351 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 11, dequeueCount: 2, memUsage:9588, maxPageSize:200
17:34:48.352 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.352 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
Sending: {"name":"Dude","age":22}
17:34:48.353 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1:4:1:1 sent to queue://response
17:34:48.358 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 1, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 12, dequeueCount: 2, memUsage:11692, maxPageSize:200
17:34:48.360 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=response,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-21_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22_1_4_1
17:34:48.360 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.360 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.361 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 12, dequeueCount: 3, memUsage:9573, maxPageSize:200
17:34:48.362 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 12, dequeueCount: 3, memUsage:9573, maxPageSize:200
17:34:48.373 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.373 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
Sending: {"name":"Dude","age":22}
17:34:48.393 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1:5:1:1 sent to queue://response
17:34:48.393 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 1, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 13, dequeueCount: 3, memUsage:10625, maxPageSize:200
17:34:48.395 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=response,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-21_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22_1_5_1
17:34:48.396 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.396 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.401 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 13, dequeueCount: 4, memUsage:9558, maxPageSize:200
17:34:48.402 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 13, dequeueCount: 4, memUsage:9558, maxPageSize:200
17:34:48.409 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.409 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
Sending: {"name":"Dude","age":22}
17:34:48.410 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1:6:1:1 sent to queue://response
17:34:48.410 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 1, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 14, dequeueCount: 4, memUsage:11662, maxPageSize:200
17:34:48.439 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=response,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-21_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22_1_6_1
17:34:48.439 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.439 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.442 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 14, dequeueCount: 5, memUsage:9543, maxPageSize:200
17:34:48.442 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 14, dequeueCount: 5, memUsage:9543, maxPageSize:200
17:34:48.443 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.443 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
Sending: {"name":"Dude","age":22}
17:34:48.444 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1:7:1:1 sent to queue://response
17:34:48.444 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 1, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 15, dequeueCount: 5, memUsage:11647, maxPageSize:200
17:34:48.448 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=response,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-21_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22_1_7_1
17:34:48.449 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.449 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.449 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 15, dequeueCount: 6, memUsage:9528, maxPageSize:200
17:34:48.450 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 15, dequeueCount: 6, memUsage:9528, maxPageSize:200
17:34:48.459 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.459 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
Sending: {"name":"Dude","age":22}
17:34:48.467 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1:8:1:1 sent to queue://response
17:34:48.467 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 1, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 16, dequeueCount: 6, memUsage:11632, maxPageSize:200
17:34:48.478 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=response,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-21_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22_1_8_1
17:34:48.478 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.478 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.479 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 16, dequeueCount: 7, memUsage:9513, maxPageSize:200
17:34:48.480 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 16, dequeueCount: 7, memUsage:9513, maxPageSize:200
17:34:48.481 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.481 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
Sending: {"name":"Dude","age":22}
17:34:48.491 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1:9:1:1 sent to queue://response
17:34:48.491 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 1, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 17, dequeueCount: 7, memUsage:11617, maxPageSize:200
17:34:48.503 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=response,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-21_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22_1_9_1
17:34:48.503 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.503 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.504 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 17, dequeueCount: 8, memUsage:9498, maxPageSize:200
17:34:48.505 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 17, dequeueCount: 8, memUsage:9498, maxPageSize:200
17:34:48.506 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.506 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
Sending: {"name":"Dude","age":22}
17:34:48.508 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1:10:1:1 sent to queue://response
17:34:48.508 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 1, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 18, dequeueCount: 8, memUsage:11602, maxPageSize:200
17:34:48.514 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=response,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-21_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22_1_10_1
17:34:48.515 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.515 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.516 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 18, dequeueCount: 9, memUsage:9483, maxPageSize:200
17:34:48.516 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 18, dequeueCount: 9, memUsage:9483, maxPageSize:200
17:34:48.518 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.518 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
Sending: {"name":"Dude","age":22}
17:34:48.528 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1:11:1:1 sent to queue://response
17:34:48.528 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 1, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 19, dequeueCount: 9, memUsage:11587, maxPageSize:200
17:34:48.538 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=response,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-21_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22_1_11_1
17:34:48.538 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.539 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.539 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 19, dequeueCount: 10, memUsage:9468, maxPageSize:200
17:34:48.539 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 19, dequeueCount: 10, memUsage:9468, maxPageSize:200
17:34:48.545 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.545 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
Sending: {"name":"Dude","age":22}
17:34:48.549 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1:12:1:1 sent to queue://response
17:34:48.549 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 1, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 10, memUsage:11572, maxPageSize:200
17:34:48.554 [pool-5-thread-7] ERROR forklift.consumer.MessageRunnable - This is expected
java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at forklift.consumer.MessageRunnable.lambda$null$7(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$112/2016173749.get(Unknown Source)
	at forklift.consumer.MessageRunnable.runLoggingErrors(MessageRunnable.java:218)
	at forklift.consumer.MessageRunnable.lambda$run$14(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$109/151589146.run(Unknown Source)
	at forklift.classloader.RunAsClassLoader.run(RunAsClassLoader.java:14)
	at forklift.consumer.MessageRunnable.run(MessageRunnable.java:61)
	at forklift.consumer.Consumer.messageLoop(Consumer.java:314)
	at forklift.consumer.Consumer.listen(Consumer.java:233)
	at forklift.activemq.test.ResponseTest.testObjResp(ResponseTest.java:138)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:138)
	at com.novocode.junit.JUnitRunner$1.execute(JUnitRunner.java:132)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$.sbt$Tests$$processRunnable$1(Tests.scala:239)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:237)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: This is expected
	at forklift.activemq.test.ResponseConsumerObj.go(ResponseConsumerObj.java:25)
	... 72 more

17:34:48.555 [pool-5-thread-7] ERROR forklift.consumer.MessageRunnable - This is expected
java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at forklift.consumer.MessageRunnable.lambda$null$7(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$112/2016173749.get(Unknown Source)
	at forklift.consumer.MessageRunnable.runLoggingErrors(MessageRunnable.java:218)
	at forklift.consumer.MessageRunnable.lambda$run$14(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$109/151589146.run(Unknown Source)
	at forklift.classloader.RunAsClassLoader.run(RunAsClassLoader.java:14)
	at forklift.consumer.MessageRunnable.run(MessageRunnable.java:61)
	at forklift.consumer.Consumer.messageLoop(Consumer.java:314)
	at forklift.consumer.Consumer.listen(Consumer.java:233)
	at forklift.activemq.test.ResponseTest.testObjResp(ResponseTest.java:138)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:138)
	at com.novocode.junit.JUnitRunner$1.execute(JUnitRunner.java:132)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$.sbt$Tests$$processRunnable$1(Tests.scala:239)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:237)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: This is expected
	at forklift.activemq.test.ResponseConsumerObj.go(ResponseConsumerObj.java:25)
	... 72 more

17:34:48.556 [pool-5-thread-7] ERROR forklift.consumer.MessageRunnable - This is expected
java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at forklift.consumer.MessageRunnable.lambda$null$7(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$112/2016173749.get(Unknown Source)
	at forklift.consumer.MessageRunnable.runLoggingErrors(MessageRunnable.java:218)
	at forklift.consumer.MessageRunnable.lambda$run$14(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$109/151589146.run(Unknown Source)
	at forklift.classloader.RunAsClassLoader.run(RunAsClassLoader.java:14)
	at forklift.consumer.MessageRunnable.run(MessageRunnable.java:61)
	at forklift.consumer.Consumer.messageLoop(Consumer.java:314)
	at forklift.consumer.Consumer.listen(Consumer.java:233)
	at forklift.activemq.test.ResponseTest.testObjResp(ResponseTest.java:138)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:138)
	at com.novocode.junit.JUnitRunner$1.execute(JUnitRunner.java:132)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$.sbt$Tests$$processRunnable$1(Tests.scala:239)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:237)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: This is expected
	at forklift.activemq.test.ResponseConsumerObj.go(ResponseConsumerObj.java:25)
	... 72 more

17:34:48.557 [pool-5-thread-7] ERROR forklift.consumer.MessageRunnable - This is expected
java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at forklift.consumer.MessageRunnable.lambda$null$7(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$112/2016173749.get(Unknown Source)
	at forklift.consumer.MessageRunnable.runLoggingErrors(MessageRunnable.java:218)
	at forklift.consumer.MessageRunnable.lambda$run$14(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$109/151589146.run(Unknown Source)
	at forklift.classloader.RunAsClassLoader.run(RunAsClassLoader.java:14)
	at forklift.consumer.MessageRunnable.run(MessageRunnable.java:61)
	at forklift.consumer.Consumer.messageLoop(Consumer.java:314)
	at forklift.consumer.Consumer.listen(Consumer.java:233)
	at forklift.activemq.test.ResponseTest.testObjResp(ResponseTest.java:138)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:138)
	at com.novocode.junit.JUnitRunner$1.execute(JUnitRunner.java:132)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$.sbt$Tests$$processRunnable$1(Tests.scala:239)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:237)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: This is expected
	at forklift.activemq.test.ResponseConsumerObj.go(ResponseConsumerObj.java:25)
	... 72 more

17:34:48.558 [pool-5-thread-7] ERROR forklift.consumer.MessageRunnable - This is expected
java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at forklift.consumer.MessageRunnable.lambda$null$7(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$112/2016173749.get(Unknown Source)
	at forklift.consumer.MessageRunnable.runLoggingErrors(MessageRunnable.java:218)
	at forklift.consumer.MessageRunnable.lambda$run$14(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$109/151589146.run(Unknown Source)
	at forklift.classloader.RunAsClassLoader.run(RunAsClassLoader.java:14)
	at forklift.consumer.MessageRunnable.run(MessageRunnable.java:61)
	at forklift.consumer.Consumer.messageLoop(Consumer.java:314)
	at forklift.consumer.Consumer.listen(Consumer.java:233)
	at forklift.activemq.test.ResponseTest.testObjResp(ResponseTest.java:138)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:138)
	at com.novocode.junit.JUnitRunner$1.execute(JUnitRunner.java:132)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$.sbt$Tests$$processRunnable$1(Tests.scala:239)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:237)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: This is expected
	at forklift.activemq.test.ResponseConsumerObj.go(ResponseConsumerObj.java:25)
	... 72 more

17:34:48.561 [pool-5-thread-7] ERROR forklift.consumer.MessageRunnable - This is expected
java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at forklift.consumer.MessageRunnable.lambda$null$7(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$112/2016173749.get(Unknown Source)
	at forklift.consumer.MessageRunnable.runLoggingErrors(MessageRunnable.java:218)
	at forklift.consumer.MessageRunnable.lambda$run$14(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$109/151589146.run(Unknown Source)
	at forklift.classloader.RunAsClassLoader.run(RunAsClassLoader.java:14)
	at forklift.consumer.MessageRunnable.run(MessageRunnable.java:61)
	at forklift.consumer.Consumer.messageLoop(Consumer.java:314)
	at forklift.consumer.Consumer.listen(Consumer.java:233)
	at forklift.activemq.test.ResponseTest.testObjResp(ResponseTest.java:138)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:138)
	at com.novocode.junit.JUnitRunner$1.execute(JUnitRunner.java:132)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$.sbt$Tests$$processRunnable$1(Tests.scala:239)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:237)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: This is expected
	at forklift.activemq.test.ResponseConsumerObj.go(ResponseConsumerObj.java:25)
	... 72 more

17:34:48.562 [pool-5-thread-7] ERROR forklift.consumer.MessageRunnable - This is expected
java.lang.reflect.InvocationTargetException
	at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at forklift.consumer.MessageRunnable.lambda$null$7(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$112/2016173749.get(Unknown Source)
	at forklift.consumer.MessageRunnable.runLoggingErrors(MessageRunnable.java:218)
	at forklift.consumer.MessageRunnable.lambda$run$14(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$109/151589146.run(Unknown Source)
	at forklift.classloader.RunAsClassLoader.run(RunAsClassLoader.java:14)
	at forklift.consumer.MessageRunnable.run(MessageRunnable.java:61)
	at forklift.consumer.Consumer.messageLoop(Consumer.java:314)
	at forklift.consumer.Consumer.listen(Consumer.java:233)
	at forklift.activemq.test.ResponseTest.testObjResp(ResponseTest.java:138)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:138)
	at com.novocode.junit.JUnitRunner$1.execute(JUnitRunner.java:132)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$.sbt$Tests$$processRunnable$1(Tests.scala:239)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:237)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: This is expected
	at forklift.activemq.test.ResponseConsumerObj.go(ResponseConsumerObj.java:25)
	... 71 more

17:34:48.563 [pool-5-thread-7] ERROR forklift.consumer.MessageRunnable - This is expected
java.lang.reflect.InvocationTargetException
	at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at forklift.consumer.MessageRunnable.lambda$null$7(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$112/2016173749.get(Unknown Source)
	at forklift.consumer.MessageRunnable.runLoggingErrors(MessageRunnable.java:218)
	at forklift.consumer.MessageRunnable.lambda$run$14(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$109/151589146.run(Unknown Source)
	at forklift.classloader.RunAsClassLoader.run(RunAsClassLoader.java:14)
	at forklift.consumer.MessageRunnable.run(MessageRunnable.java:61)
	at forklift.consumer.Consumer.messageLoop(Consumer.java:314)
	at forklift.consumer.Consumer.listen(Consumer.java:233)
	at forklift.activemq.test.ResponseTest.testObjResp(ResponseTest.java:138)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:138)
	at com.novocode.junit.JUnitRunner$1.execute(JUnitRunner.java:132)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$.sbt$Tests$$processRunnable$1(Tests.scala:239)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:237)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: This is expected
	at forklift.activemq.test.ResponseConsumerObj.go(ResponseConsumerObj.java:25)
	... 71 more

17:34:48.564 [pool-5-thread-7] ERROR forklift.consumer.MessageRunnable - This is expected
java.lang.reflect.InvocationTargetException
	at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at forklift.consumer.MessageRunnable.lambda$null$7(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$112/2016173749.get(Unknown Source)
	at forklift.consumer.MessageRunnable.runLoggingErrors(MessageRunnable.java:218)
	at forklift.consumer.MessageRunnable.lambda$run$14(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$109/151589146.run(Unknown Source)
	at forklift.classloader.RunAsClassLoader.run(RunAsClassLoader.java:14)
	at forklift.consumer.MessageRunnable.run(MessageRunnable.java:61)
	at forklift.consumer.Consumer.messageLoop(Consumer.java:314)
	at forklift.consumer.Consumer.listen(Consumer.java:233)
	at forklift.activemq.test.ResponseTest.testObjResp(ResponseTest.java:138)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:138)
	at com.novocode.junit.JUnitRunner$1.execute(JUnitRunner.java:132)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$.sbt$Tests$$processRunnable$1(Tests.scala:239)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:237)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: This is expected
	at forklift.activemq.test.ResponseConsumerObj.go(ResponseConsumerObj.java:25)
	... 71 more

17:34:48.565 [pool-5-thread-7] ERROR forklift.consumer.MessageRunnable - This is expected
java.lang.reflect.InvocationTargetException
	at sun.reflect.GeneratedMethodAccessor24.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at forklift.consumer.MessageRunnable.lambda$null$7(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$112/2016173749.get(Unknown Source)
	at forklift.consumer.MessageRunnable.runLoggingErrors(MessageRunnable.java:218)
	at forklift.consumer.MessageRunnable.lambda$run$14(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$109/151589146.run(Unknown Source)
	at forklift.classloader.RunAsClassLoader.run(RunAsClassLoader.java:14)
	at forklift.consumer.MessageRunnable.run(MessageRunnable.java:61)
	at forklift.consumer.Consumer.messageLoop(Consumer.java:314)
	at forklift.consumer.Consumer.listen(Consumer.java:233)
	at forklift.activemq.test.ResponseTest.testObjResp(ResponseTest.java:138)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:138)
	at com.novocode.junit.JUnitRunner$1.execute(JUnitRunner.java:132)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$.sbt$Tests$$processRunnable$1(Tests.scala:239)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:237)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: This is expected
	at forklift.activemq.test.ResponseConsumerObj.go(ResponseConsumerObj.java:25)
	... 71 more

17:34:48.569 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=response,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-21_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22_1_12_1
17:34:48.569 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.570 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:48.572 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 11, memUsage:9468, maxPageSize:200
17:34:48.572 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 11, memUsage:9468, maxPageSize:200
17:34:48.573 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=8, pending=0 toPageIn: 0, force:false, Inflight: 8, pagedInMessages.size 8, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 12, memUsage:8416, maxPageSize:200
17:34:48.573 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=8, pending=0 toPageIn: 0, force:false, Inflight: 8, pagedInMessages.size 8, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 12, memUsage:8416, maxPageSize:200
17:34:48.573 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=7, pending=0 toPageIn: 0, force:false, Inflight: 7, pagedInMessages.size 7, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 13, memUsage:7364, maxPageSize:200
17:34:48.573 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=7, pending=0 toPageIn: 0, force:false, Inflight: 7, pagedInMessages.size 7, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 13, memUsage:7364, maxPageSize:200
17:34:48.574 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=6, pending=0 toPageIn: 0, force:false, Inflight: 6, pagedInMessages.size 6, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 14, memUsage:6312, maxPageSize:200
17:34:48.574 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=6, pending=0 toPageIn: 0, force:false, Inflight: 6, pagedInMessages.size 6, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 14, memUsage:6312, maxPageSize:200
17:34:48.574 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=5, pending=0 toPageIn: 0, force:false, Inflight: 5, pagedInMessages.size 5, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 15, memUsage:5260, maxPageSize:200
17:34:48.574 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=5, pending=0 toPageIn: 0, force:false, Inflight: 5, pagedInMessages.size 5, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 15, memUsage:5260, maxPageSize:200
17:34:48.575 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=4, pending=0 toPageIn: 0, force:false, Inflight: 4, pagedInMessages.size 4, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 16, memUsage:4208, maxPageSize:200
17:34:48.575 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=4, pending=0 toPageIn: 0, force:false, Inflight: 4, pagedInMessages.size 4, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 16, memUsage:4208, maxPageSize:200
17:34:48.575 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=3, pending=0 toPageIn: 0, force:false, Inflight: 3, pagedInMessages.size 3, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 17, memUsage:3156, maxPageSize:200
17:34:48.575 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=3, pending=0 toPageIn: 0, force:false, Inflight: 3, pagedInMessages.size 3, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 17, memUsage:3156, maxPageSize:200
17:34:48.576 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=2, pending=0 toPageIn: 0, force:false, Inflight: 2, pagedInMessages.size 2, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 18, memUsage:2104, maxPageSize:200
17:34:48.576 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=2, pending=0 toPageIn: 0, force:false, Inflight: 2, pagedInMessages.size 2, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 18, memUsage:2104, maxPageSize:200
17:34:48.581 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=1, pending=0 toPageIn: 0, force:false, Inflight: 1, pagedInMessages.size 1, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 19, memUsage:1052, maxPageSize:200
17:34:48.581 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=1, pending=0 toPageIn: 0, force:false, Inflight: 1, pagedInMessages.size 1, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 19, memUsage:1052, maxPageSize:200
17:34:48.582 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 20, memUsage:0, maxPageSize:200
17:34:48.582 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 20, memUsage:0, maxPageSize:200
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.zookeeper#zookeeper;3.4.9!zookeeper.jar (769ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/commons-net/commons-net/3.6/commons-net-3.6.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] commons-net#commons-net;3.6!commons-net.jar (156ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/mockito/mockito-core/1.9.5/mockito-core-1.9.5.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.mockito#mockito-core;1.9.5!mockito-core.jar (880ms)[0m
[0m[[0minfo[0m] [0mdownloading http://packages.confluent.io/maven/io/confluent/kafka-schema-registry/3.1.1/kafka-schema-registry-3.1.1.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] io.confluent#kafka-schema-registry;3.1.1!kafka-schema-registry.jar (98ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/objenesis/objenesis/1.0/objenesis-1.0.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.objenesis#objenesis;1.0!objenesis.jar (35ms)[0m
[0m[[0minfo[0m] [0mdownloading http://packages.confluent.io/maven/org/apache/kafka/kafka_2.11/0.10.1.0-cp2/kafka_2.11-0.10.1.0-cp2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.kafka#kafka_2.11;0.10.1.0-cp2!kafka_2.11.jar (514ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/glassfish/jersey/ext/jersey-bean-validation/2.19/jersey-bean-validation-2.19.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.glassfish.jersey.ext#jersey-bean-validation;2.19!jersey-bean-validation.jar (42ms)[0m
[0m[[0minfo[0m] [0mdownloading http://packages.confluent.io/maven/io/confluent/rest-utils/3.1.1/rest-utils-3.1.1.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] io.confluent#rest-utils;3.1.1!rest-utils.jar (103ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/net/sf/jopt-simple/jopt-simple/4.9/jopt-simple-4.9.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] net.sf.jopt-simple#jopt-simple;4.9!jopt-simple.jar (47ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/yammer/metrics/metrics-core/2.2.0/metrics-core-2.2.0.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.yammer.metrics#metrics-core;2.2.0!metrics-core.jar (55ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/scala-lang/modules/scala-parser-combinators_2.11/1.0.4/scala-parser-combinators_2.11-1.0.4.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.scala-lang.modules#scala-parser-combinators_2.11;1.0.4!scala-parser-combinators_2.11.jar(bundle) (235ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/glassfish/hk2/external/javax.inject/2.4.0-b25/javax.inject-2.4.0-b25.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.glassfish.hk2.external#javax.inject;2.4.0-b25!javax.inject.jar (23ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/glassfish/jersey/core/jersey-common/2.19/jersey-common-2.19.jar ...[0m
17:34:51.066 [pool-5-thread-7] INFO  forklift.consumer.Consumer - Consumer shutting down
17:34:51.067 [pool-5-thread-7] DEBUG o.a.activemq.ActiveMQMessageConsumer - remove: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1:2:1, lastDeliveredSequenceId: 45
17:34:51.067 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=response,endpoint=Consumer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-21_1,consumerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22_1_2_1
17:34:51.067 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost removing consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1:2:1 for destination: queue://response
17:34:51.067 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.activemq.broker.region.Queue - queue://response remove sub: QueueSubscription: consumer=ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1:2:1, destinations=1, dispatched=0, delivered=0, pending=0, lastDeliveredSeqId: 45, dequeues: 20, dispatched: 20, inflight: 0, groups: 0
17:34:51.067 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=0, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 20, memUsage:0, maxPageSize:200
17:34:51.068 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:51.068 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:51.068 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.TempQueue_ActiveMQ.Advisory.TempTopic,endpoint=Consumer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-21_1,consumerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22_1_-1_1
17:34:51.068 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost removing consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1:-1:1 for destination: ActiveMQ.Advisory.TempQueue,ActiveMQ.Advisory.TempTopic
17:34:51.068 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnection - remove connection id: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-22:1
17:34:51.068 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:51.068 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:51.070 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@1d981696[Shutting down, pool size = 1, active threads = 0, queued tasks = 0, completed tasks = 12] is shutdown: true and terminated: false took: 0.000 seconds.
17:34:51.070 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@2d4354f7[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0] is shutdown: true and terminated: true took: 0.000 seconds.
17:34:51.070 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Stopped tcp://127.0.0.1:61618
17:34:51.070 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@7fb13847[Running, pool size = 2, active threads = 0, queued tasks = 0, completed tasks = 2]
17:34:51.070 [pool-5-thread-7] DEBUG o.a.a.transport.tcp.TcpTransport - Stopping transport tcp:///127.0.0.1:61618@39132
17:34:51.071 [pool-5-thread-7] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@e978a95[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:51.072 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,connector=clientConnectors,connectorName=tcp_//localhost_61618,connectionViewType=clientId,connectionName=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-21_1
17:34:51.072 [ActiveMQ Transport: tcp:///127.0.0.1:39132@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,connector=clientConnectors,connectorName=tcp_//localhost_61618,connectionViewType=remoteAddress,connectionName=tcp_//127.0.0.1_39132
17:34:51.072 [ActiveMQ Task-1] DEBUG o.a.a.transport.tcp.TcpTransport - Closed socket Socket[addr=/127.0.0.1,port=61618,localport=39132]
17:34:51.072 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.a.broker.TransportConnection - Stopping connection: tcp://127.0.0.1:39132
17:34:51.072 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.a.transport.tcp.TcpTransport - Stopping transport tcp:///127.0.0.1:39132@61618
17:34:51.072 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@e978a95[Running, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 0]
17:34:51.087 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:7) is shutting down
17:34:51.087 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,connector=clientConnectors,connectorName=tcp_//localhost_61618
17:34:51.087 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@434fcb86[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:51.088 [pool-5-thread-7] INFO  o.a.a.broker.TransportConnector - Connector tcp://localhost:61618 stopped
17:34:51.108 [ActiveMQ Transport Server Thread Handler: tcp://127.0.0.1:61618] INFO  o.a.a.t.tcp.TcpTransportServer - socketQueue interrupted - stopping
17:34:51.109 [ActiveMQ Transport Server Thread Handler: tcp://127.0.0.1:61618] INFO  o.a.a.broker.TransportConnector - Could not accept connection during shutdown  : java.lang.InterruptedException
17:34:51.109 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.MasterBroker
17:34:51.109 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Connection
17:34:51.116 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=response
17:34:51.116 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Queue
17:34:51.116 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Producer.Queue.response
17:34:51.116 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Consumer.Queue.response
17:34:51.116 [pool-5-thread-7] INFO  o.a.a.s.kahadb.plist.PListStoreImpl - PListStore:[/tmp/1496424887224-0/localhost/tmp_storage] stopped
17:34:51.116 [pool-5-thread-7] INFO  o.a.a.store.kahadb.KahaDBStore - Stopping async queue tasks
17:34:51.116 [pool-5-thread-7] INFO  o.a.a.store.kahadb.KahaDBStore - Stopping async topic tasks
17:34:51.116 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: org.apache.activemq.store.kahadb.KahaDBStore$StoreTaskExecutor@68293bf1[Running, pool size = 1, active threads = 0, queued tasks = 0, completed tasks = 20]
17:34:51.116 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: org.apache.activemq.store.kahadb.KahaDBStore$StoreTaskExecutor@3bc9888c[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:51.116 [pool-5-thread-7] INFO  o.a.a.store.kahadb.KahaDBStore - Stopped KahaDB
17:34:51.117 [pool-5-thread-7] DEBUG o.a.a.store.kahadb.MessageDatabase - Checkpoint started.
17:34:51.120 [ActiveMQ Task-1] DEBUG o.a.a.transport.tcp.TcpTransport - Closed socket Socket[addr=/127.0.0.1,port=39132,localport=61618]
17:34:51.120 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@434fcb86[Running, pool size = 1, active threads = 1, queued tasks = 0, completed tasks = 0]
17:34:51.121 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.a.broker.TransportConnection - Stopped transport: tcp://127.0.0.1:39132
17:34:51.121 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.a.broker.TransportConnection - Connection Stopped: tcp://127.0.0.1:39132
17:34:51.123 [pool-5-thread-7] DEBUG o.a.a.store.kahadb.MessageDatabase - Checkpoint done.
17:34:51.141 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ScheduledThreadPoolExecutor@421e7303[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0] is shutdown: true and terminated: true took: 0.004 seconds.
17:34:51.145 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.Executors$DelegatedScheduledExecutorService@4480e0bc is shutdown: true and terminated: true took: 0.003 seconds.
17:34:51.145 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,service=PersistenceAdapter,instanceName=KahaDBPersistenceAdapter[/tmp/1496424887224-0/localhost/KahaDB]
17:34:51.145 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost
17:34:51.145 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,service=Health
17:34:51.146 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,service=Log4JConfiguration
17:34:51.146 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Stopping jmx connector
17:34:51.153 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unexported JMX RMI Registry
17:34:51.154 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@3f8db61c[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 75] is shutdown: true and terminated: true took: 0.001 seconds.
17:34:51.154 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@4428169[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:51.154 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:7) uptime 3.930 seconds
17:34:51.154 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:7) is shutdown
17:34:51.165 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Creating RMIRegistry on port 1099
17:34:51.166 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Probably not using JRE 1.4: mx4j.tools.naming.NamingService
17:34:51.167 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Created JMXConnectorServer javax.management.remote.rmi.RMIConnectorServer@76b3ef8b
17:34:51.170 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Using Persistence Adapter: KahaDBPersistenceAdapter[/tmp/1496424891161-0/localhost/KahaDB]
17:34:51.184 [pool-5-thread-7] DEBUG o.a.a.store.kahadb.KahaDBStore - Store OpenWire version configured as: 11
17:34:51.185 [JMX connector] DEBUG o.a.a.broker.jmx.ManagementContext - Starting JMXConnectorServer...
17:34:51.209 [JMX connector] INFO  o.a.a.broker.jmx.ManagementContext - JMX consoles can connect to service:jmx:rmi:///jndi/rmi://localhost:1099/jmxrmi
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.glassfish.jersey.core#jersey-common;2.19!jersey-common.jar (443ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/glassfish/jersey/core/jersey-server/2.19/jersey-server-2.19.jar ...[0m
17:34:51.677 [pool-5-thread-7] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:51.685 [pool-5-thread-7] INFO  o.a.a.s.kahadb.plist.PListStoreImpl - PListStore:[/tmp/1496424891161-0/localhost/tmp_storage] started
17:34:51.686 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:8) is starting
17:34:51.687 [pool-5-thread-7] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:51.688 [pool-5-thread-7] INFO  o.a.a.t.TransportServerThreadSupport - Listening for connections at: tcp://localhost:61618
17:34:51.689 [pool-5-thread-7] INFO  o.a.a.broker.TransportConnector - Connector tcp://localhost:61618 started
17:34:51.689 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:8) started
17:34:51.689 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - For help or more information please see: http://activemq.apache.org
17:34:51.689 [pool-5-thread-7] WARN  o.a.activemq.broker.BrokerService - Store limit is 102400 mb (current store usage is 0 mb). The data directory: /tmp/1496424891161-0/localhost/KahaDB only has 14159 mb of usable space. - resetting to maximum available disk space: 14159 mb
17:34:51.689 [pool-5-thread-7] WARN  o.a.activemq.broker.BrokerService - Temporary Store limit is 51200 mb (current store usage is 0 mb). The data directory: /tmp/1496424891161-0/localhost only has 14159 mb of usable space. - resetting to maximum available disk space: 14159 mb
17:34:51.690 [pool-5-thread-7] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.MasterBroker
17:34:51.701 [pool-5-thread-7] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ BrokerService[localhost] Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@41020f22[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:51.704 [pool-5-thread-7] DEBUG ForkLift - Creating ForkLift
17:34:51.704 [pool-5-thread-7] DEBUG ForkLift - Init complete!
17:34:51.704 [pool-5-thread-7] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@75ec783b[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:51.704 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Reconnect was triggered but transport is not started yet. Wait for start to connect the transport.
17:34:51.704 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Started unconnected
17:34:51.704 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Waking up reconnect task
17:34:51.728 [ActiveMQ Task-1] DEBUG o.a.a.t.failover.FailoverTransport - urlList connectionList:[tcp://127.0.0.1:61618], from: [tcp://127.0.0.1:61618]
17:34:51.729 [ActiveMQ Task-1] DEBUG o.a.a.t.failover.FailoverTransport - Attempting 0th connect to: tcp://127.0.0.1:61618
17:34:51.733 [ActiveMQ Task-1] DEBUG o.a.a.transport.WireFormatNegotiator - Sending: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:51.744 [ActiveMQ Task-1] DEBUG o.a.a.t.failover.FailoverTransport - Connection established
17:34:51.745 [ActiveMQ Task-1] INFO  o.a.a.t.failover.FailoverTransport - Successfully connected to tcp://127.0.0.1:61618
17:34:51.759 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.transport.WireFormatNegotiator - Sending: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:51.782 [ActiveMQ Transport: tcp:///127.0.0.1:61618@39160] DEBUG o.a.a.transport.InactivityMonitor - Using min of local: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]} and remote: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:51.804 [ActiveMQ Transport: tcp:///127.0.0.1:61618@39160] DEBUG o.a.a.transport.WireFormatNegotiator - Received WireFormat: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:51.805 [ActiveMQ Transport: tcp:///127.0.0.1:61618@39160] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:61618@39160 before negotiation: OpenWireFormat{version=12, cacheEnabled=false, stackTraceEnabled=false, tightEncodingEnabled=false, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:51.807 [ActiveMQ Transport: tcp:///127.0.0.1:61618@39160] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:61618@39160 after negotiation: OpenWireFormat{version=12, cacheEnabled=true, stackTraceEnabled=true, tightEncodingEnabled=true, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:51.808 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.transport.InactivityMonitor - Using min of local: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]} and remote: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:51.821 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.transport.WireFormatNegotiator - Received WireFormat: WireFormatInfo { version=12, properties={TcpNoDelayEnabled=true, SizePrefixDisabled=false, CacheSize=1024, ProviderName=ActiveMQ, StackTraceEnabled=true, PlatformDetails=JVM: 1.8.0_31, 25.31-b07, Oracle Corporation, OS: Linux, 4.8.12-040812-generic, amd64, CacheEnabled=true, TightEncodingEnabled=true, MaxFrameSize=9223372036854775807, MaxInactivityDuration=30000, MaxInactivityDurationInitalDelay=10000, ProviderVersion=5.14.0}, magic=[A,c,t,i,v,e,M,Q]}
17:34:51.821 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:39160@61618 before negotiation: OpenWireFormat{version=12, cacheEnabled=false, stackTraceEnabled=false, tightEncodingEnabled=false, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:51.821 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.transport.WireFormatNegotiator - tcp:///127.0.0.1:39160@61618 after negotiation: OpenWireFormat{version=12, cacheEnabled=true, stackTraceEnabled=true, tightEncodingEnabled=true, sizePrefixDisabled=false, maxFrameSize=9223372036854775807}
17:34:51.840 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnection - Setting up new connection id: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1, address: tcp://127.0.0.1:39160, info: ConnectionInfo {commandId = 1, responseRequired = true, connectionId = ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1, clientId = ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-24:1, clientIp = null, userName = , password = *****, brokerPath = null, brokerMasterConnector = false, manageable = true, clientMaster = true, faultTolerant = true, failoverReconnect = false}
17:34:51.841 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:51.841 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:51.841 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Connection
17:34:51.848 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1:-1:1 for destination: ActiveMQ.Advisory.TempQueue,ActiveMQ.Advisory.TempTopic
17:34:51.852 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: queue://response
17:34:51.866 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:51.866 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:51.866 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:51.866 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:51.868 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.s.kahadb.disk.index.BTreeIndex - loading
17:34:51.872 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=0, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 0, dequeueCount: 0, memUsage:0, maxPageSize:200
17:34:51.874 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:51.874 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:51.875 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Queue
17:34:51.889 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:51.889 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:51.889 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Producer.Queue.response
17:34:51.896 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1:1:1:1 sent to queue://response
17:34:51.914 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=0, memory=0%, size=1, pending=0 toPageIn: 1, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 1, dequeueCount: 0, memUsage:2134, maxPageSize:200
17:34:51.952 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1:1:1:2 sent to queue://response
17:34:51.952 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=0, memory=0%, size=2, pending=0 toPageIn: 2, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 2, dequeueCount: 0, memUsage:3201, maxPageSize:200
17:34:51.955 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1:1:1:3 sent to queue://response
17:34:51.955 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=0, memory=0%, size=3, pending=0 toPageIn: 3, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 3, dequeueCount: 0, memUsage:4268, maxPageSize:200
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.glassfish.jersey.core#jersey-server;2.19!jersey-server.jar (676ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar ...[0m
17:34:51.961 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1:1:1:4 sent to queue://response
17:34:51.961 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=0, memory=0%, size=4, pending=0 toPageIn: 4, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 4, dequeueCount: 0, memUsage:5335, maxPageSize:200
17:34:51.963 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1:1:1:5 sent to queue://response
17:34:51.963 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=0, memory=0%, size=5, pending=0 toPageIn: 5, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 5, dequeueCount: 0, memUsage:5335, maxPageSize:200
17:34:51.973 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1:1:1:6 sent to queue://response
17:34:51.973 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=0, memory=0%, size=6, pending=0 toPageIn: 6, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 6, dequeueCount: 0, memUsage:7469, maxPageSize:200
17:34:51.975 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1:1:1:7 sent to queue://response
17:34:51.975 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=0, memory=0%, size=7, pending=0 toPageIn: 7, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 7, dequeueCount: 0, memUsage:7469, maxPageSize:200
17:34:51.976 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1:1:1:8 sent to queue://response
17:34:51.976 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=0, memory=0%, size=8, pending=0 toPageIn: 8, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 8, dequeueCount: 0, memUsage:9603, maxPageSize:200
17:34:51.977 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1:1:1:9 sent to queue://response
17:34:51.978 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=0, memory=0%, size=9, pending=0 toPageIn: 9, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 9, dequeueCount: 0, memUsage:10670, maxPageSize:200
17:34:51.981 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1:1:1:10 sent to queue://response
17:34:51.981 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=0, memory=0%, size=10, pending=0 toPageIn: 10, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 0, memUsage:11737, maxPageSize:200
17:34:51.982 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=response,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-24_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25_1_1_1
17:34:51.982 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:51.982 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:51.985 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1:2:1 for destination: queue://response
17:34:51.987 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.activemq.broker.region.Queue - queue://response add sub: QueueSubscription: consumer=ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1:2:1, destinations=0, dispatched=0, delivered=0, pending=0, dequeues: 0, dispatched: 0, inflight: 0
17:34:51.994 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 10, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 0, memUsage:10670, maxPageSize:200
17:34:51.997 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:51.997 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:51.997 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost adding destination: topic://ActiveMQ.Advisory.Consumer.Queue.response
17:34:52.033 [pool-5-thread-7] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Session Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@6eb1df21[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:52.130 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 1, memUsage:9603, maxPageSize:200
17:34:52.130 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 10, dequeueCount: 1, memUsage:9603, maxPageSize:200
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] javax.validation#validation-api;1.1.0.Final!validation-api.jar (178ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/hibernate/hibernate-validator/5.1.2.Final/hibernate-validator-5.1.2.Final.jar ...[0m
17:34:52.147 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.147 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
Sending: {"x":"x"}
17:34:52.152 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1:3:1:1 sent to queue://response
17:34:52.153 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 1, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 11, dequeueCount: 1, memUsage:11677, maxPageSize:200
17:34:52.160 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=response,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-24_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25_1_3_1
17:34:52.161 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.161 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.181 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.181 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
Sending: {"x":"x"}
17:34:52.181 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1:4:1:1 sent to queue://response
17:34:52.182 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 1, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 12, dequeueCount: 2, memUsage:11647, maxPageSize:200
17:34:52.182 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 10, pagedInPendingDispatch.size 0, enqueueCount: 12, dequeueCount: 2, memUsage:11647, maxPageSize:200
17:34:52.182 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 10, pagedInPendingDispatch.size 0, enqueueCount: 12, dequeueCount: 2, memUsage:11647, maxPageSize:200
17:34:52.183 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=response,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-24_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25_1_4_1
17:34:52.184 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.184 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.188 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.188 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
Sending: {"x":"x"}
17:34:52.195 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1:5:1:1 sent to queue://response
17:34:52.196 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 1, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 13, dequeueCount: 3, memUsage:11617, maxPageSize:200
17:34:52.197 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 0, force:false, Inflight: 10, pagedInMessages.size 10, pagedInPendingDispatch.size 0, enqueueCount: 13, dequeueCount: 3, memUsage:10580, maxPageSize:200
17:34:52.197 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 0, force:false, Inflight: 10, pagedInMessages.size 10, pagedInPendingDispatch.size 0, enqueueCount: 13, dequeueCount: 3, memUsage:10580, maxPageSize:200
17:34:52.197 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=response,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-24_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25_1_5_1
17:34:52.197 [ActiveMQ BrokerService[localhost] Task-2] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 0, force:false, Inflight: 10, pagedInMessages.size 10, pagedInPendingDispatch.size 0, enqueueCount: 13, dequeueCount: 3, memUsage:10580, maxPageSize:200
17:34:52.198 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.198 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.202 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.202 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
Sending: {"x":"x"}
17:34:52.204 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1:6:1:1 sent to queue://response
17:34:52.204 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 1, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 14, dequeueCount: 4, memUsage:11587, maxPageSize:200
17:34:52.206 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=response,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-24_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25_1_6_1
17:34:52.225 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.225 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.228 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.228 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
Sending: {"x":"x"}
17:34:52.232 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1:7:1:1 sent to queue://response
17:34:52.234 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=response,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-24_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25_1_7_1
17:34:52.234 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.234 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.235 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.235 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.239 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 1, force:false, Inflight: 7, pagedInMessages.size 8, pagedInPendingDispatch.size 0, enqueueCount: 15, dequeueCount: 6, memUsage:9453, maxPageSize:200
17:34:52.239 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 7, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 15, dequeueCount: 6, memUsage:9453, maxPageSize:200
17:34:52.239 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 7, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 15, dequeueCount: 6, memUsage:9453, maxPageSize:200
17:34:52.239 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 7, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 15, dequeueCount: 6, memUsage:9453, maxPageSize:200
17:34:52.239 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 7, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 15, dequeueCount: 6, memUsage:9453, maxPageSize:200
17:34:52.248 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 7, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 15, dequeueCount: 6, memUsage:9453, maxPageSize:200
17:34:52.248 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 15, dequeueCount: 6, memUsage:9453, maxPageSize:200
Sending: {"x":"x"}
17:34:52.249 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 15, dequeueCount: 6, memUsage:9453, maxPageSize:200
17:34:52.269 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1:8:1:1 sent to queue://response
17:34:52.269 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 1, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 16, dequeueCount: 6, memUsage:11527, maxPageSize:200
17:34:52.274 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=response,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-24_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25_1_8_1
17:34:52.275 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.275 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.276 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.276 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.276 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 16, dequeueCount: 7, memUsage:9423, maxPageSize:200
17:34:52.276 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 16, dequeueCount: 7, memUsage:9423, maxPageSize:200
Sending: {"x":"x"}
17:34:52.278 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1:9:1:1 sent to queue://response
17:34:52.278 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 1, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 17, dequeueCount: 7, memUsage:11497, maxPageSize:200
17:34:52.285 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=response,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-24_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25_1_9_1
17:34:52.285 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.285 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.287 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.287 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.287 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 17, dequeueCount: 8, memUsage:9393, maxPageSize:200
17:34:52.287 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 17, dequeueCount: 8, memUsage:9393, maxPageSize:200
Sending: {"x":"x"}
17:34:52.288 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1:10:1:1 sent to queue://response
17:34:52.288 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 1, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 18, dequeueCount: 8, memUsage:11467, maxPageSize:200
17:34:52.290 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=response,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-24_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25_1_10_1
17:34:52.291 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.291 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.291 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 18, dequeueCount: 9, memUsage:9363, maxPageSize:200
17:34:52.292 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 18, dequeueCount: 9, memUsage:9363, maxPageSize:200
17:34:52.293 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.293 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
Sending: {"x":"x"}
17:34:52.294 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1:11:1:1 sent to queue://response
17:34:52.294 [ActiveMQ BrokerService[localhost] Task-3] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 1, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 19, dequeueCount: 9, memUsage:11437, maxPageSize:200
17:34:52.300 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=response,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-24_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25_1_11_1
17:34:52.301 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.301 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.301 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 19, dequeueCount: 10, memUsage:9333, maxPageSize:200
17:34:52.301 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 19, dequeueCount: 10, memUsage:9333, maxPageSize:200
17:34:52.303 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.303 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
Sending: {"x":"x"}
17:34:52.304 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.activemq.broker.region.Queue - localhost Message ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1:12:1:1 sent to queue://response
17:34:52.304 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=10, pending=0 toPageIn: 1, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 10, memUsage:11407, maxPageSize:200
17:34:52.307 [pool-5-thread-7] ERROR forklift.consumer.MessageRunnable - This is expected
java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at forklift.consumer.MessageRunnable.lambda$null$7(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$112/2016173749.get(Unknown Source)
	at forklift.consumer.MessageRunnable.runLoggingErrors(MessageRunnable.java:218)
	at forklift.consumer.MessageRunnable.lambda$run$14(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$109/151589146.run(Unknown Source)
	at forklift.classloader.RunAsClassLoader.run(RunAsClassLoader.java:14)
	at forklift.consumer.MessageRunnable.run(MessageRunnable.java:61)
	at forklift.consumer.Consumer.messageLoop(Consumer.java:314)
	at forklift.consumer.Consumer.listen(Consumer.java:233)
	at forklift.activemq.test.ResponseTest.testMapResp(ResponseTest.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:138)
	at com.novocode.junit.JUnitRunner$1.execute(JUnitRunner.java:132)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$.sbt$Tests$$processRunnable$1(Tests.scala:239)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:237)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: This is expected
	at forklift.activemq.test.ResponseConsumerMap.go(ResponseConsumerMap.java:28)
	... 72 more

17:34:52.308 [pool-5-thread-7] ERROR forklift.consumer.MessageRunnable - This is expected
java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at forklift.consumer.MessageRunnable.lambda$null$7(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$112/2016173749.get(Unknown Source)
	at forklift.consumer.MessageRunnable.runLoggingErrors(MessageRunnable.java:218)
	at forklift.consumer.MessageRunnable.lambda$run$14(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$109/151589146.run(Unknown Source)
	at forklift.classloader.RunAsClassLoader.run(RunAsClassLoader.java:14)
	at forklift.consumer.MessageRunnable.run(MessageRunnable.java:61)
	at forklift.consumer.Consumer.messageLoop(Consumer.java:314)
	at forklift.consumer.Consumer.listen(Consumer.java:233)
	at forklift.activemq.test.ResponseTest.testMapResp(ResponseTest.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:138)
	at com.novocode.junit.JUnitRunner$1.execute(JUnitRunner.java:132)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$.sbt$Tests$$processRunnable$1(Tests.scala:239)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:237)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: This is expected
	at forklift.activemq.test.ResponseConsumerMap.go(ResponseConsumerMap.java:28)
	... 72 more

17:34:52.310 [pool-5-thread-7] ERROR forklift.consumer.MessageRunnable - This is expected
java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at forklift.consumer.MessageRunnable.lambda$null$7(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$112/2016173749.get(Unknown Source)
	at forklift.consumer.MessageRunnable.runLoggingErrors(MessageRunnable.java:218)
	at forklift.consumer.MessageRunnable.lambda$run$14(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$109/151589146.run(Unknown Source)
	at forklift.classloader.RunAsClassLoader.run(RunAsClassLoader.java:14)
	at forklift.consumer.MessageRunnable.run(MessageRunnable.java:61)
	at forklift.consumer.Consumer.messageLoop(Consumer.java:314)
	at forklift.consumer.Consumer.listen(Consumer.java:233)
	at forklift.activemq.test.ResponseTest.testMapResp(ResponseTest.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:138)
	at com.novocode.junit.JUnitRunner$1.execute(JUnitRunner.java:132)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$.sbt$Tests$$processRunnable$1(Tests.scala:239)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:237)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: This is expected
	at forklift.activemq.test.ResponseConsumerMap.go(ResponseConsumerMap.java:28)
	... 72 more

17:34:52.311 [pool-5-thread-7] ERROR forklift.consumer.MessageRunnable - This is expected
java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at forklift.consumer.MessageRunnable.lambda$null$7(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$112/2016173749.get(Unknown Source)
	at forklift.consumer.MessageRunnable.runLoggingErrors(MessageRunnable.java:218)
	at forklift.consumer.MessageRunnable.lambda$run$14(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$109/151589146.run(Unknown Source)
	at forklift.classloader.RunAsClassLoader.run(RunAsClassLoader.java:14)
	at forklift.consumer.MessageRunnable.run(MessageRunnable.java:61)
	at forklift.consumer.Consumer.messageLoop(Consumer.java:314)
	at forklift.consumer.Consumer.listen(Consumer.java:233)
	at forklift.activemq.test.ResponseTest.testMapResp(ResponseTest.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:138)
	at com.novocode.junit.JUnitRunner$1.execute(JUnitRunner.java:132)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$.sbt$Tests$$processRunnable$1(Tests.scala:239)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:237)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: This is expected
	at forklift.activemq.test.ResponseConsumerMap.go(ResponseConsumerMap.java:28)
	... 72 more

17:34:52.312 [pool-5-thread-7] ERROR forklift.consumer.MessageRunnable - This is expected
java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at forklift.consumer.MessageRunnable.lambda$null$7(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$112/2016173749.get(Unknown Source)
	at forklift.consumer.MessageRunnable.runLoggingErrors(MessageRunnable.java:218)
	at forklift.consumer.MessageRunnable.lambda$run$14(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$109/151589146.run(Unknown Source)
	at forklift.classloader.RunAsClassLoader.run(RunAsClassLoader.java:14)
	at forklift.consumer.MessageRunnable.run(MessageRunnable.java:61)
	at forklift.consumer.Consumer.messageLoop(Consumer.java:314)
	at forklift.consumer.Consumer.listen(Consumer.java:233)
	at forklift.activemq.test.ResponseTest.testMapResp(ResponseTest.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:138)
	at com.novocode.junit.JUnitRunner$1.execute(JUnitRunner.java:132)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$.sbt$Tests$$processRunnable$1(Tests.scala:239)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:237)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: This is expected
	at forklift.activemq.test.ResponseConsumerMap.go(ResponseConsumerMap.java:28)
	... 72 more

17:34:52.313 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=response,endpoint=Producer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-24_1,producerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25_1_12_1
17:34:52.313 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.313 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:52.314 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 11, memUsage:9333, maxPageSize:200
17:34:52.314 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=9, pending=0 toPageIn: 0, force:false, Inflight: 9, pagedInMessages.size 9, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 11, memUsage:9333, maxPageSize:200
17:34:52.314 [pool-5-thread-7] ERROR forklift.consumer.MessageRunnable - This is expected
java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at forklift.consumer.MessageRunnable.lambda$null$7(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$112/2016173749.get(Unknown Source)
	at forklift.consumer.MessageRunnable.runLoggingErrors(MessageRunnable.java:218)
	at forklift.consumer.MessageRunnable.lambda$run$14(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$109/151589146.run(Unknown Source)
	at forklift.classloader.RunAsClassLoader.run(RunAsClassLoader.java:14)
	at forklift.consumer.MessageRunnable.run(MessageRunnable.java:61)
	at forklift.consumer.Consumer.messageLoop(Consumer.java:314)
	at forklift.consumer.Consumer.listen(Consumer.java:233)
	at forklift.activemq.test.ResponseTest.testMapResp(ResponseTest.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:138)
	at com.novocode.junit.JUnitRunner$1.execute(JUnitRunner.java:132)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$.sbt$Tests$$processRunnable$1(Tests.scala:239)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:237)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: This is expected
	at forklift.activemq.test.ResponseConsumerMap.go(ResponseConsumerMap.java:28)
	... 72 more

17:34:52.314 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=8, pending=0 toPageIn: 0, force:false, Inflight: 8, pagedInMessages.size 8, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 12, memUsage:8296, maxPageSize:200
17:34:52.315 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=8, pending=0 toPageIn: 0, force:false, Inflight: 8, pagedInMessages.size 8, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 12, memUsage:8296, maxPageSize:200
17:34:52.336 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=7, pending=0 toPageIn: 0, force:false, Inflight: 6, pagedInMessages.size 7, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 13, memUsage:7259, maxPageSize:200
17:34:52.337 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=7, pending=0 toPageIn: 0, force:false, Inflight: 6, pagedInMessages.size 7, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 13, memUsage:7259, maxPageSize:200
17:34:52.349 [pool-5-thread-7] ERROR forklift.consumer.MessageRunnable - This is expected
java.lang.reflect.InvocationTargetException
	at sun.reflect.GeneratedMethodAccessor27.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at forklift.consumer.MessageRunnable.lambda$null$7(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$112/2016173749.get(Unknown Source)
	at forklift.consumer.MessageRunnable.runLoggingErrors(MessageRunnable.java:218)
	at forklift.consumer.MessageRunnable.lambda$run$14(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$109/151589146.run(Unknown Source)
	at forklift.classloader.RunAsClassLoader.run(RunAsClassLoader.java:14)
	at forklift.consumer.MessageRunnable.run(MessageRunnable.java:61)
	at forklift.consumer.Consumer.messageLoop(Consumer.java:314)
	at forklift.consumer.Consumer.listen(Consumer.java:233)
	at forklift.activemq.test.ResponseTest.testMapResp(ResponseTest.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:138)
	at com.novocode.junit.JUnitRunner$1.execute(JUnitRunner.java:132)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$.sbt$Tests$$processRunnable$1(Tests.scala:239)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:237)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: This is expected
	at forklift.activemq.test.ResponseConsumerMap.go(ResponseConsumerMap.java:28)
	... 71 more

17:34:52.351 [pool-5-thread-7] ERROR forklift.consumer.MessageRunnable - This is expected
java.lang.reflect.InvocationTargetException
	at sun.reflect.GeneratedMethodAccessor27.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at forklift.consumer.MessageRunnable.lambda$null$7(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$112/2016173749.get(Unknown Source)
	at forklift.consumer.MessageRunnable.runLoggingErrors(MessageRunnable.java:218)
	at forklift.consumer.MessageRunnable.lambda$run$14(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$109/151589146.run(Unknown Source)
	at forklift.classloader.RunAsClassLoader.run(RunAsClassLoader.java:14)
	at forklift.consumer.MessageRunnable.run(MessageRunnable.java:61)
	at forklift.consumer.Consumer.messageLoop(Consumer.java:314)
	at forklift.consumer.Consumer.listen(Consumer.java:233)
	at forklift.activemq.test.ResponseTest.testMapResp(ResponseTest.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:138)
	at com.novocode.junit.JUnitRunner$1.execute(JUnitRunner.java:132)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$.sbt$Tests$$processRunnable$1(Tests.scala:239)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:237)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: This is expected
	at forklift.activemq.test.ResponseConsumerMap.go(ResponseConsumerMap.java:28)
	... 71 more

17:34:52.352 [pool-5-thread-7] ERROR forklift.consumer.MessageRunnable - This is expected
java.lang.reflect.InvocationTargetException
	at sun.reflect.GeneratedMethodAccessor27.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at forklift.consumer.MessageRunnable.lambda$null$7(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$112/2016173749.get(Unknown Source)
	at forklift.consumer.MessageRunnable.runLoggingErrors(MessageRunnable.java:218)
	at forklift.consumer.MessageRunnable.lambda$run$14(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$109/151589146.run(Unknown Source)
	at forklift.classloader.RunAsClassLoader.run(RunAsClassLoader.java:14)
	at forklift.consumer.MessageRunnable.run(MessageRunnable.java:61)
	at forklift.consumer.Consumer.messageLoop(Consumer.java:314)
	at forklift.consumer.Consumer.listen(Consumer.java:233)
	at forklift.activemq.test.ResponseTest.testMapResp(ResponseTest.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:138)
	at com.novocode.junit.JUnitRunner$1.execute(JUnitRunner.java:132)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$.sbt$Tests$$processRunnable$1(Tests.scala:239)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:237)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: This is expected
	at forklift.activemq.test.ResponseConsumerMap.go(ResponseConsumerMap.java:28)
	... 71 more

17:34:52.353 [pool-5-thread-7] ERROR forklift.consumer.MessageRunnable - This is expected
java.lang.reflect.InvocationTargetException
	at sun.reflect.GeneratedMethodAccessor27.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at forklift.consumer.MessageRunnable.lambda$null$7(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$112/2016173749.get(Unknown Source)
	at forklift.consumer.MessageRunnable.runLoggingErrors(MessageRunnable.java:218)
	at forklift.consumer.MessageRunnable.lambda$run$14(MessageRunnable.java:100)
	at forklift.consumer.MessageRunnable$$Lambda$109/151589146.run(Unknown Source)
	at forklift.classloader.RunAsClassLoader.run(RunAsClassLoader.java:14)
	at forklift.consumer.MessageRunnable.run(MessageRunnable.java:61)
	at forklift.consumer.Consumer.messageLoop(Consumer.java:314)
	at forklift.consumer.Consumer.listen(Consumer.java:233)
	at forklift.activemq.test.ResponseTest.testMapResp(ResponseTest.java:96)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:483)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)
	at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runners.Suite.runChild(Suite.java:127)
	at org.junit.runners.Suite.runChild(Suite.java:26)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:309)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:160)
	at org.junit.runner.JUnitCore.run(JUnitCore.java:138)
	at com.novocode.junit.JUnitRunner$1.execute(JUnitRunner.java:132)
	at sbt.TestRunner.runTest$1(TestFramework.scala:76)
	at sbt.TestRunner.run(TestFramework.scala:85)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1$$anonfun$apply$8.apply(TestFramework.scala:202)
	at sbt.TestFramework$.sbt$TestFramework$$withContextLoader(TestFramework.scala:185)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFramework$$anon$2$$anonfun$$init$$1.apply(TestFramework.scala:202)
	at sbt.TestFunction.apply(TestFramework.scala:207)
	at sbt.Tests$.sbt$Tests$$processRunnable$1(Tests.scala:239)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.Tests$$anonfun$makeSerial$1.apply(Tests.scala:245)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$3$$anonfun$apply$2.apply(System.scala:44)
	at sbt.std.Transform$$anon$4.work(System.scala:63)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1$$anonfun$apply$1.apply(Execute.scala:228)
	at sbt.ErrorHandling$.wideConvert(ErrorHandling.scala:17)
	at sbt.Execute.work(Execute.scala:237)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.Execute$$anonfun$submit$1.apply(Execute.scala:228)
	at sbt.ConcurrentRestrictions$$anon$4$$anonfun$1.apply(ConcurrentRestrictions.scala:159)
	at sbt.CompletionService$$anon$2.call(CompletionService.scala:28)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.lang.RuntimeException: This is expected
	at forklift.activemq.test.ResponseConsumerMap.go(ResponseConsumerMap.java:28)
	... 71 more

17:34:52.361 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=6, pending=0 toPageIn: 0, force:false, Inflight: 6, pagedInMessages.size 6, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 14, memUsage:6222, maxPageSize:200
17:34:52.361 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=6, pending=0 toPageIn: 0, force:false, Inflight: 6, pagedInMessages.size 6, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 14, memUsage:6222, maxPageSize:200
17:34:52.362 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=5, pending=0 toPageIn: 0, force:false, Inflight: 5, pagedInMessages.size 5, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 15, memUsage:5185, maxPageSize:200
17:34:52.362 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=5, pending=0 toPageIn: 0, force:false, Inflight: 5, pagedInMessages.size 5, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 15, memUsage:5185, maxPageSize:200
17:34:52.366 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=4, pending=0 toPageIn: 0, force:false, Inflight: 4, pagedInMessages.size 4, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 16, memUsage:4148, maxPageSize:200
17:34:52.366 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=4, pending=0 toPageIn: 0, force:false, Inflight: 4, pagedInMessages.size 4, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 16, memUsage:4148, maxPageSize:200
17:34:52.367 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=3, pending=0 toPageIn: 0, force:false, Inflight: 3, pagedInMessages.size 3, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 17, memUsage:3111, maxPageSize:200
17:34:52.367 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=3, pending=0 toPageIn: 0, force:false, Inflight: 3, pagedInMessages.size 3, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 17, memUsage:3111, maxPageSize:200
17:34:52.368 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=2, pending=0 toPageIn: 0, force:false, Inflight: 2, pagedInMessages.size 2, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 18, memUsage:2074, maxPageSize:200
17:34:52.368 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=2, pending=0 toPageIn: 0, force:false, Inflight: 2, pagedInMessages.size 2, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 18, memUsage:2074, maxPageSize:200
17:34:52.368 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=1, pending=0 toPageIn: 0, force:false, Inflight: 1, pagedInMessages.size 1, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 19, memUsage:1037, maxPageSize:200
17:34:52.368 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=1, pending=0 toPageIn: 0, force:false, Inflight: 1, pagedInMessages.size 1, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 19, memUsage:1037, maxPageSize:200
17:34:52.369 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 20, memUsage:0, maxPageSize:200
17:34:52.369 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=1, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 20, memUsage:0, maxPageSize:200
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.hibernate#hibernate-validator;5.1.2.Final!hibernate-validator.jar (407ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/javax/el/javax.el-api/2.2.4/javax.el-api-2.2.4.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] javax.el#javax.el-api;2.2.4!javax.el-api.jar (30ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/glassfish/web/javax.el/2.2.4/javax.el-2.2.4.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.glassfish.web#javax.el;2.2.4!javax.el.jar (77ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] javax.ws.rs#javax.ws.rs-api;2.0.1!javax.ws.rs-api.jar (75ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] javax.annotation#javax.annotation-api;1.2!javax.annotation-api.jar (25ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/glassfish/jersey/bundles/repackaged/jersey-guava/2.19/jersey-guava-2.19.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.glassfish.jersey.bundles.repackaged#jersey-guava;2.19!jersey-guava.jar(bundle) (464ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/glassfish/hk2/hk2-api/2.4.0-b25/hk2-api-2.4.0-b25.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.glassfish.hk2#hk2-api;2.4.0-b25!hk2-api.jar (111ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/glassfish/hk2/hk2-locator/2.4.0-b25/hk2-locator-2.4.0-b25.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.glassfish.hk2#hk2-locator;2.4.0-b25!hk2-locator.jar (96ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.glassfish.hk2#osgi-resource-locator;1.0.1!osgi-resource-locator.jar (20ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/glassfish/hk2/hk2-utils/2.4.0-b25/hk2-utils-2.4.0-b25.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.glassfish.hk2#hk2-utils;2.4.0-b25!hk2-utils.jar (67ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/glassfish/hk2/external/aopalliance-repackaged/2.4.0-b25/aopalliance-repackaged-2.4.0-b25.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.glassfish.hk2.external#aopalliance-repackaged;2.4.0-b25!aopalliance-repackaged.jar (28ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/glassfish/jersey/core/jersey-client/2.19/jersey-client-2.19.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.glassfish.jersey.core#jersey-client;2.19!jersey-client.jar (88ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/glassfish/jersey/media/jersey-media-jaxb/2.19/jersey-media-jaxb-2.19.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.glassfish.jersey.media#jersey-media-jaxb;2.19!jersey-media-jaxb.jar (45ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/jboss/logging/jboss-logging/3.1.3.GA/jboss-logging-3.1.3.GA.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.jboss.logging#jboss-logging;3.1.3.GA!jboss-logging.jar (40ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/fasterxml/classmate/1.0.0/classmate-1.0.0.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.fasterxml#classmate;1.0.0!classmate.jar(bundle) (48ms)[0m
[0m[[0minfo[0m] [0mdownloading http://packages.confluent.io/maven/io/confluent/common-metrics/3.1.1/common-metrics-3.1.1.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] io.confluent#common-metrics;3.1.1!common-metrics.jar (47ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/glassfish/jersey/containers/jersey-container-servlet/2.19/jersey-container-servlet-2.19.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.glassfish.jersey.containers#jersey-container-servlet;2.19!jersey-container-servlet.jar (19ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-jmx/9.2.12.v20150709/jetty-jmx-9.2.12.v20150709.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.eclipse.jetty#jetty-jmx;9.2.12.v20150709!jetty-jmx.jar (21ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-server/9.2.12.v20150709/jetty-server-9.2.12.v20150709.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.eclipse.jetty#jetty-server;9.2.12.v20150709!jetty-server.jar (209ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-servlet/9.2.12.v20150709/jetty-servlet-9.2.12.v20150709.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.eclipse.jetty#jetty-servlet;9.2.12.v20150709!jetty-servlet.jar (69ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-servlets/9.2.12.v20150709/jetty-servlets-9.2.12.v20150709.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.eclipse.jetty#jetty-servlets;9.2.12.v20150709!jetty-servlets.jar (71ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-jaas/9.2.12.v20150709/jetty-jaas-9.2.12.v20150709.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.eclipse.jetty#jetty-jaas;9.2.12.v20150709!jetty-jaas.jar (33ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/fasterxml/jackson/jaxrs/jackson-jaxrs-json-provider/2.5.4/jackson-jaxrs-json-provider-2.5.4.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.fasterxml.jackson.jaxrs#jackson-jaxrs-json-provider;2.5.4!jackson-jaxrs-json-provider.jar(bundle) (19ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/fasterxml/jackson/jaxrs/jackson-jaxrs-base/2.5.4/jackson-jaxrs-base-2.5.4.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.fasterxml.jackson.jaxrs#jackson-jaxrs-base;2.5.4!jackson-jaxrs-base.jar(bundle) (24ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/glassfish/jersey/containers/jersey-container-servlet-core/2.19/jersey-container-servlet-core-2.19.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.glassfish.jersey.containers#jersey-container-servlet-core;2.19!jersey-container-servlet-core.jar (44ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-util/9.2.12.v20150709/jetty-util-9.2.12.v20150709.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.eclipse.jetty#jetty-util;9.2.12.v20150709!jetty-util.jar (181ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] javax.servlet#javax.servlet-api;3.1.0!javax.servlet-api.jar (57ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-http/9.2.12.v20150709/jetty-http-9.2.12.v20150709.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.eclipse.jetty#jetty-http;9.2.12.v20150709!jetty-http.jar (61ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-io/9.2.12.v20150709/jetty-io-9.2.12.v20150709.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.eclipse.jetty#jetty-io;9.2.12.v20150709!jetty-io.jar (62ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-security/9.2.12.v20150709/jetty-security-9.2.12.v20150709.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.eclipse.jetty#jetty-security;9.2.12.v20150709!jetty-security.jar (59ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/eclipse/jetty/jetty-continuation/9.2.12.v20150709/jetty-continuation-9.2.12.v20150709.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.eclipse.jetty#jetty-continuation;9.2.12.v20150709!jetty-continuation.jar (20ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/fasterxml/jackson/module/jackson-module-jaxb-annotations/2.5.4/jackson-module-jaxb-annotations-2.5.4.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.fasterxml.jackson.module#jackson-module-jaxb-annotations;2.5.4!jackson-module-jaxb-annotations.jar(bundle) (26ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/log4j/log4j/1.2.16/log4j-1.2.16.jar ...[0m
17:34:54.859 [pool-5-thread-7] INFO  forklift.consumer.Consumer - Consumer shutting down
17:34:54.860 [pool-5-thread-7] DEBUG o.a.activemq.ActiveMQMessageConsumer - remove: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1:2:1, lastDeliveredSequenceId: 45
17:34:54.865 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=response,endpoint=Consumer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-24_1,consumerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25_1_2_1
17:34:54.865 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost removing consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1:2:1 for destination: queue://response
17:34:54.865 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.activemq.broker.region.Queue - queue://response remove sub: QueueSubscription: consumer=ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1:2:1, destinations=1, dispatched=0, delivered=0, pending=0, lastDeliveredSeqId: 45, dequeues: 20, dispatched: 20, inflight: 0, groups: 0
17:34:54.866 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.broker.region.Queue - queue://response, subscriptions=0, memory=0%, size=0, pending=0 toPageIn: 0, force:false, Inflight: 0, pagedInMessages.size 0, pagedInPendingDispatch.size 0, enqueueCount: 20, dequeueCount: 20, memUsage:0, maxPageSize:200
17:34:54.867 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:54.867 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:54.874 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.TempQueue_ActiveMQ.Advisory.TempTopic,endpoint=Consumer,clientId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-24_1,consumerId=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25_1_-1_1
17:34:54.875 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.region.AbstractRegion - localhost removing consumer: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1:-1:1 for destination: ActiveMQ.Advisory.TempQueue,ActiveMQ.Advisory.TempTopic
17:34:54.875 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnection - remove connection id: ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-25:1
17:34:54.877 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:54.877 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.TransportConnector - Publishing: tcp://localhost:61618 for broker transport URI: tcp://localhost:61618
17:34:54.878 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@6eb1df21[Shutting down, pool size = 1, active threads = 0, queued tasks = 0, completed tasks = 11] is shutdown: true and terminated: false took: 0.000 seconds.
17:34:54.879 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@1b5af02b[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0] is shutdown: true and terminated: true took: 0.000 seconds.
17:34:54.879 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,connector=clientConnectors,connectorName=tcp_//localhost_61618,connectionViewType=clientId,connectionName=ID_testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-24_1
17:34:54.880 [ActiveMQ Transport: tcp:///127.0.0.1:39160@61618] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,connector=clientConnectors,connectorName=tcp_//localhost_61618,connectionViewType=remoteAddress,connectionName=tcp_//127.0.0.1_39160
17:34:54.880 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.broker.TransportConnection - Stopping connection: tcp://127.0.0.1:39160
17:34:54.880 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.transport.tcp.TcpTransport - Stopping transport tcp:///127.0.0.1:39160@61618
17:34:54.881 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@67b84ed8[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:54.884 [pool-5-thread-7] DEBUG o.a.a.t.failover.FailoverTransport - Stopped tcp://127.0.0.1:61618
17:34:54.885 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@75ec783b[Running, pool size = 2, active threads = 0, queued tasks = 0, completed tasks = 2]
17:34:54.885 [pool-5-thread-7] DEBUG o.a.a.transport.tcp.TcpTransport - Stopping transport tcp:///127.0.0.1:61618@39160
17:34:54.885 [pool-5-thread-7] DEBUG o.a.a.thread.TaskRunnerFactory - Initialized TaskRunnerFactory[ActiveMQ Task] using ExecutorService: java.util.concurrent.ThreadPoolExecutor@599b29f2[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:54.901 [ActiveMQ Task-1] DEBUG o.a.a.transport.tcp.TcpTransport - Closed socket Socket[addr=/127.0.0.1,port=39160,localport=61618]
17:34:54.901 [ActiveMQ Task-1] DEBUG o.a.a.transport.tcp.TcpTransport - Closed socket Socket[addr=/127.0.0.1,port=61618,localport=39160]
17:34:54.902 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@599b29f2[Running, pool size = 1, active threads = 0, queued tasks = 0, completed tasks = 1]
17:34:54.903 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:8) is shutting down
17:34:54.903 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,connector=clientConnectors,connectorName=tcp_//localhost_61618
17:34:54.904 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@67b84ed8[Running, pool size = 1, active threads = 0, queued tasks = 0, completed tasks = 1]
17:34:54.904 [pool-5-thread-7] INFO  o.a.a.broker.TransportConnector - Connector tcp://localhost:61618 stopped
17:34:54.905 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.broker.TransportConnection - Stopped transport: tcp://127.0.0.1:39160
17:34:54.905 [ActiveMQ BrokerService[localhost] Task-1] DEBUG o.a.a.broker.TransportConnection - Connection Stopped: tcp://127.0.0.1:39160
17:34:54.905 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.MasterBroker
17:34:54.905 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Connection
17:34:54.905 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Queue,destinationName=response
17:34:54.905 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Queue
17:34:54.906 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Producer.Queue.response
17:34:54.906 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,destinationType=Topic,destinationName=ActiveMQ.Advisory.Consumer.Queue.response
17:34:54.906 [pool-5-thread-7] INFO  o.a.a.s.kahadb.plist.PListStoreImpl - PListStore:[/tmp/1496424891161-0/localhost/tmp_storage] stopped
17:34:54.906 [pool-5-thread-7] INFO  o.a.a.store.kahadb.KahaDBStore - Stopping async queue tasks
17:34:54.906 [pool-5-thread-7] INFO  o.a.a.store.kahadb.KahaDBStore - Stopping async topic tasks
17:34:54.906 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: org.apache.activemq.store.kahadb.KahaDBStore$StoreTaskExecutor@74486982[Running, pool size = 1, active threads = 0, queued tasks = 0, completed tasks = 20]
17:34:54.907 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: org.apache.activemq.store.kahadb.KahaDBStore$StoreTaskExecutor@7dc679d3[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:54.907 [pool-5-thread-7] INFO  o.a.a.store.kahadb.KahaDBStore - Stopped KahaDB
17:34:54.907 [pool-5-thread-7] DEBUG o.a.a.store.kahadb.MessageDatabase - Checkpoint started.
17:34:54.921 [pool-5-thread-7] DEBUG o.a.a.store.kahadb.MessageDatabase - Checkpoint done.
17:34:54.940 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ScheduledThreadPoolExecutor@1f145c2e[Terminated, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0] is shutdown: true and terminated: true took: 0.004 seconds.
17:34:54.945 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.Executors$DelegatedScheduledExecutorService@901605e is shutdown: true and terminated: true took: 0.004 seconds.
17:34:54.945 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,service=PersistenceAdapter,instanceName=KahaDBPersistenceAdapter[/tmp/1496424891161-0/localhost/KahaDB]
17:34:54.945 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost
17:34:54.945 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,service=Health
17:34:54.945 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unregistering MBean org.apache.activemq:type=Broker,brokerName=localhost,service=Log4JConfiguration
17:34:54.946 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Stopping jmx connector
17:34:54.953 [pool-5-thread-7] DEBUG o.a.a.broker.jmx.ManagementContext - Unexported JMX RMI Registry
17:34:54.954 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@41020f22[Shutting down, pool size = 2, active threads = 0, queued tasks = 0, completed tasks = 66] is shutdown: true and terminated: false took: 0.000 seconds.
17:34:54.954 [pool-5-thread-7] DEBUG o.a.activemq.util.ThreadPoolUtils - Forcing shutdown of ExecutorService: java.util.concurrent.ThreadPoolExecutor@1e18b6ae[Running, pool size = 0, active threads = 0, queued tasks = 0, completed tasks = 0]
17:34:54.954 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:8) uptime 3.793 seconds
17:34:54.954 [pool-5-thread-7] INFO  o.a.activemq.broker.BrokerService - Apache ActiveMQ 5.14.0 (localhost, ID:testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c-35325-1496424860751-0:8) is shutdown
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest forklift.activemq.test.[33mResponseTest[0m.[36mtestObjResp[0m started[0m
[0m[[0minfo[0m] [0mTest forklift.activemq.test.[33mResponseTest[0m.[36mtestMapResp[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 2 total, 7.742s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest forklift.activemq.test.[33mActiveMQHeadersTest[0m.[36msetAllHeaders[0m started[0m
[0m[[0minfo[0m] [0mTest forklift.activemq.test.[33mActiveMQHeadersTest[0m.[36msetBadHeaders[0m started[0m
[0m[[0minfo[0m] [0mTest forklift.activemq.test.[33mActiveMQHeadersTest[0m.[36msetNullHeaders[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 3 total, 0.031s[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 11, Failed 0, Errors 0, Passed 11[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] log4j#log4j;1.2.16!log4j.jar(bundle) (316ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/io/netty/netty/3.10.5.Final/netty-3.10.5.Final.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] io.netty#netty;3.10.5.Final!netty.jar(bundle) (739ms)[0m
[0m[[0minfo[0m] [0mDone updating.[0m
[0m[[0minfo[0m] [0mResolving com.github.dcshock#forklift;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro-compiler;1.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro;1.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.jackson#jackson-core-asl;1.8.8 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.jackson#jackson-mapper-asl;1.8.8 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.thoughtworks.paranamer#paranamer;2.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.xerial.snappy#snappy-java;1.0.4.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-api;1.6.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-lang#commons-lang;2.6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.velocity#velocity;1.7 ...[0m
[0m[[0minfo[0m] [0mAvro compiler using stringType=CharSequence[0m
[0m[[0minfo[0m] [0mResolving commons-collections#commons-collections;3.2.1 ...[0m
[0m[[0minfo[0m] [0mCompiling Avro schema /home/travis/build/dcshock/forklift/connectors/kafka/src/test/resources/schemas/UserRegistered.avsc[0m
[0m[[0minfo[0m] [0mResolving com.google.guava#guava;18.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.core#jackson-databind;2.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.core#jackson-annotations;2.7.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.core#jackson-core;2.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.datatype#jackson-datatype-jsr310;2.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback#logback-classic;1.0.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback#logback-core;1.0.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-api;1.7.5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.reflections#reflections;0.9.10 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.javassist#javassist;3.18.2-GA ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.google.code.findbugs#annotations;2.0.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving javax.inject#javax.inject;1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-compiler;2.11.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-library;2.11.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-reflect;2.11.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang.modules#scala-xml_2.11;1.0.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang.modules#scala-parser-combinators_2.11;1.0.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving jline#jline;2.12 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.github.dcshock#forklift;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro-compiler;1.7.3 ...[0m
[0m[[0minfo[0m] [0mDone updating.[0m
[0m[[0minfo[0m] [0mResolving org.apache.avro#avro;1.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.jackson#jackson-core-asl;1.8.8 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.jackson#jackson-mapper-asl;1.8.8 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.thoughtworks.paranamer#paranamer;2.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.xerial.snappy#snappy-java;1.0.4.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-api;1.6.4 ...[0m
[0m[[0minfo[0m] [0mCompiling 1 Java source to /home/travis/build/dcshock/forklift/plugins/stats/target/classes...[0m
[0m[[0minfo[0m] [0mResolving commons-lang#commons-lang;2.6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.velocity#velocity;1.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-collections#commons-collections;3.2.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.google.guava#guava;18.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.core#jackson-databind;2.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.core#jackson-annotations;2.7.0 ...[0m
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.core#jackson-core;2.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.datatype#jackson-datatype-jsr310;2.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback#logback-classic;1.0.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback#logback-core;1.0.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-api;1.7.5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.reflections#reflections;0.9.10 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.javassist#javassist;3.18.2-GA ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.google.code.findbugs#annotations;2.0.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving javax.inject#javax.inject;1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving io.searchbox#jest;2.0.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving io.searchbox#jest;2.0.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving io.searchbox#jest-parent;2.0.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving io.searchbox#jest-parent;2.0.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.oss#oss-parent;9 ...[0m
[0m[[0minfo[0m] [0mCompiling Avro schema /home/travis/build/dcshock/forklift/connectors/kafka/src/test/resources/schemas/AvroMessage.avsc[0m
[0m[[0minfo[0m] [0mResolving io.searchbox#jest-common;2.0.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving io.searchbox#jest-common;2.0.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving io.searchbox#jest-parent;2.0.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.google.code.gson#gson;2.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.google.code.gson#gson;2.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.oss#oss-parent;9 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-lang3;3.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-lang3;3.4 ...[0m
[0m[[0minfo[0m] [0mCompiling 11 Java sources to /home/travis/build/dcshock/forklift/connectors/kafka/target/classes...[0m
[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-parent;37 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-parent;37 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;16 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;16 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpcore-nio;4.4.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpcore-nio;4.4.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpcomponents-core;4.4.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpcomponents-core;4.4.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#project;7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#project;7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;13 ...[0m
[0m[[0minfo[0m] [0m/home/travis/build/dcshock/forklift/connectors/kafka/src/main/java/forklift/producers/KafkaForkliftProducer.java: /home/travis/build/dcshock/forklift/connectors/kafka/src/main/java/forklift/producers/KafkaForkliftProducer.java uses unchecked or unsafe operations.[0m
[0m[[0minfo[0m] [0m/home/travis/build/dcshock/forklift/connectors/kafka/src/main/java/forklift/producers/KafkaForkliftProducer.java: Recompile with -Xlint:unchecked for details.[0m
[0m[[0minfo[0m] [0mCompiling 17 Java sources to /home/travis/build/dcshock/forklift/connectors/kafka/target/test-classes...[0m
[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpcore;4.4.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpcore;4.4.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpcomponents-core;4.4.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpclient;4.5.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpclient;4.5.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpcomponents-client;4.5.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpcomponents-client;4.5.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#project;7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-logging#commons-logging;1.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-logging#commons-logging;1.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-parent;34 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-parent;34 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-codec#commons-codec;1.9 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-codec#commons-codec;1.9 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-parent;32 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpasyncclient;4.1.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpasyncclient;4.1.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpcomponents-asyncclient;4.1.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpcomponents-asyncclient;4.1.1 ...[0m
[0m[[0minfo[0m] [0m/home/travis/build/dcshock/forklift/connectors/kafka/src/test/java/forklift/connectors/KafkaControllerTests.java: Some input files use unchecked or unsafe operations.[0m
[0m[[0minfo[0m] [0m/home/travis/build/dcshock/forklift/connectors/kafka/src/test/java/forklift/connectors/KafkaControllerTests.java: Recompile with -Xlint:unchecked for details.[0m
[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#project;7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-api;1.7.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-compiler;2.11.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-library;2.11.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-reflect;2.11.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang.modules#scala-xml_2.11;1.0.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang.modules#scala-parser-combinators_2.11;1.0.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving jline#jline;2.12 ...[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/io/searchbox/jest/2.0.0/jest-2.0.0.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] io.searchbox#jest;2.0.0!jest.jar (36ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/io/searchbox/jest-common/2.0.0/jest-common-2.0.0.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] io.searchbox#jest-common;2.0.0!jest-common.jar (139ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/httpcomponents/httpcore-nio/4.4.4/httpcore-nio-4.4.4.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.httpcomponents#httpcore-nio;4.4.4!httpcore-nio.jar (211ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/httpcomponents/httpclient/4.5.1/httpclient-4.5.1.jar ...[0m
17:35:03,135 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback.groovy]
17:35:03,135 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Could NOT find resource [logback-test.xml]
17:35:03,135 |-INFO in ch.qos.logback.classic.LoggerContext[default] - Found resource [logback.xml] at [file:/home/travis/build/dcshock/forklift/connectors/kafka/target/test-classes/logback.xml]
17:35:03,235 |-INFO in ch.qos.logback.classic.joran.action.ConfigurationAction - debug attribute not set
17:35:03,238 |-INFO in ch.qos.logback.core.joran.action.AppenderAction - About to instantiate appender of type [ch.qos.logback.core.ConsoleAppender]
17:35:03,251 |-INFO in ch.qos.logback.core.joran.action.AppenderAction - Naming appender as [STDOUT]
17:35:03,504 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - This appender no longer admits a layout as a sub-component, set an encoder instead.
17:35:03,504 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - To ensure compatibility, wrapping your layout in LayoutWrappingEncoder.
17:35:03,504 |-WARN in ch.qos.logback.core.ConsoleAppender[STDOUT] - See also http://logback.qos.ch/codes.html#layoutInsteadOfEncoder for details
17:35:03,505 |-INFO in ch.qos.logback.classic.joran.action.RootLoggerAction - Setting level of ROOT logger to INFO
17:35:03,505 |-INFO in ch.qos.logback.core.joran.action.AppenderRefAction - Attaching appender named [STDOUT] to Logger[ROOT]
17:35:03,506 |-INFO in ch.qos.logback.classic.joran.action.ConfigurationAction - End of configuration.
17:35:03,507 |-INFO in ch.qos.logback.classic.joran.JoranConfigurator@63a8e36c - Registering current configuration as safe fallback point

2017-06-02 17:35:03 [pool-6-thread-1] INFO  o.a.z.server.ZooKeeperServerMain - Starting server
2017-06-02 17:35:03 [pool-6-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2017-06-02 17:35:03 [pool-6-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:host.name=testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c
2017-06-02 17:35:03 [pool-6-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:java.version=1.8.0_31
2017-06-02 17:35:03 [pool-6-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:java.vendor=Oracle Corporation
2017-06-02 17:35:03 [pool-6-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:java.home=/usr/lib/jvm/java-8-oracle/jre
2017-06-02 17:35:03 [pool-6-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:java.class.path=/home/travis/.sbt/launchers/0.13.13/sbt-launch.jar
2017-06-02 17:35:03 [pool-6-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2017-06-02 17:35:03 [pool-6-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:java.io.tmpdir=/tmp
2017-06-02 17:35:03 [pool-6-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:java.compiler=<NA>
2017-06-02 17:35:03 [pool-6-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:os.name=Linux
2017-06-02 17:35:03 [pool-6-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:os.arch=amd64
2017-06-02 17:35:03 [pool-6-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:os.version=4.8.12-040812-generic
2017-06-02 17:35:03 [pool-6-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:user.name=travis
2017-06-02 17:35:03 [pool-6-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:user.home=/home/travis
2017-06-02 17:35:03 [pool-6-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - Server environment:user.dir=/home/travis/build/dcshock/forklift
2017-06-02 17:35:03 [pool-6-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - tickTime set to 2000
2017-06-02 17:35:03 [pool-6-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - minSessionTimeout set to -1
2017-06-02 17:35:03 [pool-6-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - maxSessionTimeout set to -1
2017-06-02 17:35:03 [pool-6-thread-1] INFO  o.a.z.server.NIOServerCnxnFactory - binding to port 0.0.0.0/0.0.0.0:42181
2017-06-02 17:35:03 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:39692
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.httpcomponents#httpclient;4.5.1!httpclient.jar (481ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/httpcomponents/httpasyncclient/4.1.1/httpasyncclient-4.1.1.jar ...[0m
2017-06-02 17:35:03 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] WARN  o.a.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x0, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_31]
2017-06-02 17:35:03 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /127.0.0.1:39692 (no session established for client)
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.httpcomponents#httpasyncclient;4.1.1!httpasyncclient.jar (177ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/google/code/gson/gson/2.4/gson-2.4.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.google.code.gson#gson;2.4!gson.jar (138ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/commons/commons-lang3/3.4/commons-lang3-3.4.jar ...[0m
2017-06-02 17:35:04 [pool-6-thread-2] INFO  kafka.server.KafkaConfig - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	default.replication.factor = 1
	delete.topic.enable = false
	fetch.purgatory.purge.interval.requests = 1000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.protocol.version = 0.10.1-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listeners = PLAINTEXT://:49092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /home/travis/build/dcshock/forklift/src/test/resources/zafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.10.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 16
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	unclean.leader.election.enable = true
	zookeeper.connect = localhost:42181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.commons#commons-lang3;3.4!commons-lang3.jar (281ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/httpcomponents/httpcore/4.4.4/httpcore-4.4.4.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.httpcomponents#httpcore;4.4.4!httpcore.jar (246ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/commons-logging/commons-logging/1.2/commons-logging-1.2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] commons-logging#commons-logging;1.2!commons-logging.jar (127ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/commons-codec/commons-codec/1.9/commons-codec-1.9.jar ...[0m
2017-06-02 17:35:04 [pool-6-thread-2] INFO  org.apache.zookeeper.ZooKeeper - Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT
2017-06-02 17:35:04 [pool-6-thread-2] INFO  org.apache.zookeeper.ZooKeeper - Client environment:host.name=testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c
2017-06-02 17:35:04 [pool-6-thread-2] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.version=1.8.0_31
2017-06-02 17:35:04 [pool-6-thread-2] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.vendor=Oracle Corporation
2017-06-02 17:35:04 [pool-6-thread-2] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.home=/usr/lib/jvm/java-8-oracle/jre
2017-06-02 17:35:04 [pool-6-thread-2] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.class.path=/home/travis/.sbt/launchers/0.13.13/sbt-launch.jar
2017-06-02 17:35:04 [pool-6-thread-2] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2017-06-02 17:35:04 [pool-6-thread-2] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.io.tmpdir=/tmp
2017-06-02 17:35:04 [pool-6-thread-2] INFO  org.apache.zookeeper.ZooKeeper - Client environment:java.compiler=<NA>
2017-06-02 17:35:04 [pool-6-thread-2] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.name=Linux
2017-06-02 17:35:04 [pool-6-thread-2] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.arch=amd64
2017-06-02 17:35:04 [pool-6-thread-2] INFO  org.apache.zookeeper.ZooKeeper - Client environment:os.version=4.8.12-040812-generic
2017-06-02 17:35:04 [pool-6-thread-2] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.name=travis
2017-06-02 17:35:04 [pool-6-thread-2] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.home=/home/travis
2017-06-02 17:35:04 [pool-6-thread-2] INFO  org.apache.zookeeper.ZooKeeper - Client environment:user.dir=/home/travis/build/dcshock/forklift
2017-06-02 17:35:04 [pool-6-thread-2] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@1494d4ab
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] commons-codec#commons-codec;1.9!commons-codec.jar (262ms)[0m
2017-06-02 17:35:04 [pool-6-thread-2-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:35:04 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:39742
2017-06-02 17:35:04 [pool-6-thread-2-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/127.0.0.1:42181, initiating session
2017-06-02 17:35:04 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:39742
2017-06-02 17:35:04 [SyncThread:0] INFO  o.a.z.server.persistence.FileTxnLog - Creating new log file: log.1
2017-06-02 17:35:04 [pool-6-thread-2-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:42181, sessionid = 0x15c69dff4390000, negotiated timeout = 6000
2017-06-02 17:35:04 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69dff4390000 with negotiated timeout 6000 for client /127.0.0.1:39742
[0m[[0minfo[0m] [0mDone updating.[0m
[0m[[0minfo[0m] [0mResolving com.github.dcshock#forklift;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro-compiler;1.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro;1.7.3 ...[0m
2017-06-02 17:35:05 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x5 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2017-06-02 17:35:05 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0xb zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
[0m[[0minfo[0m] [0mCompiling 5 Java sources to /home/travis/build/dcshock/forklift/plugins/retry/target/classes...[0m
[0m[[0minfo[0m] [0mResolving org.codehaus.jackson#jackson-core-asl;1.8.8 ...[0m
2017-06-02 17:35:05 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x13 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.jackson#jackson-mapper-asl;1.8.8 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.thoughtworks.paranamer#paranamer;2.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.xerial.snappy#snappy-java;1.0.4.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-api;1.6.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-lang#commons-lang;2.6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.velocity#velocity;1.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-collections#commons-collections;3.2.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.google.guava#guava;18.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.core#jackson-databind;2.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.core#jackson-annotations;2.7.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.core#jackson-core;2.7.3 ...[0m
2017-06-02 17:35:05 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x1b zxid:0x11 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.datatype#jackson-datatype-jsr310;2.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback#logback-classic;1.0.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback#logback-core;1.0.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-api;1.7.5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.reflections#reflections;0.9.10 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.javassist#javassist;3.18.2-GA ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.google.code.findbugs#annotations;2.0.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving javax.inject#javax.inject;1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.elasticsearch#elasticsearch;2.4.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.elasticsearch#elasticsearch;2.4.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.elasticsearch#parent;2.4.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.elasticsearch#parent;2.4.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.oss#oss-parent;7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-core;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-core;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-parent;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-parent;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-solr-grandparent;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-solr-grandparent;5.5.2 ...[0m
2017-06-02 17:35:06 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:setData cxid:0x25 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
[A[2K[0m[[0minfo[0m] [0mResolving org.apache#apache;13 ...[0m
2017-06-02 17:35:07 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:delete cxid:0x34 zxid:0x17 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2017-06-02 17:35:07 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x3f zxid:0x18 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2017-06-02 17:35:07 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x40 zxid:0x19 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2017-06-02 17:35:08 [pool-6-thread-2] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:35:08 [pool-6-thread-2] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:35:08 [pool-6-thread-3] INFO  i.c.k.s.rest.SchemaRegistryConfig - SchemaRegistryConfig values: 
	metric.reporters = []
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	kafkastore.ssl.trustmanager.algorithm = PKIX
	authentication.realm = 
	ssl.keystore.type = JKS
	kafkastore.topic = _schemas
	metrics.jmx.prefix = kafka.schema.registry
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.topic.replication.factor = 3
	ssl.truststore.password = 
	kafkastore.timeout.ms = 500
	host.name = localhost
	kafkastore.bootstrap.servers = []
	schema.registry.zk.namespace = schema_registry
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.kerberos.service.name = 
	ssl.endpoint.identification.algorithm = 
	compression.enable = false
	kafkastore.ssl.truststore.type = JKS
	avro.compatibility.level = full
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.truststore.location = 
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	kafkastore.ssl.keystore.type = JKS
	ssl.truststore.type = JKS
	kafkastore.ssl.truststore.password = 
	access.control.allow.origin = 
	ssl.truststore.location = 
	ssl.keystore.password = 
	port = 8081
	kafkastore.ssl.keystore.location = 
	master.eligibility = true
	ssl.client.auth = false
	kafkastore.ssl.keystore.password = 
	kafkastore.security.protocol = PLAINTEXT
	ssl.trustmanager.algorithm = 
	authentication.method = NONE
	request.logger.name = io.confluent.rest-utils.requests
	ssl.key.password = 
	kafkastore.zk.session.timeout.ms = 30000
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.ssl.key.password = 
	zookeeper.set.acl = false
	authentication.roles = [*]
	metrics.num.samples = 2
	ssl.protocol = TLS
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.connection.url = localhost:42181
	debug = false
	listeners = [http://localhost:58081]
	ssl.provider = 
	ssl.enabled.protocols = []
	shutdown.graceful.ms = 1000
	ssl.keystore.location = 
	ssl.cipher.suites = []
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.cipher.suites = 
	access.control.allow.methods = 
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	ssl.keymanager.algorithm = 
	metrics.sample.window.ms = 30000
	kafkastore.init.timeout.ms = 60000

2017-06-02 17:35:11 [pool-6-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@19ff220a
2017-06-02 17:35:11 [pool-6-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:35:11 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:39850
2017-06-02 17:35:11 [pool-6-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/127.0.0.1:42181, initiating session
2017-06-02 17:35:11 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:39850
2017-06-02 17:35:11 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69dff4390001 with negotiated timeout 30000 for client /127.0.0.1:39850
2017-06-02 17:35:11 [pool-6-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:42181, sessionid = 0x15c69dff4390001, negotiated timeout = 30000
2017-06-02 17:35:11 [pool-6-thread-3] INFO  i.c.k.s.storage.KafkaStore - Initializing KafkaStore with broker endpoints: PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092
2017-06-02 17:35:11 [pool-6-thread-3] WARN  i.c.k.s.storage.KafkaStore - Creating the schema topic _schemas using a replication factor of 1, which is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic.
2017-06-02 17:35:11 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390001 type:setData cxid:0x8 zxid:0x1c txntype:-1 reqpath:n/a Error Path:/config/topics/_schemas Error:KeeperErrorCode = NoNode for /config/topics/_schemas
2017-06-02 17:35:11 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390001 type:create cxid:0x9 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:35:11 [pool-6-thread-3] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2017-06-02 17:35:11 [pool-6-thread-3] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	buffer.memory = 33554432
	client.id = producer-1
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2017-06-02 17:35:12 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x4a zxid:0x20 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_schemas/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_schemas/partitions/0
2017-06-02 17:35:12 [pool-6-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:35:12 [pool-6-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:35:12 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x4b zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_schemas/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_schemas/partitions
2017-06-02 17:35:12 [pool-6-thread-3] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	check.crcs = true
	client.id = KafkaStore-reader-_schemas
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = schema-registry-localhost-58081
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-06-02 17:35:12 [pool-6-thread-3] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	check.crcs = true
	client.id = KafkaStore-reader-_schemas
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = schema-registry-localhost-58081
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-06-02 17:35:12 [pool-6-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:35:12 [pool-6-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:35:12 [pool-6-thread-3] INFO  i.c.k.s.s.KafkaStoreReaderThread - Initialized last consumed offset to -1
[2017-06-02 17:35:12,314] INFO [kafka-store-reader-thread-_schemas], Starting  (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-backward-codecs;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-backward-codecs;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-parent;5.5.2 ...[0m
2017-06-02 17:35:12 [pool-6-thread-3] INFO  i.c.k.s.storage.KafkaStore - Wait to catch up until the offset of the last message at 0
2017-06-02 17:35:12 [pool-6-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@73f9bfbd
2017-06-02 17:35:12 [pool-6-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:35:12 [pool-6-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/0:0:0:0:0:0:0:1:42181, initiating session
2017-06-02 17:35:12 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /0:0:0:0:0:0:0:1:57250
2017-06-02 17:35:12 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /0:0:0:0:0:0:0:1:57250
2017-06-02 17:35:12 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69dff4390002 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:57250
2017-06-02 17:35:12 [pool-6-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:42181, sessionid = 0x15c69dff4390002, negotiated timeout = 30000
2017-06-02 17:35:12 [pool-6-thread-3] INFO  i.c.k.s.storage.KafkaSchemaRegistry - Created schema registry namespace localhost:42181/schema_registry
2017-06-02 17:35:12 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69dff4390002
2017-06-02 17:35:12 [pool-6-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69dff4390002 closed
2017-06-02 17:35:12 [pool-6-thread-3-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69dff4390002
2017-06-02 17:35:12 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /0:0:0:0:0:0:0:1:57250 which had sessionid 0x15c69dff4390002
2017-06-02 17:35:12 [pool-6-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181/schema_registry sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@714636c7
2017-06-02 17:35:12 [pool-6-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:35:12 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:39922
2017-06-02 17:35:12 [pool-6-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/127.0.0.1:42181, initiating session
2017-06-02 17:35:12 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:39922
2017-06-02 17:35:12 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69dff4390003 with negotiated timeout 30000 for client /127.0.0.1:39922
2017-06-02 17:35:12 [pool-6-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:42181, sessionid = 0x15c69dff4390003, negotiated timeout = 30000
2017-06-02 17:35:12 [pool-6-thread-3] INFO  i.c.k.s.z.ZookeeperMasterElector - Successfully elected the new master: {"host":"localhost","port":58081,"master_eligibility":true,"version":1}
2017-06-02 17:35:12 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390003 type:create cxid:0x5 zxid:0x2a txntype:-1 reqpath:n/a Error Path:/schema_registry/schema_registry_master Error:KeeperErrorCode = NodeExists for /schema_registry/schema_registry_master
2017-06-02 17:35:12 [ZkClient-EventThread-1255-localhost:42181/schema_registry] INFO  i.c.k.s.z.ZookeeperMasterElector - Successfully elected the new master: {"host":"localhost","port":58081,"master_eligibility":true,"version":1}
2017-06-02 17:35:13 [pool-6-thread-3] INFO  org.eclipse.jetty.util.log - Logging initialized @217922ms
2017-06-02 17:35:13 [pool-6-thread-3] INFO  io.confluent.rest.Application - Adding listener: http://localhost:58081
2017-06-02 17:35:13 [pool-6-thread-3] INFO  org.eclipse.jetty.server.Server - jetty-9.2.12.v20150709
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-analyzers-common;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-analyzers-common;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-parent;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-queries;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-queries;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-parent;5.5.2 ...[0m
[2017-06-02 17:35:16,167] INFO HV000001: Hibernate Validator 5.1.2.Final (org.hibernate.validator.internal.util.Version:27)
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-memory;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-memory;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-parent;5.5.2 ...[0m
2017-06-02 17:35:16 [pool-5-thread-28] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:35:17 [pool-6-thread-3] INFO  o.e.j.server.handler.ContextHandler - Started o.e.j.s.ServletContextHandler@15bbfe67{/,null,AVAILABLE}
2017-06-02 17:35:17 [pool-6-thread-3] INFO  o.e.j.s.NetworkTrafficServerConnector - Started NetworkTrafficServerConnector@c35be21{HTTP/1.1}{localhost:58081}
2017-06-02 17:35:17 [pool-6-thread-3] INFO  org.eclipse.jetty.server.Server - Started @222372ms
2017-06-02 17:35:17 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:35:17 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:35:17 [pool-5-thread-28] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = producer-2
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:35:17 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:35:17 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-highlighter;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-highlighter;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-parent;5.5.2 ...[0m
2017-06-02 17:35:17 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:setData cxid:0x53 zxid:0x2c txntype:-1 reqpath:n/a Error Path:/config/topics/forklift-object-topic Error:KeeperErrorCode = NoNode for /config/topics/forklift-object-topic
2017-06-02 17:35:18 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x54 zxid:0x2d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:35:18 [kafka-producer-network-thread | producer-2] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 0 : {forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:35:18 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x6b zxid:0x30 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/9
2017-06-02 17:35:18 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x6c zxid:0x31 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions
2017-06-02 17:35:18 [kafka-producer-network-thread | producer-2] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 1 : {forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:35:18 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x73 zxid:0x35 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/7
2017-06-02 17:35:18 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x76 zxid:0x38 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/1
2017-06-02 17:35:18 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x7a zxid:0x3b txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/13
2017-06-02 17:35:18 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x7e zxid:0x3e txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/3
2017-06-02 17:35:18 [kafka-producer-network-thread | producer-2] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 2 : {forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:35:18 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x82 zxid:0x41 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/12
2017-06-02 17:35:18 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x85 zxid:0x44 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/6
2017-06-02 17:35:18 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x88 zxid:0x47 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/11
2017-06-02 17:35:18 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x8d zxid:0x4a txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/14
2017-06-02 17:35:18 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x90 zxid:0x4d txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/10
2017-06-02 17:35:18 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x94 zxid:0x50 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/5
2017-06-02 17:35:18 [kafka-producer-network-thread | producer-2] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 3 : {forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:35:18 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x97 zxid:0x53 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/2
2017-06-02 17:35:18 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x9a zxid:0x56 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/15
2017-06-02 17:35:18 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x9d zxid:0x59 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/8
2017-06-02 17:35:18 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0xa0 zxid:0x5c txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/0
2017-06-02 17:35:18 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0xa3 zxid:0x5f txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/4
2017-06-02 17:35:18 [kafka-producer-network-thread | producer-2] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 4 : {forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:35:18 [kafka-producer-network-thread | producer-2] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 5 : {forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:35:19 [kafka-producer-network-thread | producer-2] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 6 : {forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:35:19 [kafka-producer-network-thread | producer-2] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 7 : {forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:35:19 [kafka-producer-network-thread | producer-2] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 8 : {forklift-object-topic=LEADER_NOT_AVAILABLE}
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-join;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-join;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-parent;5.5.2 ...[0m
2017-06-02 17:35:20 [qtp713480909-1265] INFO  i.c.k.s.storage.KafkaStore - Wait to catch up until the offset of the last message at 1
2017-06-02 17:35:20 [qtp713480909-1265] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:35:19 +0000] "POST /subjects/forklift-object-topic-value/versions HTTP/1.1" 200 8  836
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-grouping;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-grouping;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-parent;5.5.2 ...[0m
2017-06-02 17:35:21 [pool-5-thread-28] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:35:21 [pool-5-thread-28] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = consumer-1
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:35:21 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:35:21 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:35:21 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:35:21 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:35:21 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:setData cxid:0xc9 zxid:0x62 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2017-06-02 17:35:21 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0xca zxid:0x63 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-queryparser;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-queryparser;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-parent;5.5.2 ...[0m
2017-06-02 17:35:21 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x106 zxid:0x66 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2017-06-02 17:35:21 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x107 zxid:0x67 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2017-06-02 17:35:21 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x10b zxid:0x6b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2017-06-02 17:35:21 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x111 zxid:0x6e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2017-06-02 17:35:21 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x114 zxid:0x71 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2017-06-02 17:35:21 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x117 zxid:0x74 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2017-06-02 17:35:21 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x11a zxid:0x77 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2017-06-02 17:35:21 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x11f zxid:0x7a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x123 zxid:0x7d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x126 zxid:0x80 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x12b zxid:0x83 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x12f zxid:0x86 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x132 zxid:0x89 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x135 zxid:0x8c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x138 zxid:0x8f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x13b zxid:0x92 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x13e zxid:0x95 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x141 zxid:0x98 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x147 zxid:0x9b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x14a zxid:0x9e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x14d zxid:0xa1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x153 zxid:0xa4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x156 zxid:0xa7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x15a zxid:0xaa txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x15f zxid:0xad txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x165 zxid:0xb0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x168 zxid:0xb3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x16b zxid:0xb6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x16e zxid:0xb9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x171 zxid:0xbc txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x174 zxid:0xbf txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x177 zxid:0xc2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x17d zxid:0xc5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x180 zxid:0xc8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x183 zxid:0xcb txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x186 zxid:0xce txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x189 zxid:0xd1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x18c zxid:0xd4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x18f zxid:0xd7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x192 zxid:0xda txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x195 zxid:0xdd txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x198 zxid:0xe0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x19b zxid:0xe3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x19e zxid:0xe6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x1a1 zxid:0xe9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x1a4 zxid:0xec txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x1a7 zxid:0xef txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x1ad zxid:0xf2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x1b0 zxid:0xf5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x1b3 zxid:0xf8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2017-06-02 17:35:22 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69dff4390000 type:create cxid:0x1b6 zxid:0xfb txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-sandbox;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-sandbox;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-parent;5.5.2 ...[0m
2017-06-02 17:35:23 [pool-13-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:35:23 [pool-13-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [] for group testGroup
2017-06-02 17:35:23 [pool-13-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:35:23 [pool-13-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-suggest;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-suggest;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-parent;5.5.2 ...[0m
2017-06-02 17:35:23 [pool-13-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:35:23 [pool-13-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:35:24 [pool-13-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Successfully joined group testGroup with generation 1
2017-06-02 17:35:24 [pool-13-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Setting newly assigned partitions [forklift-object-topic-2, forklift-object-topic-1, forklift-object-topic-0, forklift-object-topic-6, forklift-object-topic-5, forklift-object-topic-4, forklift-object-topic-3, forklift-object-topic-10, forklift-object-topic-9, forklift-object-topic-8, forklift-object-topic-7, forklift-object-topic-14, forklift-object-topic-13, forklift-object-topic-12, forklift-object-topic-11, forklift-object-topic-15] for group testGroup
2017-06-02 17:35:24 [qtp713480909-1267] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:35:24 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 552  124
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-misc;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-misc;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-parent;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-spatial;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-spatial;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-parent;5.5.2 ...[0m
2017-06-02 17:35:27 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:35:27 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - SentIds: 100 consumedIds: 100
2017-06-02 17:35:27 [pool-13-thread-1] INFO  forklift.controller.KafkaController - Wakeup, controlLoop exiting
2017-06-02 17:35:27 [pool-13-thread-1] INFO  forklift.controller.KafkaController - closing offset size committed: 16
2017-06-02 17:35:27 [pool-13-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:35:27 [pool-13-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:35:27 [pool-13-thread-1] INFO  forklift.controller.KafkaController - controlLoop closing kafkaConsumer
2017-06-02 17:35:27 [pool-5-thread-28] INFO  o.a.k.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-06-02 17:35:27 [pool-5-thread-28] INFO  o.e.j.s.NetworkTrafficServerConnector - Stopped NetworkTrafficServerConnector@c35be21{HTTP/1.1}{localhost:58081}
2017-06-02 17:35:27 [pool-5-thread-28] INFO  o.e.j.server.handler.ContextHandler - Stopped o.e.j.s.ServletContextHandler@15bbfe67{/,null,UNAVAILABLE}
2017-06-02 17:35:27 [pool-5-thread-28] INFO  i.c.k.s.storage.KafkaSchemaRegistry - Shutting down schema registry
[2017-06-02 17:35:27,637] INFO [kafka-store-reader-thread-_schemas], Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
[2017-06-02 17:35:27,641] INFO [kafka-store-reader-thread-_schemas], Stopped  (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
[2017-06-02 17:35:27,642] INFO [kafka-store-reader-thread-_schemas], Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
2017-06-02 17:35:27 [pool-5-thread-28] INFO  i.c.k.s.s.KafkaStoreReaderThread - KafkaStoreReaderThread shutdown complete.
2017-06-02 17:35:27 [pool-5-thread-28] INFO  o.a.k.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-06-02 17:35:27 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69dff4390001
2017-06-02 17:35:27 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /127.0.0.1:39850 which had sessionid 0x15c69dff4390001
2017-06-02 17:35:27 [pool-5-thread-28] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69dff4390001 closed
2017-06-02 17:35:27 [pool-6-thread-3-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69dff4390001
2017-06-02 17:35:27 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69dff4390003
2017-06-02 17:35:27 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /127.0.0.1:39922 which had sessionid 0x15c69dff4390003
2017-06-02 17:35:27 [pool-5-thread-28] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69dff4390003 closed
2017-06-02 17:35:27 [pool-6-thread-3-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69dff4390003
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-spatial3d;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-spatial3d;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-parent;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.spatial4j#spatial4j;0.5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.spatial4j#spatial4j;0.5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.oss#oss-parent;7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.elasticsearch#securesm;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.elasticsearch#securesm;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.oss#oss-parent;7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.carrotsearch#hppc;0.7.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.carrotsearch#hppc;0.7.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.carrotsearch#hppc-parent;0.7.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.carrotsearch#hppc-parent;0.7.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.oss#oss-parent;9 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving joda-time#joda-time;2.9.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving joda-time#joda-time;2.9.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.joda#joda-convert;1.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.joda#joda-convert;1.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.core#jackson-core;2.8.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.core#jackson-core;2.8.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson#jackson-parent;2.8 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson#jackson-parent;2.8 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml#oss-parent;27 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml#oss-parent;27 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.dataformat#jackson-dataformat-smile;2.8.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.dataformat#jackson-dataformat-smile;2.8.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.dataformat#jackson-dataformats-binary;2.8.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.dataformat#jackson-dataformats-binary;2.8.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson#jackson-parent;2.8 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.dataformat#jackson-dataformat-yaml;2.8.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.dataformat#jackson-dataformat-yaml;2.8.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson#jackson-parent;2.8 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.yaml#snakeyaml;1.15 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.yaml#snakeyaml;1.15 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.dataformat#jackson-dataformat-cbor;2.8.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.dataformat#jackson-dataformat-cbor;2.8.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.dataformat#jackson-dataformats-binary;2.8.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving io.netty#netty;3.10.6.Final ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving io.netty#netty;3.10.6.Final ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.oss#oss-parent;9 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.ning#compress-lzf;1.0.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.ning#compress-lzf;1.0.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.oss#oss-parent;7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.tdunning#t-digest;3.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.tdunning#t-digest;3.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.hdrhistogram#HdrHistogram;2.1.6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.hdrhistogram#HdrHistogram;2.1.6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.oss#oss-parent;7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-cli#commons-cli;1.3.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-cli#commons-cli;1.3.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-parent;37 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.twitter#jsr166e;1.1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.twitter#jsr166e;1.1.0 ...[0m
2017-06-02 17:35:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69dff4390000
2017-06-02 17:35:31 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /127.0.0.1:39742 which had sessionid 0x15c69dff4390000
2017-06-02 17:35:31 [pool-5-thread-28] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69dff4390000 closed
2017-06-02 17:35:31 [pool-6-thread-2-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69dff4390000
[A[2K[0m[[0minfo[0m] [0mResolving com.novocode#junit-interface;0.11 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving junit#junit;4.11 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.hamcrest#hamcrest-core;1.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#test-interface;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-compiler;2.11.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-library;2.11.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-reflect;2.11.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang.modules#scala-xml_2.11;1.0.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang.modules#scala-parser-combinators_2.11;1.0.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving jline#jline;2.12 ...[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/elasticsearch/elasticsearch/2.4.1/elasticsearch-2.4.1.jar ...[0m
2017-06-02 17:35:32 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - NIOServerCnxn factory exited run method
2017-06-02 17:35:32 [pool-5-thread-28] INFO  o.a.zookeeper.server.ZooKeeperServer - shutting down
2017-06-02 17:35:32 [pool-5-thread-28] INFO  o.a.z.server.SessionTrackerImpl - Shutting down
2017-06-02 17:35:32 [pool-5-thread-28] INFO  o.a.z.server.PrepRequestProcessor - Shutting down
2017-06-02 17:35:32 [pool-5-thread-28] INFO  o.a.z.server.SyncRequestProcessor - Shutting down
2017-06-02 17:35:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - PrepRequestProcessor exited loop!
2017-06-02 17:35:32 [SyncThread:0] INFO  o.a.z.server.SyncRequestProcessor - SyncRequestProcessor exited!
2017-06-02 17:35:32 [pool-5-thread-28] INFO  o.a.z.server.FinalRequestProcessor - shutdown of request processor complete
2017-06-02 17:35:34 [SessionTracker] INFO  o.a.z.server.SessionTrackerImpl - SessionTrackerImpl exited loop!
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest forklift.integration.[33mObjectMessageTests[0m.[36mtestSendObjectMessage[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 1 total, 31.384s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest forklift.message.[33mKafkaMessageTests[0m.[36macknowledgeCallsControllerSuccess[0m started[0m
[0m[[0minfo[0m] [0mTest forklift.message.[33mKafkaMessageTests[0m.[36macknowledgeFalseTest[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 2 total, 0.305s[0m[0m
2017-06-02 17:35:34 [pool-15-thread-1] INFO  o.a.z.server.ZooKeeperServerMain - Starting server
2017-06-02 17:35:34 [pool-15-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - tickTime set to 2000
2017-06-02 17:35:34 [pool-15-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - minSessionTimeout set to -1
2017-06-02 17:35:34 [pool-15-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - maxSessionTimeout set to -1
2017-06-02 17:35:34 [pool-15-thread-1] INFO  o.a.z.server.NIOServerCnxnFactory - binding to port 0.0.0.0/0.0.0.0:42181
2017-06-02 17:35:34 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:40072
2017-06-02 17:35:34 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] WARN  o.a.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x0, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_31]
2017-06-02 17:35:34 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /127.0.0.1:40072 (no session established for client)
2017-06-02 17:35:34 [pool-15-thread-2] INFO  kafka.server.KafkaConfig - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	default.replication.factor = 1
	delete.topic.enable = false
	fetch.purgatory.purge.interval.requests = 1000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.protocol.version = 0.10.1-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listeners = PLAINTEXT://:49092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /home/travis/build/dcshock/forklift/src/test/resources/zafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.10.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 16
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	unclean.leader.election.enable = true
	zookeeper.connect = localhost:42181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2017-06-02 17:35:34 [pool-15-thread-2] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@532c1747
2017-06-02 17:35:34 [pool-15-thread-2-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:35:34 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /0:0:0:0:0:0:0:1:57410
2017-06-02 17:35:34 [pool-15-thread-2-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/0:0:0:0:0:0:0:1:42181, initiating session
2017-06-02 17:35:34 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /0:0:0:0:0:0:0:1:57410
2017-06-02 17:35:34 [SyncThread:0] INFO  o.a.z.server.persistence.FileTxnLog - Creating new log file: log.1
2017-06-02 17:35:34 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e06d750000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:57410
2017-06-02 17:35:34 [pool-15-thread-2-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:42181, sessionid = 0x15c69e06d750000, negotiated timeout = 6000
2017-06-02 17:35:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x4 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2017-06-02 17:35:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0xa zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2017-06-02 17:35:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x12 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2017-06-02 17:35:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x1a zxid:0x11 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2017-06-02 17:35:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:setData cxid:0x23 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2017-06-02 17:35:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:delete cxid:0x33 zxid:0x17 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2017-06-02 17:35:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x3e zxid:0x18 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2017-06-02 17:35:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x3f zxid:0x19 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2017-06-02 17:35:36 [pool-15-thread-2] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:35:36 [pool-15-thread-2] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.elasticsearch#elasticsearch;2.4.1!elasticsearch.jar (5223ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/lucene/lucene-core/5.5.2/lucene-core-5.5.2.jar ...[0m
2017-06-02 17:35:37 [pool-15-thread-3] INFO  i.c.k.s.rest.SchemaRegistryConfig - SchemaRegistryConfig values: 
	metric.reporters = []
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	kafkastore.ssl.trustmanager.algorithm = PKIX
	authentication.realm = 
	ssl.keystore.type = JKS
	kafkastore.topic = _schemas
	metrics.jmx.prefix = kafka.schema.registry
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.topic.replication.factor = 3
	ssl.truststore.password = 
	kafkastore.timeout.ms = 500
	host.name = localhost
	kafkastore.bootstrap.servers = []
	schema.registry.zk.namespace = schema_registry
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.kerberos.service.name = 
	ssl.endpoint.identification.algorithm = 
	compression.enable = false
	kafkastore.ssl.truststore.type = JKS
	avro.compatibility.level = full
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.truststore.location = 
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	kafkastore.ssl.keystore.type = JKS
	ssl.truststore.type = JKS
	kafkastore.ssl.truststore.password = 
	access.control.allow.origin = 
	ssl.truststore.location = 
	ssl.keystore.password = 
	port = 8081
	kafkastore.ssl.keystore.location = 
	master.eligibility = true
	ssl.client.auth = false
	kafkastore.ssl.keystore.password = 
	kafkastore.security.protocol = PLAINTEXT
	ssl.trustmanager.algorithm = 
	authentication.method = NONE
	request.logger.name = io.confluent.rest-utils.requests
	ssl.key.password = 
	kafkastore.zk.session.timeout.ms = 30000
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.ssl.key.password = 
	zookeeper.set.acl = false
	authentication.roles = [*]
	metrics.num.samples = 2
	ssl.protocol = TLS
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.connection.url = localhost:42181
	debug = false
	listeners = [http://localhost:58081]
	ssl.provider = 
	ssl.enabled.protocols = []
	shutdown.graceful.ms = 1000
	ssl.keystore.location = 
	ssl.cipher.suites = []
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.cipher.suites = 
	access.control.allow.methods = 
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	ssl.keymanager.algorithm = 
	metrics.sample.window.ms = 30000
	kafkastore.init.timeout.ms = 60000

2017-06-02 17:35:37 [pool-15-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@350e600c
2017-06-02 17:35:37 [pool-15-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:35:37 [pool-15-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/0:0:0:0:0:0:0:1:42181, initiating session
2017-06-02 17:35:37 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /0:0:0:0:0:0:0:1:57440
2017-06-02 17:35:37 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /0:0:0:0:0:0:0:1:57440
2017-06-02 17:35:37 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e06d750001 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:57440
2017-06-02 17:35:37 [pool-15-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:42181, sessionid = 0x15c69e06d750001, negotiated timeout = 30000
2017-06-02 17:35:37 [pool-15-thread-3] INFO  i.c.k.s.storage.KafkaStore - Initializing KafkaStore with broker endpoints: PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092
2017-06-02 17:35:37 [pool-15-thread-3] WARN  i.c.k.s.storage.KafkaStore - Creating the schema topic _schemas using a replication factor of 1, which is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic.
2017-06-02 17:35:37 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750001 type:setData cxid:0x8 zxid:0x1c txntype:-1 reqpath:n/a Error Path:/config/topics/_schemas Error:KeeperErrorCode = NoNode for /config/topics/_schemas
2017-06-02 17:35:37 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750001 type:create cxid:0x9 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:35:37 [pool-15-thread-3] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2017-06-02 17:35:37 [pool-15-thread-3] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	buffer.memory = 33554432
	client.id = producer-3
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2017-06-02 17:35:37 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x49 zxid:0x20 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_schemas/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_schemas/partitions/0
2017-06-02 17:35:37 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x4a zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_schemas/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_schemas/partitions
2017-06-02 17:35:37 [pool-15-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:35:37 [pool-15-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:35:37 [pool-15-thread-3] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	check.crcs = true
	client.id = KafkaStore-reader-_schemas
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = schema-registry-localhost-58081
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-06-02 17:35:37 [pool-15-thread-3] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	check.crcs = true
	client.id = KafkaStore-reader-_schemas
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = schema-registry-localhost-58081
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-06-02 17:35:37 [pool-15-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:35:37 [pool-15-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:35:38 [pool-15-thread-3] INFO  i.c.k.s.s.KafkaStoreReaderThread - Initialized last consumed offset to -1
[2017-06-02 17:35:38,087] INFO [kafka-store-reader-thread-_schemas], Starting  (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
2017-06-02 17:35:38 [pool-15-thread-3] INFO  i.c.k.s.storage.KafkaStore - Wait to catch up until the offset of the last message at 0
2017-06-02 17:35:38 [pool-15-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@120877fa
2017-06-02 17:35:38 [pool-15-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:35:38 [pool-15-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/0:0:0:0:0:0:0:1:42181, initiating session
2017-06-02 17:35:38 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /0:0:0:0:0:0:0:1:57462
2017-06-02 17:35:38 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /0:0:0:0:0:0:0:1:57462
2017-06-02 17:35:38 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e06d750002 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:57462
2017-06-02 17:35:38 [pool-15-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:42181, sessionid = 0x15c69e06d750002, negotiated timeout = 30000
2017-06-02 17:35:38 [pool-15-thread-3] INFO  i.c.k.s.storage.KafkaSchemaRegistry - Created schema registry namespace localhost:42181/schema_registry
2017-06-02 17:35:38 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e06d750002
2017-06-02 17:35:38 [pool-15-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e06d750002 closed
2017-06-02 17:35:38 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] WARN  o.a.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x15c69e06d750002, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_31]
2017-06-02 17:35:38 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /0:0:0:0:0:0:0:1:57462 which had sessionid 0x15c69e06d750002
2017-06-02 17:35:38 [pool-15-thread-3-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e06d750002
2017-06-02 17:35:38 [pool-15-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181/schema_registry sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@1d50a76d
2017-06-02 17:35:38 [pool-15-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:35:38 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:40134
2017-06-02 17:35:38 [pool-15-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/127.0.0.1:42181, initiating session
2017-06-02 17:35:38 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:40134
2017-06-02 17:35:38 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e06d750003 with negotiated timeout 30000 for client /127.0.0.1:40134
2017-06-02 17:35:38 [pool-15-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:42181, sessionid = 0x15c69e06d750003, negotiated timeout = 30000
2017-06-02 17:35:38 [pool-15-thread-3] INFO  i.c.k.s.z.ZookeeperMasterElector - Successfully elected the new master: {"host":"localhost","port":58081,"master_eligibility":true,"version":1}
2017-06-02 17:35:38 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750003 type:create cxid:0x7 zxid:0x2b txntype:-1 reqpath:n/a Error Path:/schema_registry/schema_registry_master Error:KeeperErrorCode = NodeExists for /schema_registry/schema_registry_master
2017-06-02 17:35:38 [pool-15-thread-3] INFO  io.confluent.rest.Application - Adding listener: http://localhost:58081
2017-06-02 17:35:38 [ZkClient-EventThread-1330-localhost:42181/schema_registry] INFO  i.c.k.s.z.ZookeeperMasterElector - Successfully elected the new master: {"host":"localhost","port":58081,"master_eligibility":true,"version":1}
2017-06-02 17:35:38 [pool-15-thread-3] INFO  org.eclipse.jetty.server.Server - jetty-9.2.12.v20150709
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.lucene#lucene-core;5.5.2!lucene-core.jar (1492ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/lucene/lucene-backward-codecs/5.5.2/lucene-backward-codecs-5.5.2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.lucene#lucene-backward-codecs;5.5.2!lucene-backward-codecs.jar (299ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/lucene/lucene-analyzers-common/5.5.2/lucene-analyzers-common-5.5.2.jar ...[0m
2017-06-02 17:35:39 [pool-15-thread-3] INFO  o.e.j.server.handler.ContextHandler - Started o.e.j.s.ServletContextHandler@6727d07{/,null,AVAILABLE}
2017-06-02 17:35:39 [pool-15-thread-3] INFO  o.e.j.s.NetworkTrafficServerConnector - Started NetworkTrafficServerConnector@7827f573{HTTP/1.1}{localhost:58081}
2017-06-02 17:35:39 [pool-15-thread-3] INFO  org.eclipse.jetty.server.Server - Started @244224ms
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.lucene#lucene-analyzers-common;5.5.2!lucene-analyzers-common.jar (988ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/lucene/lucene-queries/5.5.2/lucene-queries-5.5.2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.lucene#lucene-queries;5.5.2!lucene-queries.jar (140ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/lucene/lucene-memory/5.5.2/lucene-memory-5.5.2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.lucene#lucene-memory;5.5.2!lucene-memory.jar (36ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/lucene/lucene-highlighter/5.5.2/lucene-highlighter-5.5.2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.lucene#lucene-highlighter;5.5.2!lucene-highlighter.jar (91ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/lucene/lucene-queryparser/5.5.2/lucene-queryparser-5.5.2.jar ...[0m
2017-06-02 17:35:40 [pool-5-thread-28] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:35:40 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:35:40 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:35:40 [pool-5-thread-28] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = producer-4
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:35:40 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:35:40 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:35:40 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:setData cxid:0x52 zxid:0x2c txntype:-1 reqpath:n/a Error Path:/config/topics/forklift-map-topic Error:KeeperErrorCode = NoNode for /config/topics/forklift-map-topic
2017-06-02 17:35:40 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x53 zxid:0x2d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:35:40 [kafka-producer-network-thread | producer-4] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 0 : {forklift-map-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:35:40 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x6a zxid:0x30 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/13
2017-06-02 17:35:40 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x6b zxid:0x31 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.lucene#lucene-queryparser;5.5.2!lucene-queryparser.jar (227ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/lucene/lucene-suggest/5.5.2/lucene-suggest-5.5.2.jar ...[0m
2017-06-02 17:35:40 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x6f zxid:0x35 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/3
2017-06-02 17:35:40 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x72 zxid:0x38 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/15
2017-06-02 17:35:40 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x75 zxid:0x3b txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/14
2017-06-02 17:35:40 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x78 zxid:0x3e txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/6
2017-06-02 17:35:40 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x7b zxid:0x41 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/11
2017-06-02 17:35:40 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x80 zxid:0x44 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/9
2017-06-02 17:35:40 [kafka-producer-network-thread | producer-4] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 1 : {forklift-map-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:35:40 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x84 zxid:0x47 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/8
2017-06-02 17:35:40 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x87 zxid:0x4a txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/1
2017-06-02 17:35:40 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x8a zxid:0x4d txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/4
2017-06-02 17:35:40 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x8d zxid:0x50 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/10
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.lucene#lucene-suggest;5.5.2!lucene-suggest.jar (143ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/lucene/lucene-join/5.5.2/lucene-join-5.5.2.jar ...[0m
2017-06-02 17:35:40 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x90 zxid:0x53 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/7
2017-06-02 17:35:40 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x93 zxid:0x56 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/5
2017-06-02 17:35:40 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x96 zxid:0x59 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/12
2017-06-02 17:35:40 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x9b zxid:0x5c txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/0
2017-06-02 17:35:40 [kafka-producer-network-thread | producer-4] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 2 : {forklift-map-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:35:40 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x9f zxid:0x5f txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/2
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.lucene#lucene-join;5.5.2!lucene-join.jar (95ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/lucene/lucene-spatial/5.5.2/lucene-spatial-5.5.2.jar ...[0m
2017-06-02 17:35:40 [kafka-producer-network-thread | producer-4] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 3 : {forklift-map-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:35:40 [kafka-producer-network-thread | producer-4] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 4 : {forklift-map-topic=LEADER_NOT_AVAILABLE}
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.lucene#lucene-spatial;5.5.2!lucene-spatial.jar (258ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/elasticsearch/securesm/1.0/securesm-1.0.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.elasticsearch#securesm;1.0!securesm.jar (12ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/carrotsearch/hppc/0.7.1/hppc-0.7.1.jar ...[0m
2017-06-02 17:35:41 [qtp1629212103-1340] INFO  i.c.k.s.storage.KafkaStore - Wait to catch up until the offset of the last message at 1
2017-06-02 17:35:41 [qtp1629212103-1340] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:35:41 +0000] "POST /subjects/forklift-map-topic-value/versions HTTP/1.1" 200 8  293
2017-06-02 17:35:41 [pool-5-thread-28] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:35:41 [pool-5-thread-28] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = consumer-2
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:35:41 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:35:41 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:35:41 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:35:41 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:35:41 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:setData cxid:0xbc zxid:0x62 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2017-06-02 17:35:41 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0xbd zxid:0x63 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.carrotsearch#hppc;0.7.1!hppc.jar (748ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/joda-time/joda-time/2.9.4/joda-time-2.9.4.jar ...[0m
2017-06-02 17:35:41 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0xfc zxid:0x66 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2017-06-02 17:35:41 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0xfd zxid:0x67 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2017-06-02 17:35:41 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x101 zxid:0x6b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2017-06-02 17:35:41 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x104 zxid:0x6e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2017-06-02 17:35:41 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x107 zxid:0x71 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2017-06-02 17:35:41 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x10d zxid:0x74 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2017-06-02 17:35:41 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x110 zxid:0x77 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2017-06-02 17:35:41 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x113 zxid:0x7a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2017-06-02 17:35:41 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x116 zxid:0x7d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x11c zxid:0x80 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x11f zxid:0x83 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x122 zxid:0x86 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x125 zxid:0x89 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x128 zxid:0x8c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x12b zxid:0x8f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x12e zxid:0x92 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x131 zxid:0x95 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x137 zxid:0x98 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x13a zxid:0x9b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] joda-time#joda-time;2.9.4!joda-time.jar (331ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/joda/joda-convert/1.2/joda-convert-1.2.jar ...[0m
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x13d zxid:0x9e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x140 zxid:0xa1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x143 zxid:0xa4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x146 zxid:0xa7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x149 zxid:0xaa txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x14c zxid:0xad txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.joda#joda-convert;1.2!joda-convert.jar (40ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-core/2.8.1/jackson-core-2.8.1.jar ...[0m
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x14f zxid:0xb0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x152 zxid:0xb3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x157 zxid:0xb6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x15b zxid:0xb9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x15e zxid:0xbc txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x161 zxid:0xbf txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x164 zxid:0xc2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x167 zxid:0xc5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x16a zxid:0xc8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x16d zxid:0xcb txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x171 zxid:0xce txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x176 zxid:0xd1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.fasterxml.jackson.core#jackson-core;2.8.1!jackson-core.jar(bundle) (172ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/fasterxml/jackson/dataformat/jackson-dataformat-smile/2.8.1/jackson-dataformat-smile-2.8.1.jar ...[0m
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x179 zxid:0xd4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x17c zxid:0xd7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x17f zxid:0xda txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x182 zxid:0xdd txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.fasterxml.jackson.dataformat#jackson-dataformat-smile;2.8.1!jackson-dataformat-smile.jar(bundle) (73ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/fasterxml/jackson/dataformat/jackson-dataformat-yaml/2.8.1/jackson-dataformat-yaml-2.8.1.jar ...[0m
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x185 zxid:0xe0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x18b zxid:0xe3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.fasterxml.jackson.dataformat#jackson-dataformat-yaml;2.8.1!jackson-dataformat-yaml.jar(bundle) (39ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/fasterxml/jackson/dataformat/jackson-dataformat-cbor/2.8.1/jackson-dataformat-cbor-2.8.1.jar ...[0m
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x18e zxid:0xe6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x191 zxid:0xe9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x194 zxid:0xec txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.fasterxml.jackson.dataformat#jackson-dataformat-cbor;2.8.1!jackson-dataformat-cbor.jar(bundle) (43ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/yaml/snakeyaml/1.15/snakeyaml-1.15.jar ...[0m
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x197 zxid:0xef txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x19c zxid:0xf2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x1a0 zxid:0xf5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x1a3 zxid:0xf8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2017-06-02 17:35:42 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e06d750000 type:create cxid:0x1a6 zxid:0xfb txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.yaml#snakeyaml;1.15!snakeyaml.jar(bundle) (160ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/io/netty/netty/3.10.6.Final/netty-3.10.6.Final.jar ...[0m
2017-06-02 17:35:43 [pool-22-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:35:43 [pool-22-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [] for group testGroup
2017-06-02 17:35:43 [pool-22-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:35:43 [pool-22-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Successfully joined group testGroup with generation 1
2017-06-02 17:35:43 [pool-22-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Setting newly assigned partitions [forklift-map-topic-13, forklift-map-topic-12, forklift-map-topic-15, forklift-map-topic-14, forklift-map-topic-9, forklift-map-topic-8, forklift-map-topic-11, forklift-map-topic-10, forklift-map-topic-5, forklift-map-topic-4, forklift-map-topic-7, forklift-map-topic-6, forklift-map-topic-1, forklift-map-topic-0, forklift-map-topic-3, forklift-map-topic-2] for group testGroup
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] io.netty#netty;3.10.6.Final!netty.jar(bundle) (787ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/ning/compress-lzf/1.0.2/compress-lzf-1.0.2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.ning#compress-lzf;1.0.2!compress-lzf.jar(bundle) (1354ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/tdunning/t-digest/3.0/t-digest-3.0.jar ...[0m
2017-06-02 17:35:44 [qtp1629212103-1341] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:35:44 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 552  139
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.tdunning#t-digest;3.0!t-digest.jar (179ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/hdrhistogram/HdrHistogram/2.1.6/HdrHistogram-2.1.6.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.hdrhistogram#HdrHistogram;2.1.6!HdrHistogram.jar(bundle) (140ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/commons-cli/commons-cli/1.3.1/commons-cli-1.3.1.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] commons-cli#commons-cli;1.3.1!commons-cli.jar (54ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/twitter/jsr166e/1.1.0/jsr166e-1.1.0.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.twitter#jsr166e;1.1.0!jsr166e.jar (105ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/lucene/lucene-grouping/5.5.2/lucene-grouping-5.5.2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.lucene#lucene-grouping;5.5.2!lucene-grouping.jar (94ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/lucene/lucene-sandbox/5.5.2/lucene-sandbox-5.5.2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.lucene#lucene-sandbox;5.5.2!lucene-sandbox.jar (192ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/lucene/lucene-misc/5.5.2/lucene-misc-5.5.2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.lucene#lucene-misc;5.5.2!lucene-misc.jar (111ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/lucene/lucene-spatial3d/5.5.2/lucene-spatial3d-5.5.2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.lucene#lucene-spatial3d;5.5.2!lucene-spatial3d.jar (110ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/spatial4j/spatial4j/0.5/spatial4j-0.5.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.spatial4j#spatial4j;0.5!spatial4j.jar(bundle) (183ms)[0m
[0m[[0minfo[0m] [0mDone updating.[0m
[0m[[0minfo[0m] [0mUpdating {file:/home/travis/build/dcshock/forklift/}server...[0m
[0m[[0minfo[0m] [0mResolving com.github.dcshock#forklift;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro-compiler;1.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.avro#avro;1.7.3 ...[0m
[0m[[0minfo[0m] [0mCompiling 9 Java sources to /home/travis/build/dcshock/forklift/plugins/replay/target/classes...[0m
[0m[[0minfo[0m] [0mResolving org.codehaus.jackson#jackson-core-asl;1.8.8 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.jackson#jackson-mapper-asl;1.8.8 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.thoughtworks.paranamer#paranamer;2.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.xerial.snappy#snappy-java;1.0.4.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-api;1.6.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-lang#commons-lang;2.6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.velocity#velocity;1.7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-collections#commons-collections;3.2.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.google.guava#guava;18.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.core#jackson-databind;2.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.core#jackson-annotations;2.7.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.core#jackson-core;2.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.datatype#jackson-datatype-jsr310;2.7.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback#logback-classic;1.0.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback#logback-core;1.0.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-api;1.7.5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.reflections#reflections;0.9.10 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.javassist#javassist;3.18.2-GA ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.google.code.findbugs#annotations;2.0.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving javax.inject#javax.inject;1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.github.dcshock#forklift-activemq;1.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.activemq#activemq-client;5.14.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.slf4j#slf4j-api;1.7.13 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.geronimo.specs#geronimo-jms_1.1_spec;1.1.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.fusesource.hawtbuf#hawtbuf;1.11 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.geronimo.specs#geronimo-j2ee-management_1.1_spec;1.0.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.activemq#activemq-broker;5.14.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.activemq#activemq-openwire-legacy;5.14.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.github.dcshock#forklift-replay;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.elasticsearch#elasticsearch;2.4.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-core;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-backward-codecs;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-analyzers-common;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-queries;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-memory;5.5.2 ...[0m
2017-06-02 17:35:47 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:35:47 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - SentIds: 10 consumedIds: 10
2017-06-02 17:35:47 [pool-22-thread-1] INFO  forklift.controller.KafkaController - Wakeup, controlLoop exiting
2017-06-02 17:35:47 [pool-22-thread-1] INFO  forklift.controller.KafkaController - closing offset size committed: 10
2017-06-02 17:35:47 [pool-22-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-highlighter;5.5.2 ...[0m
[0m[[0minfo[0m] [0mCompiling 1 Java source to /home/travis/build/dcshock/forklift/plugins/replay/target/test-classes...[0m
[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-join;5.5.2 ...[0m
2017-06-02 17:35:47 [pool-22-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:35:47 [pool-22-thread-1] INFO  forklift.controller.KafkaController - controlLoop closing kafkaConsumer
2017-06-02 17:35:47 [pool-5-thread-28] INFO  o.a.k.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-grouping;5.5.2 ...[0m
2017-06-02 17:35:47 [pool-5-thread-28] INFO  o.e.j.s.NetworkTrafficServerConnector - Stopped NetworkTrafficServerConnector@7827f573{HTTP/1.1}{localhost:58081}
2017-06-02 17:35:47 [pool-5-thread-28] INFO  o.e.j.server.handler.ContextHandler - Stopped o.e.j.s.ServletContextHandler@6727d07{/,null,UNAVAILABLE}
2017-06-02 17:35:47 [pool-5-thread-28] INFO  i.c.k.s.storage.KafkaSchemaRegistry - Shutting down schema registry
[2017-06-02 17:35:47,758] INFO [kafka-store-reader-thread-_schemas], Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
[2017-06-02 17:35:47,760] INFO [kafka-store-reader-thread-_schemas], Stopped  (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
[2017-06-02 17:35:47,760] INFO [kafka-store-reader-thread-_schemas], Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
2017-06-02 17:35:47 [pool-5-thread-28] INFO  i.c.k.s.s.KafkaStoreReaderThread - KafkaStoreReaderThread shutdown complete.
2017-06-02 17:35:47 [pool-5-thread-28] INFO  o.a.k.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-06-02 17:35:47 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e06d750001
2017-06-02 17:35:47 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /0:0:0:0:0:0:0:1:57440 which had sessionid 0x15c69e06d750001
2017-06-02 17:35:47 [pool-5-thread-28] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e06d750001 closed
2017-06-02 17:35:47 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e06d750003
2017-06-02 17:35:47 [pool-15-thread-3-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e06d750001
2017-06-02 17:35:47 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /127.0.0.1:40134 which had sessionid 0x15c69e06d750003
2017-06-02 17:35:47 [pool-5-thread-28] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e06d750003 closed
2017-06-02 17:35:47 [pool-15-thread-3-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e06d750003
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-queryparser;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-sandbox;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-suggest;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-misc;5.5.2 ...[0m
[0m[[0minfo[0m] [0mPassed: Total 1, Failed 0, Errors 0, Passed 1[0m
[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-spatial;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.lucene#lucene-spatial3d;5.5.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.spatial4j#spatial4j;0.5 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.elasticsearch#securesm;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.carrotsearch#hppc;0.7.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving joda-time#joda-time;2.9.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.joda#joda-convert;1.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.core#jackson-core;2.8.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.dataformat#jackson-dataformat-smile;2.8.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.dataformat#jackson-dataformat-yaml;2.8.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.yaml#snakeyaml;1.15 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.fasterxml.jackson.dataformat#jackson-dataformat-cbor;2.8.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving io.netty#netty;3.10.6.Final ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.ning#compress-lzf;1.0.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.tdunning#t-digest;3.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.hdrhistogram#HdrHistogram;2.1.6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-cli#commons-cli;1.3.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.twitter#jsr166e;1.1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.github.dcshock#forklift-retry;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving io.searchbox#jest;2.0.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving io.searchbox#jest-common;2.0.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.google.code.gson#gson;2.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.commons#commons-lang3;3.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpcore-nio;4.4.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpcore;4.4.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpclient;4.5.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-logging#commons-logging;1.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-codec#commons-codec;1.9 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpasyncclient;4.1.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.github.dcshock#forklift-stats;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.github.dcshock#consul-rest-client;0.10 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.github.dcshock#consul-rest-client;0.10 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.mashape.unirest#unirest-java;1.3.27 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.mashape.unirest#unirest-java;1.3.27 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.oss#oss-parent;7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpmime;4.3.6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpmime;4.3.6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpcomponents-client;4.3.6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#httpcomponents-client;4.3.6 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.apache.httpcomponents#project;7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.json#json;20140107 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.json#json;20140107 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.oss#oss-parent;7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving args4j#args4j;2.0.31 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving args4j#args4j;2.0.31 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving args4j#args4j-site;2.0.31 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving args4j#args4j-site;2.0.31 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.kohsuke#pom;14 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.kohsuke#pom;14 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.janino#janino;2.6.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.janino#janino;2.6.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.janino#janino-parent;2.6.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.janino#janino-parent;2.6.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus#codehaus-parent;4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.janino#commons-compiler;2.6.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.janino#commons-compiler;2.6.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.codehaus.janino#janino-parent;2.6.1 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback.contrib#logback-json-core;0.1.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback.contrib#logback-json-core;0.1.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback.contrib#logback-json-parent;0.1.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback.contrib#logback-json-parent;0.1.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback.contrib#logback-contrib-parent;0.1.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback.contrib#logback-contrib-parent;0.1.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.sonatype.oss#oss-parent;7 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback.contrib#logback-json-classic;0.1.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback.contrib#logback-json-classic;0.1.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback.contrib#logback-json-parent;0.1.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback.contrib#logback-jackson;0.1.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback.contrib#logback-jackson;0.1.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving ch.qos.logback.contrib#logback-contrib-parent;0.1.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving com.novocode#junit-interface;0.11 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving junit#junit;4.11 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.hamcrest#hamcrest-core;1.3 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-sbt#test-interface;1.0 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving commons-io#commons-io;2.4 ...[0m
2017-06-02 17:35:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e06d750000
2017-06-02 17:35:51 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /0:0:0:0:0:0:0:1:57410 which had sessionid 0x15c69e06d750000
2017-06-02 17:35:51 [pool-5-thread-28] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e06d750000 closed
2017-06-02 17:35:51 [pool-15-thread-2-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e06d750000
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-compiler;2.11.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-library;2.11.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang#scala-reflect;2.11.4 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang.modules#scala-xml_2.11;1.0.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving org.scala-lang.modules#scala-parser-combinators_2.11;1.0.2 ...[0m
[A[2K[0m[[0minfo[0m] [0mResolving jline#jline;2.12 ...[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/github/dcshock/consul-rest-client/0.10/consul-rest-client-0.10.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.github.dcshock#consul-rest-client;0.10!consul-rest-client.jar (34ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/args4j/args4j/2.0.31/args4j-2.0.31.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] args4j#args4j;2.0.31!args4j.jar(bundle) (59ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/codehaus/janino/janino/2.6.1/janino-2.6.1.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.codehaus.janino#janino;2.6.1!janino.jar (285ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/ch/qos/logback/contrib/logback-json-core/0.1.2/logback-json-core-0.1.2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] ch.qos.logback.contrib#logback-json-core;0.1.2!logback-json-core.jar (13ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/ch/qos/logback/contrib/logback-json-classic/0.1.2/logback-json-classic-0.1.2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] ch.qos.logback.contrib#logback-json-classic;0.1.2!logback-json-classic.jar (15ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/ch/qos/logback/contrib/logback-jackson/0.1.2/logback-jackson-0.1.2.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] ch.qos.logback.contrib#logback-jackson;0.1.2!logback-jackson.jar (12ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/spatial4j/spatial4j/0.5/spatial4j-0.5.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.spatial4j#spatial4j;0.5!spatial4j.jar (106ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/com/mashape/unirest/unirest-java/1.3.27/unirest-java-1.3.27.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] com.mashape.unirest#unirest-java;1.3.27!unirest-java.jar (50ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/apache/httpcomponents/httpmime/4.3.6/httpmime-4.3.6.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.apache.httpcomponents#httpmime;4.3.6!httpmime.jar (79ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/json/json/20140107/json-20140107.jar ...[0m
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.json#json;20140107!json.jar (64ms)[0m
[0m[[0minfo[0m] [0mdownloading https://repo1.maven.org/maven2/org/codehaus/janino/commons-compiler/2.6.1/commons-compiler-2.6.1.jar ...[0m
2017-06-02 17:35:53 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - NIOServerCnxn factory exited run method
2017-06-02 17:35:53 [pool-5-thread-28] INFO  o.a.zookeeper.server.ZooKeeperServer - shutting down
2017-06-02 17:35:53 [pool-5-thread-28] INFO  o.a.z.server.SessionTrackerImpl - Shutting down
2017-06-02 17:35:53 [pool-5-thread-28] INFO  o.a.z.server.PrepRequestProcessor - Shutting down
2017-06-02 17:35:53 [pool-5-thread-28] INFO  o.a.z.server.SyncRequestProcessor - Shutting down
2017-06-02 17:35:53 [SyncThread:0] INFO  o.a.z.server.SyncRequestProcessor - SyncRequestProcessor exited!
2017-06-02 17:35:53 [pool-5-thread-28] INFO  o.a.z.server.FinalRequestProcessor - shutdown of request processor complete
2017-06-02 17:35:53 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - PrepRequestProcessor exited loop!
2017-06-02 17:35:53 [pool-15-thread-1] WARN  o.a.z.server.ZooKeeperServerMain - Server interrupted
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.doAcquireSharedInterruptibly(AbstractQueuedSynchronizer.java:998) ~[na:1.8.0_31]
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireSharedInterruptibly(AbstractQueuedSynchronizer.java:1304) ~[na:1.8.0_31]
	at java.util.concurrent.CountDownLatch.await(CountDownLatch.java:231) ~[na:1.8.0_31]
	at org.apache.zookeeper.server.ZooKeeperServerMain.runFromConfig(ZooKeeperServerMain.java:122) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at forklift.integration.server.ZookeeperService.run(ZookeeperService.java:40) [test-classes/:na]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_31]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_31]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_31]
[0m[[0minfo[0m] [0m	[SUCCESSFUL ] org.codehaus.janino#commons-compiler;2.6.1!commons-compiler.jar (59ms)[0m
[0m[[0minfo[0m] [0mDone updating.[0m
[0m[[0minfo[0m] [0mCompiling 4 Java sources to /home/travis/build/dcshock/forklift/server/target/classes...[0m
2017-06-02 17:35:54 [SessionTracker] INFO  o.a.z.server.SessionTrackerImpl - SessionTrackerImpl exited loop!
[0m[[0minfo[0m] [0m/home/travis/build/dcshock/forklift/server/src/main/java/forklift/ForkliftMain.java: /home/travis/build/dcshock/forklift/server/src/main/java/forklift/ForkliftMain.java uses or overrides a deprecated API.[0m
[0m[[0minfo[0m] [0m/home/travis/build/dcshock/forklift/server/src/main/java/forklift/ForkliftMain.java: Recompile with -Xlint:deprecation for details.[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest forklift.integration.[33mMapMessageTests[0m.[36mtestSendMapValueMessage[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 1 total, 20.067s[0m[0m
2017-06-02 17:35:54 [pool-24-thread-1] INFO  o.a.z.server.ZooKeeperServerMain - Starting server
2017-06-02 17:35:54 [pool-24-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - tickTime set to 2000
2017-06-02 17:35:54 [pool-24-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - minSessionTimeout set to -1
2017-06-02 17:35:54 [pool-24-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - maxSessionTimeout set to -1
2017-06-02 17:35:54 [pool-24-thread-1] INFO  o.a.z.server.NIOServerCnxnFactory - binding to port 0.0.0.0/0.0.0.0:42181
2017-06-02 17:35:54 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:40278
2017-06-02 17:35:54 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] WARN  o.a.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x0, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_31]
2017-06-02 17:35:54 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /127.0.0.1:40278 (no session established for client)
2017-06-02 17:35:54 [pool-24-thread-2] INFO  kafka.server.KafkaConfig - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	default.replication.factor = 1
	delete.topic.enable = false
	fetch.purgatory.purge.interval.requests = 1000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.protocol.version = 0.10.1-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listeners = PLAINTEXT://:49092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /home/travis/build/dcshock/forklift/src/test/resources/zafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.10.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 16
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	unclean.leader.election.enable = true
	zookeeper.connect = localhost:42181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2017-06-02 17:35:54 [pool-24-thread-2] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@12c50cd2
2017-06-02 17:35:54 [pool-24-thread-2-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:35:54 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /0:0:0:0:0:0:0:1:57614
2017-06-02 17:35:54 [pool-24-thread-2-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/0:0:0:0:0:0:0:1:42181, initiating session
2017-06-02 17:35:54 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /0:0:0:0:0:0:0:1:57614
2017-06-02 17:35:54 [SyncThread:0] INFO  o.a.z.server.persistence.FileTxnLog - Creating new log file: log.1
2017-06-02 17:35:54 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e0bbce0000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:57614
2017-06-02 17:35:54 [pool-24-thread-2-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:42181, sessionid = 0x15c69e0bbce0000, negotiated timeout = 6000
2017-06-02 17:35:54 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x4 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2017-06-02 17:35:54 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0xa zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2017-06-02 17:35:54 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x12 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2017-06-02 17:35:54 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x1a zxid:0x11 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2017-06-02 17:35:55 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:setData cxid:0x24 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2017-06-02 17:35:55 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:delete cxid:0x33 zxid:0x17 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2017-06-02 17:35:55 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x3e zxid:0x18 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2017-06-02 17:35:55 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x3f zxid:0x19 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2017-06-02 17:35:55 [pool-24-thread-2] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:35:55 [pool-24-thread-2] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:35:57 [pool-24-thread-3] INFO  i.c.k.s.rest.SchemaRegistryConfig - SchemaRegistryConfig values: 
	metric.reporters = []
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	kafkastore.ssl.trustmanager.algorithm = PKIX
	authentication.realm = 
	ssl.keystore.type = JKS
	kafkastore.topic = _schemas
	metrics.jmx.prefix = kafka.schema.registry
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.topic.replication.factor = 3
	ssl.truststore.password = 
	kafkastore.timeout.ms = 500
	host.name = localhost
	kafkastore.bootstrap.servers = []
	schema.registry.zk.namespace = schema_registry
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.kerberos.service.name = 
	ssl.endpoint.identification.algorithm = 
	compression.enable = false
	kafkastore.ssl.truststore.type = JKS
	avro.compatibility.level = full
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.truststore.location = 
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	kafkastore.ssl.keystore.type = JKS
	ssl.truststore.type = JKS
	kafkastore.ssl.truststore.password = 
	access.control.allow.origin = 
	ssl.truststore.location = 
	ssl.keystore.password = 
	port = 8081
	kafkastore.ssl.keystore.location = 
	master.eligibility = true
	ssl.client.auth = false
	kafkastore.ssl.keystore.password = 
	kafkastore.security.protocol = PLAINTEXT
	ssl.trustmanager.algorithm = 
	authentication.method = NONE
	request.logger.name = io.confluent.rest-utils.requests
	ssl.key.password = 
	kafkastore.zk.session.timeout.ms = 30000
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.ssl.key.password = 
	zookeeper.set.acl = false
	authentication.roles = [*]
	metrics.num.samples = 2
	ssl.protocol = TLS
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.connection.url = localhost:42181
	debug = false
	listeners = [http://localhost:58081]
	ssl.provider = 
	ssl.enabled.protocols = []
	shutdown.graceful.ms = 1000
	ssl.keystore.location = 
	ssl.cipher.suites = []
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.cipher.suites = 
	access.control.allow.methods = 
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	ssl.keymanager.algorithm = 
	metrics.sample.window.ms = 30000
	kafkastore.init.timeout.ms = 60000

2017-06-02 17:35:57 [pool-24-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@427c19
2017-06-02 17:35:57 [pool-24-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:35:57 [pool-24-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/0:0:0:0:0:0:0:1:42181, initiating session
2017-06-02 17:35:57 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /0:0:0:0:0:0:0:1:57632
2017-06-02 17:35:57 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /0:0:0:0:0:0:0:1:57632
2017-06-02 17:35:57 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e0bbce0001 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:57632
2017-06-02 17:35:57 [pool-24-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:42181, sessionid = 0x15c69e0bbce0001, negotiated timeout = 30000
2017-06-02 17:35:57 [pool-24-thread-3] INFO  i.c.k.s.storage.KafkaStore - Initializing KafkaStore with broker endpoints: PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092
2017-06-02 17:35:57 [pool-24-thread-3] WARN  i.c.k.s.storage.KafkaStore - Creating the schema topic _schemas using a replication factor of 1, which is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic.
2017-06-02 17:35:57 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0001 type:setData cxid:0x8 zxid:0x1c txntype:-1 reqpath:n/a Error Path:/config/topics/_schemas Error:KeeperErrorCode = NoNode for /config/topics/_schemas
2017-06-02 17:35:57 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0001 type:create cxid:0x9 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:35:57 [pool-24-thread-3] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2017-06-02 17:35:57 [pool-24-thread-3] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	buffer.memory = 33554432
	client.id = producer-5
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2017-06-02 17:35:57 [pool-24-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:35:57 [pool-24-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:35:57 [pool-24-thread-3] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	check.crcs = true
	client.id = KafkaStore-reader-_schemas
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = schema-registry-localhost-58081
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-06-02 17:35:57 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x49 zxid:0x20 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_schemas/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_schemas/partitions/0
2017-06-02 17:35:57 [pool-24-thread-3] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	check.crcs = true
	client.id = KafkaStore-reader-_schemas
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = schema-registry-localhost-58081
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-06-02 17:35:57 [pool-24-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:35:57 [pool-24-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:35:57 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x4a zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_schemas/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_schemas/partitions
2017-06-02 17:35:57 [pool-24-thread-3] INFO  i.c.k.s.s.KafkaStoreReaderThread - Initialized last consumed offset to -1
[2017-06-02 17:35:57,701] INFO [kafka-store-reader-thread-_schemas], Starting  (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
2017-06-02 17:35:57 [pool-24-thread-3] INFO  i.c.k.s.storage.KafkaStore - Wait to catch up until the offset of the last message at 0
2017-06-02 17:35:57 [pool-24-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@43fc4f68
2017-06-02 17:35:57 [pool-24-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:35:57 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /0:0:0:0:0:0:0:1:57656
2017-06-02 17:35:57 [pool-24-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/0:0:0:0:0:0:0:1:42181, initiating session
2017-06-02 17:35:57 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /0:0:0:0:0:0:0:1:57656
2017-06-02 17:35:57 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e0bbce0002 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:57656
2017-06-02 17:35:57 [pool-24-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:42181, sessionid = 0x15c69e0bbce0002, negotiated timeout = 30000
2017-06-02 17:35:57 [pool-24-thread-3] INFO  i.c.k.s.storage.KafkaSchemaRegistry - Created schema registry namespace localhost:42181/schema_registry
2017-06-02 17:35:57 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e0bbce0002
2017-06-02 17:35:57 [pool-24-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e0bbce0002 closed
2017-06-02 17:35:57 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] WARN  o.a.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x15c69e0bbce0002, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_31]
2017-06-02 17:35:57 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /0:0:0:0:0:0:0:1:57656 which had sessionid 0x15c69e0bbce0002
2017-06-02 17:35:57 [pool-24-thread-3-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e0bbce0002
2017-06-02 17:35:57 [pool-24-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181/schema_registry sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@753bba4e
2017-06-02 17:35:57 [pool-24-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:35:57 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /0:0:0:0:0:0:0:1:57660
2017-06-02 17:35:57 [pool-24-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/0:0:0:0:0:0:0:1:42181, initiating session
2017-06-02 17:35:57 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /0:0:0:0:0:0:0:1:57660
2017-06-02 17:35:57 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e0bbce0003 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:57660
2017-06-02 17:35:57 [pool-24-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:42181, sessionid = 0x15c69e0bbce0003, negotiated timeout = 30000
2017-06-02 17:35:57 [pool-24-thread-3] INFO  i.c.k.s.z.ZookeeperMasterElector - Successfully elected the new master: {"host":"localhost","port":58081,"master_eligibility":true,"version":1}
2017-06-02 17:35:57 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0003 type:create cxid:0x7 zxid:0x2b txntype:-1 reqpath:n/a Error Path:/schema_registry/schema_registry_master Error:KeeperErrorCode = NodeExists for /schema_registry/schema_registry_master
2017-06-02 17:35:57 [pool-24-thread-3] INFO  io.confluent.rest.Application - Adding listener: http://localhost:58081
2017-06-02 17:35:57 [ZkClient-EventThread-1406-localhost:42181/schema_registry] INFO  i.c.k.s.z.ZookeeperMasterElector - Successfully elected the new master: {"host":"localhost","port":58081,"master_eligibility":true,"version":1}
2017-06-02 17:35:57 [pool-24-thread-3] INFO  org.eclipse.jetty.server.Server - jetty-9.2.12.v20150709
2017-06-02 17:35:58 [pool-24-thread-3] INFO  o.e.j.server.handler.ContextHandler - Started o.e.j.s.ServletContextHandler@4418cbea{/,null,AVAILABLE}
2017-06-02 17:35:58 [pool-24-thread-3] INFO  o.e.j.s.NetworkTrafficServerConnector - Started NetworkTrafficServerConnector@58852422{HTTP/1.1}{localhost:58081}
2017-06-02 17:35:58 [pool-24-thread-3] INFO  org.eclipse.jetty.server.Server - Started @263253ms
2017-06-02 17:35:59 [pool-5-thread-28] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:35:59 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:35:59 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:35:59 [pool-5-thread-28] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = producer-6
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:35:59 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:35:59 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:35:59 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:setData cxid:0x52 zxid:0x2c txntype:-1 reqpath:n/a Error Path:/config/topics/forklift-avro-topic Error:KeeperErrorCode = NoNode for /config/topics/forklift-avro-topic
2017-06-02 17:35:59 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x53 zxid:0x2d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:35:59 [kafka-producer-network-thread | producer-6] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 0 : {forklift-avro-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:35:59 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x6a zxid:0x30 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/14
2017-06-02 17:35:59 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x6b zxid:0x31 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions
2017-06-02 17:35:59 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x6f zxid:0x35 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/11
2017-06-02 17:35:59 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x72 zxid:0x38 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/1
2017-06-02 17:35:59 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x75 zxid:0x3b txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/4
2017-06-02 17:35:59 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x78 zxid:0x3e txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/7
2017-06-02 17:35:59 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x7b zxid:0x41 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/8
2017-06-02 17:35:59 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x7e zxid:0x44 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/6
2017-06-02 17:35:59 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x81 zxid:0x47 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/13
2017-06-02 17:35:59 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x84 zxid:0x4a txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/2
2017-06-02 17:35:59 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x87 zxid:0x4d txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/10
2017-06-02 17:35:59 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x8a zxid:0x50 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/0
2017-06-02 17:35:59 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x8d zxid:0x53 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/5
2017-06-02 17:35:59 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x90 zxid:0x56 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/15
2017-06-02 17:35:59 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x96 zxid:0x59 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/9
2017-06-02 17:35:59 [kafka-producer-network-thread | producer-6] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 1 : {forklift-avro-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:35:59 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x99 zxid:0x5c txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/3
2017-06-02 17:35:59 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x9c zxid:0x5f txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/12
2017-06-02 17:35:59 [kafka-producer-network-thread | producer-6] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 2 : {forklift-avro-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:35:59 [qtp179665732-1415] INFO  i.c.k.s.storage.KafkaStore - Wait to catch up until the offset of the last message at 1
2017-06-02 17:36:00 [qtp179665732-1415] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:35:59 +0000] "POST /subjects/forklift-avro-topic-value/versions HTTP/1.1" 200 8  177
2017-06-02 17:36:00 [pool-5-thread-28] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:36:00 [pool-5-thread-28] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = consumer-3
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:36:00 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:36:00 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:36:00 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:36:00 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:setData cxid:0xb6 zxid:0x62 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0xb7 zxid:0x63 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0xf0 zxid:0x66 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0xf1 zxid:0x67 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0xf8 zxid:0x6b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0xfb zxid:0x6e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0xfe zxid:0x71 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x101 zxid:0x74 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x104 zxid:0x77 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x107 zxid:0x7a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x10a zxid:0x7d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x10d zxid:0x80 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x110 zxid:0x83 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x113 zxid:0x86 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x116 zxid:0x89 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x119 zxid:0x8c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x11c zxid:0x8f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x11f zxid:0x92 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x125 zxid:0x95 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x128 zxid:0x98 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x12b zxid:0x9b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x12e zxid:0x9e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x131 zxid:0xa1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x134 zxid:0xa4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x137 zxid:0xa7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x13a zxid:0xaa txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x13d zxid:0xad txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x140 zxid:0xb0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x143 zxid:0xb3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x146 zxid:0xb6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x149 zxid:0xb9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x14c zxid:0xbc txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x14f zxid:0xbf txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x152 zxid:0xc2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x155 zxid:0xc5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x158 zxid:0xc8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x15b zxid:0xcb txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x15e zxid:0xce txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x161 zxid:0xd1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x164 zxid:0xd4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x167 zxid:0xd7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x16a zxid:0xda txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x16f zxid:0xdd txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x173 zxid:0xe0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x176 zxid:0xe3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x179 zxid:0xe6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x17c zxid:0xe9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x17f zxid:0xec txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x182 zxid:0xef txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x185 zxid:0xf2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x188 zxid:0xf5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x18b zxid:0xf8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2017-06-02 17:36:00 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0bbce0000 type:create cxid:0x18e zxid:0xfb txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2017-06-02 17:36:01 [pool-31-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:36:01 [pool-31-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [] for group testGroup
2017-06-02 17:36:01 [pool-31-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:36:01 [pool-31-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Successfully joined group testGroup with generation 1
2017-06-02 17:36:01 [pool-31-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Setting newly assigned partitions [forklift-avro-topic-12, forklift-avro-topic-13, forklift-avro-topic-10, forklift-avro-topic-11, forklift-avro-topic-8, forklift-avro-topic-9, forklift-avro-topic-6, forklift-avro-topic-7, forklift-avro-topic-14, forklift-avro-topic-15, forklift-avro-topic-4, forklift-avro-topic-5, forklift-avro-topic-2, forklift-avro-topic-3, forklift-avro-topic-0, forklift-avro-topic-1] for group testGroup
2017-06-02 17:36:01 [qtp179665732-1416] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:36:01 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 1319  7
pool-5-thread-28MT
pool-5-thread-28MT
pool-5-thread-28MT
pool-5-thread-28MT
pool-5-thread-28MT
pool-5-thread-28MT
pool-5-thread-28MT
pool-5-thread-28MT
pool-5-thread-28MT
pool-5-thread-28MT
2017-06-02 17:36:03 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:36:03 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - SentIds: 20 consumedIds: 20
2017-06-02 17:36:03 [pool-31-thread-1] INFO  forklift.controller.KafkaController - Wakeup, controlLoop exiting
2017-06-02 17:36:03 [pool-31-thread-1] INFO  forklift.controller.KafkaController - closing offset size committed: 10
2017-06-02 17:36:03 [pool-31-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:36:04 [pool-31-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:36:04 [pool-31-thread-1] INFO  forklift.controller.KafkaController - controlLoop closing kafkaConsumer
2017-06-02 17:36:04 [pool-5-thread-28] INFO  o.a.k.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-06-02 17:36:04 [pool-5-thread-28] INFO  o.e.j.s.NetworkTrafficServerConnector - Stopped NetworkTrafficServerConnector@58852422{HTTP/1.1}{localhost:58081}
2017-06-02 17:36:04 [pool-5-thread-28] INFO  o.e.j.server.handler.ContextHandler - Stopped o.e.j.s.ServletContextHandler@4418cbea{/,null,UNAVAILABLE}
2017-06-02 17:36:04 [pool-5-thread-28] INFO  i.c.k.s.storage.KafkaSchemaRegistry - Shutting down schema registry
[2017-06-02 17:36:04,351] INFO [kafka-store-reader-thread-_schemas], Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
[2017-06-02 17:36:04,357] INFO [kafka-store-reader-thread-_schemas], Stopped  (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
[2017-06-02 17:36:04,359] INFO [kafka-store-reader-thread-_schemas], Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
2017-06-02 17:36:04 [pool-5-thread-28] INFO  i.c.k.s.s.KafkaStoreReaderThread - KafkaStoreReaderThread shutdown complete.
2017-06-02 17:36:04 [pool-5-thread-28] INFO  o.a.k.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-06-02 17:36:04 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e0bbce0001
2017-06-02 17:36:04 [pool-5-thread-28] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e0bbce0001 closed
2017-06-02 17:36:04 [pool-24-thread-3-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e0bbce0001
2017-06-02 17:36:04 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /0:0:0:0:0:0:0:1:57632 which had sessionid 0x15c69e0bbce0001
2017-06-02 17:36:04 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e0bbce0003
2017-06-02 17:36:04 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /0:0:0:0:0:0:0:1:57660 which had sessionid 0x15c69e0bbce0003
2017-06-02 17:36:04 [pool-5-thread-28] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e0bbce0003 closed
2017-06-02 17:36:04 [pool-24-thread-3-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e0bbce0003
2017-06-02 17:36:07 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e0bbce0000
2017-06-02 17:36:07 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /0:0:0:0:0:0:0:1:57614 which had sessionid 0x15c69e0bbce0000
2017-06-02 17:36:07 [pool-5-thread-28] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e0bbce0000 closed
2017-06-02 17:36:07 [pool-24-thread-2-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e0bbce0000
2017-06-02 17:36:09 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - NIOServerCnxn factory exited run method
2017-06-02 17:36:09 [pool-5-thread-28] INFO  o.a.zookeeper.server.ZooKeeperServer - shutting down
2017-06-02 17:36:09 [pool-5-thread-28] INFO  o.a.z.server.SessionTrackerImpl - Shutting down
2017-06-02 17:36:09 [pool-5-thread-28] INFO  o.a.z.server.PrepRequestProcessor - Shutting down
2017-06-02 17:36:09 [pool-5-thread-28] INFO  o.a.z.server.SyncRequestProcessor - Shutting down
2017-06-02 17:36:09 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - PrepRequestProcessor exited loop!
2017-06-02 17:36:09 [SyncThread:0] INFO  o.a.z.server.SyncRequestProcessor - SyncRequestProcessor exited!
2017-06-02 17:36:09 [pool-5-thread-28] INFO  o.a.z.server.FinalRequestProcessor - shutdown of request processor complete
2017-06-02 17:36:10 [SessionTracker] INFO  o.a.z.server.SessionTrackerImpl - SessionTrackerImpl exited loop!
2017-06-02 17:36:10 [pool-33-thread-1] INFO  o.a.z.server.ZooKeeperServerMain - Starting server
2017-06-02 17:36:10 [pool-33-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - tickTime set to 2000
2017-06-02 17:36:10 [pool-33-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - minSessionTimeout set to -1
2017-06-02 17:36:10 [pool-33-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - maxSessionTimeout set to -1
2017-06-02 17:36:10 [pool-33-thread-1] INFO  o.a.z.server.NIOServerCnxnFactory - binding to port 0.0.0.0/0.0.0.0:42181
2017-06-02 17:36:10 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:40402
2017-06-02 17:36:10 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] WARN  o.a.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x0, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_31]
2017-06-02 17:36:10 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /127.0.0.1:40402 (no session established for client)
2017-06-02 17:36:10 [pool-33-thread-2] INFO  kafka.server.KafkaConfig - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	default.replication.factor = 1
	delete.topic.enable = false
	fetch.purgatory.purge.interval.requests = 1000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.protocol.version = 0.10.1-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listeners = PLAINTEXT://:49092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /home/travis/build/dcshock/forklift/src/test/resources/zafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.10.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 16
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	unclean.leader.election.enable = true
	zookeeper.connect = localhost:42181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2017-06-02 17:36:10 [pool-33-thread-2] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@8448d02
2017-06-02 17:36:11 [pool-33-thread-2-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:36:11 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:40406
2017-06-02 17:36:11 [pool-33-thread-2-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/127.0.0.1:42181, initiating session
2017-06-02 17:36:11 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:40406
2017-06-02 17:36:11 [SyncThread:0] INFO  o.a.z.server.persistence.FileTxnLog - Creating new log file: log.1
2017-06-02 17:36:11 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e0fa920000 with negotiated timeout 6000 for client /127.0.0.1:40406
2017-06-02 17:36:11 [pool-33-thread-2-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:42181, sessionid = 0x15c69e0fa920000, negotiated timeout = 6000
2017-06-02 17:36:11 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x4 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2017-06-02 17:36:11 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0xa zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2017-06-02 17:36:11 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x12 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2017-06-02 17:36:11 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x1a zxid:0x11 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2017-06-02 17:36:11 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:setData cxid:0x24 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2017-06-02 17:36:11 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:delete cxid:0x33 zxid:0x17 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2017-06-02 17:36:11 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x3e zxid:0x18 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2017-06-02 17:36:11 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x3f zxid:0x19 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2017-06-02 17:36:11 [pool-33-thread-2] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:36:11 [pool-33-thread-2] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:36:13 [pool-33-thread-3] INFO  i.c.k.s.rest.SchemaRegistryConfig - SchemaRegistryConfig values: 
	metric.reporters = []
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	kafkastore.ssl.trustmanager.algorithm = PKIX
	authentication.realm = 
	ssl.keystore.type = JKS
	kafkastore.topic = _schemas
	metrics.jmx.prefix = kafka.schema.registry
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.topic.replication.factor = 3
	ssl.truststore.password = 
	kafkastore.timeout.ms = 500
	host.name = localhost
	kafkastore.bootstrap.servers = []
	schema.registry.zk.namespace = schema_registry
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.kerberos.service.name = 
	ssl.endpoint.identification.algorithm = 
	compression.enable = false
	kafkastore.ssl.truststore.type = JKS
	avro.compatibility.level = full
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.truststore.location = 
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	kafkastore.ssl.keystore.type = JKS
	ssl.truststore.type = JKS
	kafkastore.ssl.truststore.password = 
	access.control.allow.origin = 
	ssl.truststore.location = 
	ssl.keystore.password = 
	port = 8081
	kafkastore.ssl.keystore.location = 
	master.eligibility = true
	ssl.client.auth = false
	kafkastore.ssl.keystore.password = 
	kafkastore.security.protocol = PLAINTEXT
	ssl.trustmanager.algorithm = 
	authentication.method = NONE
	request.logger.name = io.confluent.rest-utils.requests
	ssl.key.password = 
	kafkastore.zk.session.timeout.ms = 30000
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.ssl.key.password = 
	zookeeper.set.acl = false
	authentication.roles = [*]
	metrics.num.samples = 2
	ssl.protocol = TLS
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.connection.url = localhost:42181
	debug = false
	listeners = [http://localhost:58081]
	ssl.provider = 
	ssl.enabled.protocols = []
	shutdown.graceful.ms = 1000
	ssl.keystore.location = 
	ssl.cipher.suites = []
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.cipher.suites = 
	access.control.allow.methods = 
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	ssl.keymanager.algorithm = 
	metrics.sample.window.ms = 30000
	kafkastore.init.timeout.ms = 60000

2017-06-02 17:36:13 [pool-33-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@67cd57c6
2017-06-02 17:36:13 [pool-33-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:36:13 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:40426
2017-06-02 17:36:13 [pool-33-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/127.0.0.1:42181, initiating session
2017-06-02 17:36:13 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:40426
2017-06-02 17:36:13 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e0fa920001 with negotiated timeout 30000 for client /127.0.0.1:40426
2017-06-02 17:36:13 [pool-33-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:42181, sessionid = 0x15c69e0fa920001, negotiated timeout = 30000
2017-06-02 17:36:13 [pool-33-thread-3] INFO  i.c.k.s.storage.KafkaStore - Initializing KafkaStore with broker endpoints: PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092
2017-06-02 17:36:13 [pool-33-thread-3] WARN  i.c.k.s.storage.KafkaStore - Creating the schema topic _schemas using a replication factor of 1, which is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic.
2017-06-02 17:36:13 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920001 type:setData cxid:0x8 zxid:0x1c txntype:-1 reqpath:n/a Error Path:/config/topics/_schemas Error:KeeperErrorCode = NoNode for /config/topics/_schemas
2017-06-02 17:36:13 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920001 type:create cxid:0x9 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:36:13 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x49 zxid:0x20 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_schemas/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_schemas/partitions/0
2017-06-02 17:36:13 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x4a zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_schemas/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_schemas/partitions
2017-06-02 17:36:13 [pool-33-thread-3] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2017-06-02 17:36:13 [pool-33-thread-3] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	buffer.memory = 33554432
	client.id = producer-7
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2017-06-02 17:36:13 [pool-33-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:36:13 [pool-33-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:36:13 [pool-33-thread-3] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	check.crcs = true
	client.id = KafkaStore-reader-_schemas
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = schema-registry-localhost-58081
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-06-02 17:36:13 [pool-33-thread-3] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	check.crcs = true
	client.id = KafkaStore-reader-_schemas
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = schema-registry-localhost-58081
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-06-02 17:36:13 [pool-33-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:36:13 [pool-33-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:36:13 [pool-33-thread-3] INFO  i.c.k.s.s.KafkaStoreReaderThread - Initialized last consumed offset to -1
[2017-06-02 17:36:13,488] INFO [kafka-store-reader-thread-_schemas], Starting  (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
2017-06-02 17:36:13 [pool-33-thread-3] INFO  i.c.k.s.storage.KafkaStore - Wait to catch up until the offset of the last message at 0
2017-06-02 17:36:13 [pool-33-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@2e41caea
2017-06-02 17:36:13 [pool-33-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:36:13 [pool-33-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/0:0:0:0:0:0:0:1:42181, initiating session
2017-06-02 17:36:13 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /0:0:0:0:0:0:0:1:57780
2017-06-02 17:36:13 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /0:0:0:0:0:0:0:1:57780
2017-06-02 17:36:13 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e0fa920002 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:57780
2017-06-02 17:36:13 [pool-33-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:42181, sessionid = 0x15c69e0fa920002, negotiated timeout = 30000
2017-06-02 17:36:13 [pool-33-thread-3] INFO  i.c.k.s.storage.KafkaSchemaRegistry - Created schema registry namespace localhost:42181/schema_registry
2017-06-02 17:36:13 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e0fa920002
2017-06-02 17:36:13 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /0:0:0:0:0:0:0:1:57780 which had sessionid 0x15c69e0fa920002
2017-06-02 17:36:13 [pool-33-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e0fa920002 closed
2017-06-02 17:36:13 [pool-33-thread-3-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e0fa920002
2017-06-02 17:36:13 [pool-33-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181/schema_registry sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@6a4f8151
2017-06-02 17:36:13 [pool-33-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:36:13 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /0:0:0:0:0:0:0:1:57784
2017-06-02 17:36:13 [pool-33-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/0:0:0:0:0:0:0:1:42181, initiating session
2017-06-02 17:36:13 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /0:0:0:0:0:0:0:1:57784
2017-06-02 17:36:13 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e0fa920003 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:57784
2017-06-02 17:36:13 [pool-33-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:42181, sessionid = 0x15c69e0fa920003, negotiated timeout = 30000
2017-06-02 17:36:13 [pool-33-thread-3] INFO  i.c.k.s.z.ZookeeperMasterElector - Successfully elected the new master: {"host":"localhost","port":58081,"master_eligibility":true,"version":1}
2017-06-02 17:36:13 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920003 type:create cxid:0x7 zxid:0x2b txntype:-1 reqpath:n/a Error Path:/schema_registry/schema_registry_master Error:KeeperErrorCode = NodeExists for /schema_registry/schema_registry_master
2017-06-02 17:36:13 [ZkClient-EventThread-1479-localhost:42181/schema_registry] INFO  i.c.k.s.z.ZookeeperMasterElector - Successfully elected the new master: {"host":"localhost","port":58081,"master_eligibility":true,"version":1}
2017-06-02 17:36:13 [pool-33-thread-3] INFO  io.confluent.rest.Application - Adding listener: http://localhost:58081
2017-06-02 17:36:13 [pool-33-thread-3] INFO  org.eclipse.jetty.server.Server - jetty-9.2.12.v20150709
2017-06-02 17:36:14 [pool-33-thread-3] INFO  o.e.j.server.handler.ContextHandler - Started o.e.j.s.ServletContextHandler@de5e7b7{/,null,AVAILABLE}
2017-06-02 17:36:14 [pool-33-thread-3] INFO  o.e.j.s.NetworkTrafficServerConnector - Started NetworkTrafficServerConnector@62282037{HTTP/1.1}{localhost:58081}
2017-06-02 17:36:14 [pool-33-thread-3] INFO  org.eclipse.jetty.server.Server - Started @279253ms
2017-06-02 17:36:15 [pool-5-thread-28] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:36:15 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:36:15 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:36:15 [pool-5-thread-28] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = producer-8
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:36:15 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:36:15 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:36:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:setData cxid:0x52 zxid:0x2c txntype:-1 reqpath:n/a Error Path:/config/topics/forklift-avro-topic Error:KeeperErrorCode = NoNode for /config/topics/forklift-avro-topic
2017-06-02 17:36:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x53 zxid:0x2d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:36:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x6a zxid:0x30 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/14
2017-06-02 17:36:15 [kafka-producer-network-thread | producer-8] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 0 : {forklift-avro-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x6b zxid:0x31 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions
2017-06-02 17:36:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x6f zxid:0x35 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/11
2017-06-02 17:36:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x72 zxid:0x38 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/1
2017-06-02 17:36:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x75 zxid:0x3b txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/4
2017-06-02 17:36:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x78 zxid:0x3e txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/7
2017-06-02 17:36:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x7b zxid:0x41 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/8
2017-06-02 17:36:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x7e zxid:0x44 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/6
2017-06-02 17:36:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x81 zxid:0x47 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/13
2017-06-02 17:36:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x84 zxid:0x4a txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/2
2017-06-02 17:36:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x87 zxid:0x4d txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/10
2017-06-02 17:36:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x8a zxid:0x50 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/0
2017-06-02 17:36:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x8d zxid:0x53 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/5
2017-06-02 17:36:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x90 zxid:0x56 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/15
2017-06-02 17:36:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x93 zxid:0x59 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/9
2017-06-02 17:36:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x96 zxid:0x5c txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/3
2017-06-02 17:36:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x99 zxid:0x5f txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-avro-topic/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-avro-topic/partitions/12
2017-06-02 17:36:15 [kafka-producer-network-thread | producer-8] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 1 : {forklift-avro-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:15 [kafka-producer-network-thread | producer-8] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 2 : {forklift-avro-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:15 [qtp1633860340-1489] INFO  i.c.k.s.storage.KafkaStore - Wait to catch up until the offset of the last message at 1
2017-06-02 17:36:16 [qtp1633860340-1489] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:36:15 +0000] "POST /subjects/forklift-avro-topic-value/versions HTTP/1.1" 200 8  180
2017-06-02 17:36:16 [pool-5-thread-28] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:36:16 [pool-5-thread-28] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = consumer-4
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:36:16 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:36:16 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:36:16 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:36:16 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:setData cxid:0xb6 zxid:0x62 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0xb7 zxid:0x63 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0xf0 zxid:0x66 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0xf1 zxid:0x67 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0xf5 zxid:0x6b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0xf8 zxid:0x6e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0xfb zxid:0x71 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0xfe zxid:0x74 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x101 zxid:0x77 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x104 zxid:0x7a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x107 zxid:0x7d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x10a zxid:0x80 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x10e zxid:0x83 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x113 zxid:0x86 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x119 zxid:0x89 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x11c zxid:0x8c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x11f zxid:0x8f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x122 zxid:0x92 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x125 zxid:0x95 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x12b zxid:0x98 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x12e zxid:0x9b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x131 zxid:0x9e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x134 zxid:0xa1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x137 zxid:0xa4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x13a zxid:0xa7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x140 zxid:0xaa txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x143 zxid:0xad txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x148 zxid:0xb0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x14c zxid:0xb3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x14f zxid:0xb6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x152 zxid:0xb9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x155 zxid:0xbc txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x158 zxid:0xbf txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x15b zxid:0xc2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x15e zxid:0xc5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x161 zxid:0xc8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x167 zxid:0xcb txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x16a zxid:0xce txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x16d zxid:0xd1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x170 zxid:0xd4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x173 zxid:0xd7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x176 zxid:0xda txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x179 zxid:0xdd txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x17c zxid:0xe0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x17f zxid:0xe3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x182 zxid:0xe6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x185 zxid:0xe9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x188 zxid:0xec txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x18b zxid:0xef txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x18e zxid:0xf2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x191 zxid:0xf5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x194 zxid:0xf8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2017-06-02 17:36:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e0fa920000 type:create cxid:0x197 zxid:0xfb txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2017-06-02 17:36:17 [pool-40-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:36:17 [pool-40-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [] for group testGroup
2017-06-02 17:36:17 [pool-40-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:36:17 [pool-40-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Successfully joined group testGroup with generation 1
2017-06-02 17:36:17 [pool-40-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Setting newly assigned partitions [forklift-avro-topic-12, forklift-avro-topic-13, forklift-avro-topic-10, forklift-avro-topic-11, forklift-avro-topic-8, forklift-avro-topic-9, forklift-avro-topic-6, forklift-avro-topic-7, forklift-avro-topic-14, forklift-avro-topic-15, forklift-avro-topic-4, forklift-avro-topic-5, forklift-avro-topic-2, forklift-avro-topic-3, forklift-avro-topic-0, forklift-avro-topic-1] for group testGroup
2017-06-02 17:36:18 [qtp1633860340-1490] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:36:18 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 1134  24
pool-5-thread-28MT
pool-5-thread-28MT
pool-5-thread-28MT
pool-5-thread-28MT
pool-5-thread-28MT
pool-5-thread-28MT
pool-5-thread-28MT
pool-5-thread-28MT
pool-5-thread-28MT
pool-5-thread-28MT
2017-06-02 17:36:21 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:36:21 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - SentIds: 23 consumedIds: 23
2017-06-02 17:36:21 [pool-40-thread-1] INFO  forklift.controller.KafkaController - Wakeup, controlLoop exiting
2017-06-02 17:36:21 [pool-40-thread-1] INFO  forklift.controller.KafkaController - closing offset size committed: 10
2017-06-02 17:36:21 [pool-40-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:36:21 [pool-40-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:36:21 [pool-40-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:36:21 [pool-40-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:36:21 [pool-40-thread-1] INFO  forklift.controller.KafkaController - controlLoop closing kafkaConsumer
2017-06-02 17:36:21 [pool-5-thread-28] INFO  o.a.k.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-06-02 17:36:21 [pool-5-thread-28] INFO  o.e.j.s.NetworkTrafficServerConnector - Stopped NetworkTrafficServerConnector@62282037{HTTP/1.1}{localhost:58081}
2017-06-02 17:36:21 [pool-5-thread-28] INFO  o.e.j.server.handler.ContextHandler - Stopped o.e.j.s.ServletContextHandler@de5e7b7{/,null,UNAVAILABLE}
2017-06-02 17:36:21 [pool-5-thread-28] INFO  i.c.k.s.storage.KafkaSchemaRegistry - Shutting down schema registry
[2017-06-02 17:36:21,287] INFO [kafka-store-reader-thread-_schemas], Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
[2017-06-02 17:36:21,288] INFO [kafka-store-reader-thread-_schemas], Stopped  (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
[2017-06-02 17:36:21,288] INFO [kafka-store-reader-thread-_schemas], Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
2017-06-02 17:36:21 [pool-5-thread-28] INFO  i.c.k.s.s.KafkaStoreReaderThread - KafkaStoreReaderThread shutdown complete.
2017-06-02 17:36:21 [pool-5-thread-28] INFO  o.a.k.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-06-02 17:36:21 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e0fa920001
2017-06-02 17:36:21 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /127.0.0.1:40426 which had sessionid 0x15c69e0fa920001
2017-06-02 17:36:21 [pool-5-thread-28] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e0fa920001 closed
2017-06-02 17:36:21 [pool-33-thread-3-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e0fa920001
2017-06-02 17:36:21 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e0fa920003
2017-06-02 17:36:21 [pool-5-thread-28] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e0fa920003 closed
2017-06-02 17:36:21 [pool-33-thread-3-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e0fa920003
2017-06-02 17:36:21 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] WARN  o.a.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x15c69e0fa920003, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_31]
2017-06-02 17:36:21 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /0:0:0:0:0:0:0:1:57784 which had sessionid 0x15c69e0fa920003
2017-06-02 17:36:24 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e0fa920000
2017-06-02 17:36:24 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /127.0.0.1:40406 which had sessionid 0x15c69e0fa920000
2017-06-02 17:36:24 [pool-5-thread-28] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e0fa920000 closed
2017-06-02 17:36:24 [pool-33-thread-2-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e0fa920000
2017-06-02 17:36:25 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - NIOServerCnxn factory exited run method
2017-06-02 17:36:25 [pool-5-thread-28] INFO  o.a.zookeeper.server.ZooKeeperServer - shutting down
2017-06-02 17:36:25 [pool-5-thread-28] INFO  o.a.z.server.SessionTrackerImpl - Shutting down
2017-06-02 17:36:25 [pool-5-thread-28] INFO  o.a.z.server.PrepRequestProcessor - Shutting down
2017-06-02 17:36:25 [pool-5-thread-28] INFO  o.a.z.server.SyncRequestProcessor - Shutting down
2017-06-02 17:36:25 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - PrepRequestProcessor exited loop!
2017-06-02 17:36:25 [SyncThread:0] INFO  o.a.z.server.SyncRequestProcessor - SyncRequestProcessor exited!
2017-06-02 17:36:25 [pool-5-thread-28] INFO  o.a.z.server.FinalRequestProcessor - shutdown of request processor complete
2017-06-02 17:36:26 [SessionTracker] INFO  o.a.z.server.SessionTrackerImpl - SessionTrackerImpl exited loop!
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest forklift.integration.[33mAvroMessageTests[0m.[36mtestComplexAvroMessageWithProperty[0m started[0m
[0m[[0minfo[0m] [0mTest forklift.integration.[33mAvroMessageTests[0m.[36mtestComplexAvroMessageWithoutProperty[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 2 total, 32.259s[0m[0m
2017-06-02 17:36:27 [pool-42-thread-1] INFO  o.a.z.server.ZooKeeperServerMain - Starting server
2017-06-02 17:36:27 [pool-42-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - tickTime set to 2000
2017-06-02 17:36:27 [pool-42-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - minSessionTimeout set to -1
2017-06-02 17:36:27 [pool-42-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - maxSessionTimeout set to -1
2017-06-02 17:36:27 [pool-42-thread-1] INFO  o.a.z.server.NIOServerCnxnFactory - binding to port 0.0.0.0/0.0.0.0:42181
2017-06-02 17:36:27 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:40512
2017-06-02 17:36:27 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] WARN  o.a.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x0, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_31]
2017-06-02 17:36:27 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /127.0.0.1:40512 (no session established for client)
2017-06-02 17:36:27 [pool-42-thread-2] INFO  kafka.server.KafkaConfig - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	default.replication.factor = 1
	delete.topic.enable = false
	fetch.purgatory.purge.interval.requests = 1000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.protocol.version = 0.10.1-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listeners = PLAINTEXT://:49092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /home/travis/build/dcshock/forklift/src/test/resources/zafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.10.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 16
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	unclean.leader.election.enable = true
	zookeeper.connect = localhost:42181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2017-06-02 17:36:27 [pool-42-thread-2] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@730086d0
2017-06-02 17:36:27 [pool-42-thread-2-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:36:27 [pool-42-thread-2-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/127.0.0.1:42181, initiating session
2017-06-02 17:36:27 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:40516
2017-06-02 17:36:27 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:40516
2017-06-02 17:36:27 [SyncThread:0] INFO  o.a.z.server.persistence.FileTxnLog - Creating new log file: log.1
2017-06-02 17:36:27 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e139e30000 with negotiated timeout 6000 for client /127.0.0.1:40516
2017-06-02 17:36:27 [pool-42-thread-2-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:42181, sessionid = 0x15c69e139e30000, negotiated timeout = 6000
2017-06-02 17:36:27 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x4 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2017-06-02 17:36:27 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0xa zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2017-06-02 17:36:27 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x12 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2017-06-02 17:36:27 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x1a zxid:0x11 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2017-06-02 17:36:27 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:setData cxid:0x22 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2017-06-02 17:36:27 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:delete cxid:0x33 zxid:0x17 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2017-06-02 17:36:27 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x3e zxid:0x18 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2017-06-02 17:36:27 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x3f zxid:0x19 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2017-06-02 17:36:27 [pool-42-thread-2] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:36:27 [pool-42-thread-2] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:36:29 [pool-42-thread-3] INFO  i.c.k.s.rest.SchemaRegistryConfig - SchemaRegistryConfig values: 
	metric.reporters = []
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	kafkastore.ssl.trustmanager.algorithm = PKIX
	authentication.realm = 
	ssl.keystore.type = JKS
	kafkastore.topic = _schemas
	metrics.jmx.prefix = kafka.schema.registry
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.topic.replication.factor = 3
	ssl.truststore.password = 
	kafkastore.timeout.ms = 500
	host.name = localhost
	kafkastore.bootstrap.servers = []
	schema.registry.zk.namespace = schema_registry
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.kerberos.service.name = 
	ssl.endpoint.identification.algorithm = 
	compression.enable = false
	kafkastore.ssl.truststore.type = JKS
	avro.compatibility.level = full
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.truststore.location = 
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	kafkastore.ssl.keystore.type = JKS
	ssl.truststore.type = JKS
	kafkastore.ssl.truststore.password = 
	access.control.allow.origin = 
	ssl.truststore.location = 
	ssl.keystore.password = 
	port = 8081
	kafkastore.ssl.keystore.location = 
	master.eligibility = true
	ssl.client.auth = false
	kafkastore.ssl.keystore.password = 
	kafkastore.security.protocol = PLAINTEXT
	ssl.trustmanager.algorithm = 
	authentication.method = NONE
	request.logger.name = io.confluent.rest-utils.requests
	ssl.key.password = 
	kafkastore.zk.session.timeout.ms = 30000
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.ssl.key.password = 
	zookeeper.set.acl = false
	authentication.roles = [*]
	metrics.num.samples = 2
	ssl.protocol = TLS
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.connection.url = localhost:42181
	debug = false
	listeners = [http://localhost:58081]
	ssl.provider = 
	ssl.enabled.protocols = []
	shutdown.graceful.ms = 1000
	ssl.keystore.location = 
	ssl.cipher.suites = []
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.cipher.suites = 
	access.control.allow.methods = 
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	ssl.keymanager.algorithm = 
	metrics.sample.window.ms = 30000
	kafkastore.init.timeout.ms = 60000

2017-06-02 17:36:29 [pool-42-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@e994fb5
2017-06-02 17:36:29 [pool-42-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:36:29 [pool-42-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/0:0:0:0:0:0:0:1:42181, initiating session
2017-06-02 17:36:29 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /0:0:0:0:0:0:0:1:57860
2017-06-02 17:36:29 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /0:0:0:0:0:0:0:1:57860
2017-06-02 17:36:29 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e139e30001 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:57860
2017-06-02 17:36:29 [pool-42-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:42181, sessionid = 0x15c69e139e30001, negotiated timeout = 30000
2017-06-02 17:36:29 [pool-42-thread-3] INFO  i.c.k.s.storage.KafkaStore - Initializing KafkaStore with broker endpoints: PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092
2017-06-02 17:36:29 [pool-42-thread-3] WARN  i.c.k.s.storage.KafkaStore - Creating the schema topic _schemas using a replication factor of 1, which is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic.
2017-06-02 17:36:29 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30001 type:setData cxid:0x8 zxid:0x1c txntype:-1 reqpath:n/a Error Path:/config/topics/_schemas Error:KeeperErrorCode = NoNode for /config/topics/_schemas
2017-06-02 17:36:29 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30001 type:create cxid:0x9 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:36:29 [pool-42-thread-3] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2017-06-02 17:36:29 [pool-42-thread-3] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	buffer.memory = 33554432
	client.id = producer-9
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2017-06-02 17:36:29 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x49 zxid:0x20 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_schemas/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_schemas/partitions/0
2017-06-02 17:36:29 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x4a zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_schemas/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_schemas/partitions
2017-06-02 17:36:29 [pool-42-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:36:29 [pool-42-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:36:29 [pool-42-thread-3] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	check.crcs = true
	client.id = KafkaStore-reader-_schemas
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = schema-registry-localhost-58081
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-06-02 17:36:29 [pool-42-thread-3] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	check.crcs = true
	client.id = KafkaStore-reader-_schemas
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = schema-registry-localhost-58081
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-06-02 17:36:29 [pool-42-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:36:29 [pool-42-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:36:29 [pool-42-thread-3] INFO  i.c.k.s.s.KafkaStoreReaderThread - Initialized last consumed offset to -1
2017-06-02 17:36:29 [pool-42-thread-3] INFO  i.c.k.s.storage.KafkaStore - Wait to catch up until the offset of the last message at 0
[2017-06-02 17:36:29,529] INFO [kafka-store-reader-thread-_schemas], Starting  (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
2017-06-02 17:36:29 [pool-42-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@232a0007
2017-06-02 17:36:29 [pool-42-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:36:29 [pool-42-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/0:0:0:0:0:0:0:1:42181, initiating session
2017-06-02 17:36:29 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /0:0:0:0:0:0:0:1:57886
2017-06-02 17:36:29 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /0:0:0:0:0:0:0:1:57886
2017-06-02 17:36:29 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e139e30002 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:57886
2017-06-02 17:36:29 [pool-42-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:42181, sessionid = 0x15c69e139e30002, negotiated timeout = 30000
2017-06-02 17:36:29 [pool-42-thread-3] INFO  i.c.k.s.storage.KafkaSchemaRegistry - Created schema registry namespace localhost:42181/schema_registry
2017-06-02 17:36:29 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e139e30002
2017-06-02 17:36:29 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /0:0:0:0:0:0:0:1:57886 which had sessionid 0x15c69e139e30002
2017-06-02 17:36:29 [pool-42-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e139e30002 closed
2017-06-02 17:36:29 [pool-42-thread-3-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e139e30002
2017-06-02 17:36:29 [pool-42-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181/schema_registry sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@1977c0dc
2017-06-02 17:36:29 [pool-42-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:36:29 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /0:0:0:0:0:0:0:1:57890
2017-06-02 17:36:29 [pool-42-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/0:0:0:0:0:0:0:1:42181, initiating session
2017-06-02 17:36:29 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /0:0:0:0:0:0:0:1:57890
2017-06-02 17:36:29 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e139e30003 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:57890
2017-06-02 17:36:29 [pool-42-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:42181, sessionid = 0x15c69e139e30003, negotiated timeout = 30000
2017-06-02 17:36:29 [pool-42-thread-3] INFO  i.c.k.s.z.ZookeeperMasterElector - Successfully elected the new master: {"host":"localhost","port":58081,"master_eligibility":true,"version":1}
2017-06-02 17:36:29 [pool-42-thread-3] INFO  io.confluent.rest.Application - Adding listener: http://localhost:58081
2017-06-02 17:36:29 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30003 type:create cxid:0x7 zxid:0x2b txntype:-1 reqpath:n/a Error Path:/schema_registry/schema_registry_master Error:KeeperErrorCode = NodeExists for /schema_registry/schema_registry_master
2017-06-02 17:36:29 [ZkClient-EventThread-1554-localhost:42181/schema_registry] INFO  i.c.k.s.z.ZookeeperMasterElector - Successfully elected the new master: {"host":"localhost","port":58081,"master_eligibility":true,"version":1}
2017-06-02 17:36:29 [pool-42-thread-3] INFO  org.eclipse.jetty.server.Server - jetty-9.2.12.v20150709
2017-06-02 17:36:30 [pool-42-thread-3] INFO  o.e.j.server.handler.ContextHandler - Started o.e.j.s.ServletContextHandler@8edff5e{/,null,AVAILABLE}
2017-06-02 17:36:30 [pool-42-thread-3] INFO  o.e.j.s.NetworkTrafficServerConnector - Started NetworkTrafficServerConnector@45589472{HTTP/1.1}{localhost:58081}
2017-06-02 17:36:30 [pool-42-thread-3] INFO  org.eclipse.jetty.server.Server - Started @295434ms
2017-06-02 17:36:31 [pool-5-thread-28] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:36:31 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:36:31 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:36:31 [pool-5-thread-28] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = producer-10
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:36:31 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:36:31 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:36:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:setData cxid:0x52 zxid:0x2c txntype:-1 reqpath:n/a Error Path:/config/topics/forklift-string-topic Error:KeeperErrorCode = NoNode for /config/topics/forklift-string-topic
2017-06-02 17:36:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x53 zxid:0x2d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:36:31 [kafka-producer-network-thread | producer-10] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 0 : {forklift-string-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x6a zxid:0x30 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/3
2017-06-02 17:36:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x6b zxid:0x31 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions
2017-06-02 17:36:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x6f zxid:0x35 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/14
2017-06-02 17:36:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x72 zxid:0x38 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/12
2017-06-02 17:36:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x75 zxid:0x3b txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/8
2017-06-02 17:36:31 [kafka-producer-network-thread | producer-10] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 1 : {forklift-string-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x7b zxid:0x3e txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/6
2017-06-02 17:36:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x7e zxid:0x41 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/7
2017-06-02 17:36:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x81 zxid:0x44 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/13
2017-06-02 17:36:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x84 zxid:0x47 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/10
2017-06-02 17:36:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x87 zxid:0x4a txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/5
2017-06-02 17:36:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x8a zxid:0x4d txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/2
2017-06-02 17:36:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x8d zxid:0x50 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/4
2017-06-02 17:36:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x92 zxid:0x53 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/11
2017-06-02 17:36:31 [kafka-producer-network-thread | producer-10] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 2 : {forklift-string-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x96 zxid:0x56 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/15
2017-06-02 17:36:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x99 zxid:0x59 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/1
2017-06-02 17:36:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x9c zxid:0x5c txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/9
2017-06-02 17:36:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x9f zxid:0x5f txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/0
2017-06-02 17:36:32 [qtp1060863298-1564] INFO  i.c.k.s.storage.KafkaStore - Wait to catch up until the offset of the last message at 1
2017-06-02 17:36:32 [qtp1060863298-1564] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:36:32 +0000] "POST /subjects/forklift-string-topic-value/versions HTTP/1.1" 200 8  119
2017-06-02 17:36:32 [pool-5-thread-28] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:36:32 [pool-5-thread-28] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = consumer-5
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:36:32 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:36:32 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:36:32 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:36:32 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:setData cxid:0xb6 zxid:0x62 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0xb7 zxid:0x63 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0xf0 zxid:0x66 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0xf1 zxid:0x67 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0xf5 zxid:0x6b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0xf8 zxid:0x6e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0xfb zxid:0x71 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0xfe zxid:0x74 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x101 zxid:0x77 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x104 zxid:0x7a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x107 zxid:0x7d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x10a zxid:0x80 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x10d zxid:0x83 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x110 zxid:0x86 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x113 zxid:0x89 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x116 zxid:0x8c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x119 zxid:0x8f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x11c zxid:0x92 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x11f zxid:0x95 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x122 zxid:0x98 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x125 zxid:0x9b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x128 zxid:0x9e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x12b zxid:0xa1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x130 zxid:0xa4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x134 zxid:0xa7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x137 zxid:0xaa txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x13a zxid:0xad txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x13d zxid:0xb0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x140 zxid:0xb3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x143 zxid:0xb6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x146 zxid:0xb9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x149 zxid:0xbc txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x14c zxid:0xbf txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x14f zxid:0xc2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x152 zxid:0xc5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x155 zxid:0xc8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x158 zxid:0xcb txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x15c zxid:0xce txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x161 zxid:0xd1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x164 zxid:0xd4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x167 zxid:0xd7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x16a zxid:0xda txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x16d zxid:0xdd txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x170 zxid:0xe0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x173 zxid:0xe3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x176 zxid:0xe6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x179 zxid:0xe9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x17c zxid:0xec txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x182 zxid:0xef txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x185 zxid:0xf2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x188 zxid:0xf5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x18b zxid:0xf8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2017-06-02 17:36:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e139e30000 type:create cxid:0x18e zxid:0xfb txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2017-06-02 17:36:33 [pool-49-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:36:33 [pool-49-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [] for group testGroup
2017-06-02 17:36:33 [pool-49-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:36:33 [pool-49-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Successfully joined group testGroup with generation 1
2017-06-02 17:36:33 [pool-49-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Setting newly assigned partitions [forklift-string-topic-15, forklift-string-topic-14, forklift-string-topic-13, forklift-string-topic-12, forklift-string-topic-11, forklift-string-topic-10, forklift-string-topic-9, forklift-string-topic-8, forklift-string-topic-7, forklift-string-topic-6, forklift-string-topic-5, forklift-string-topic-4, forklift-string-topic-3, forklift-string-topic-2, forklift-string-topic-1, forklift-string-topic-0] for group testGroup
pool-5-thread-28sending all the text, producer test
pool-5-thread-28sending all the text, producer test
pool-5-thread-28sending all the text, producer test
pool-5-thread-28sending all the text, producer test
pool-5-thread-28sending all the text, producer test
pool-5-thread-28sending all the text, producer test
2017-06-02 17:36:33 [qtp1060863298-1565] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:36:33 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 552  75
pool-5-thread-28sending all the text, producer test
pool-5-thread-28sending all the text, producer test
pool-5-thread-28sending all the text, producer test
pool-5-thread-28sending all the text, producer test
2017-06-02 17:36:35 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:36:35 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - SentIds: 33 consumedIds: 33
2017-06-02 17:36:35 [pool-49-thread-1] INFO  forklift.controller.KafkaController - Wakeup, controlLoop exiting
2017-06-02 17:36:35 [pool-49-thread-1] INFO  forklift.controller.KafkaController - closing offset size committed: 10
2017-06-02 17:36:35 [pool-49-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:36:35 [pool-49-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:36:35 [pool-49-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:36:36 [pool-49-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:36:36 [pool-49-thread-1] INFO  forklift.controller.KafkaController - controlLoop closing kafkaConsumer
2017-06-02 17:36:36 [pool-5-thread-28] INFO  o.a.k.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-06-02 17:36:36 [pool-5-thread-28] INFO  o.e.j.s.NetworkTrafficServerConnector - Stopped NetworkTrafficServerConnector@45589472{HTTP/1.1}{localhost:58081}
2017-06-02 17:36:36 [pool-5-thread-28] INFO  o.e.j.server.handler.ContextHandler - Stopped o.e.j.s.ServletContextHandler@8edff5e{/,null,UNAVAILABLE}
2017-06-02 17:36:36 [pool-5-thread-28] INFO  i.c.k.s.storage.KafkaSchemaRegistry - Shutting down schema registry
[2017-06-02 17:36:36,140] INFO [kafka-store-reader-thread-_schemas], Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
[2017-06-02 17:36:36,148] INFO [kafka-store-reader-thread-_schemas], Stopped  (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
[2017-06-02 17:36:36,148] INFO [kafka-store-reader-thread-_schemas], Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
2017-06-02 17:36:36 [pool-5-thread-28] INFO  i.c.k.s.s.KafkaStoreReaderThread - KafkaStoreReaderThread shutdown complete.
2017-06-02 17:36:36 [pool-5-thread-28] INFO  o.a.k.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-06-02 17:36:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e139e30001
2017-06-02 17:36:36 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /0:0:0:0:0:0:0:1:57860 which had sessionid 0x15c69e139e30001
2017-06-02 17:36:36 [pool-5-thread-28] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e139e30001 closed
2017-06-02 17:36:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e139e30003
2017-06-02 17:36:36 [pool-42-thread-3-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e139e30001
2017-06-02 17:36:36 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /0:0:0:0:0:0:0:1:57890 which had sessionid 0x15c69e139e30003
2017-06-02 17:36:36 [pool-5-thread-28] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e139e30003 closed
2017-06-02 17:36:36 [pool-42-thread-3-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e139e30003
2017-06-02 17:36:40 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e139e30000
2017-06-02 17:36:40 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /127.0.0.1:40516 which had sessionid 0x15c69e139e30000
2017-06-02 17:36:40 [pool-5-thread-28] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e139e30000 closed
2017-06-02 17:36:40 [pool-42-thread-2-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e139e30000
2017-06-02 17:36:41 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - NIOServerCnxn factory exited run method
2017-06-02 17:36:41 [pool-5-thread-28] INFO  o.a.zookeeper.server.ZooKeeperServer - shutting down
2017-06-02 17:36:41 [pool-5-thread-28] INFO  o.a.z.server.SessionTrackerImpl - Shutting down
2017-06-02 17:36:41 [pool-5-thread-28] INFO  o.a.z.server.PrepRequestProcessor - Shutting down
2017-06-02 17:36:41 [pool-5-thread-28] INFO  o.a.z.server.SyncRequestProcessor - Shutting down
2017-06-02 17:36:41 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - PrepRequestProcessor exited loop!
2017-06-02 17:36:41 [SyncThread:0] INFO  o.a.z.server.SyncRequestProcessor - SyncRequestProcessor exited!
2017-06-02 17:36:41 [pool-5-thread-28] INFO  o.a.z.server.FinalRequestProcessor - shutdown of request processor complete
2017-06-02 17:36:42 [SessionTracker] INFO  o.a.z.server.SessionTrackerImpl - SessionTrackerImpl exited loop!
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest forklift.integration.[33mForkliftMessageTests[0m.[36mtestForkliftMessageWithProperties[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 1 total, 16.035s[0m[0m
2017-06-02 17:36:44 [pool-5-thread-28] WARN  forklift.message.MessageStream - Tried to take record from non-existant topic queue: topic1
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest forklift.connectors.[33mMessageStreamTests[0m.[36mnextMessageMultipleTopics[0m started[0m
[0m[[0minfo[0m] [0mTest forklift.connectors.[33mMessageStreamTests[0m.[36maddAndGetNextMessageTest[0m started[0m
[0m[[0minfo[0m] [0mTest forklift.connectors.[33mMessageStreamTests[0m.[36mnextMessageOrderTest[0m started[0m
[0m[[0minfo[0m] [0mTest forklift.connectors.[33mMessageStreamTests[0m.[36mremoveTopic[0m started[0m
[0m[[0minfo[0m] [0mTest forklift.connectors.[33mMessageStreamTests[0m.[36mnextMessageNullTest[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 5 total, 1.479s[0m[0m
2017-06-02 17:36:44 [pool-51-thread-1] INFO  o.a.z.server.ZooKeeperServerMain - Starting server
2017-06-02 17:36:44 [pool-51-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - tickTime set to 2000
2017-06-02 17:36:44 [pool-51-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - minSessionTimeout set to -1
2017-06-02 17:36:44 [pool-51-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - maxSessionTimeout set to -1
2017-06-02 17:36:44 [pool-51-thread-1] INFO  o.a.z.server.NIOServerCnxnFactory - binding to port 0.0.0.0/0.0.0.0:42181
2017-06-02 17:36:44 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:40648
2017-06-02 17:36:44 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] WARN  o.a.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x0, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_31]
2017-06-02 17:36:44 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /127.0.0.1:40648 (no session established for client)
2017-06-02 17:36:44 [pool-51-thread-2] INFO  kafka.server.KafkaConfig - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	default.replication.factor = 1
	delete.topic.enable = false
	fetch.purgatory.purge.interval.requests = 1000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.protocol.version = 0.10.1-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listeners = PLAINTEXT://:49092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /home/travis/build/dcshock/forklift/src/test/resources/zafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.10.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 16
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	unclean.leader.election.enable = true
	zookeeper.connect = localhost:42181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2017-06-02 17:36:44 [pool-51-thread-2] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@20a72f38
2017-06-02 17:36:44 [pool-51-thread-2-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:36:44 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /0:0:0:0:0:0:0:1:57984
2017-06-02 17:36:44 [pool-51-thread-2-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/0:0:0:0:0:0:0:1:42181, initiating session
2017-06-02 17:36:44 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /0:0:0:0:0:0:0:1:57984
2017-06-02 17:36:44 [SyncThread:0] INFO  o.a.z.server.persistence.FileTxnLog - Creating new log file: log.1
2017-06-02 17:36:44 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e17e840000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:57984
2017-06-02 17:36:44 [pool-51-thread-2-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:42181, sessionid = 0x15c69e17e840000, negotiated timeout = 6000
2017-06-02 17:36:44 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x4 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2017-06-02 17:36:44 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0xa zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2017-06-02 17:36:44 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x12 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2017-06-02 17:36:44 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x1a zxid:0x11 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2017-06-02 17:36:45 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:setData cxid:0x24 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2017-06-02 17:36:45 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:delete cxid:0x33 zxid:0x17 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2017-06-02 17:36:45 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x3e zxid:0x18 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2017-06-02 17:36:45 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x3f zxid:0x19 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2017-06-02 17:36:45 [pool-51-thread-2] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:36:45 [pool-51-thread-2] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:36:47 [pool-51-thread-3] INFO  i.c.k.s.rest.SchemaRegistryConfig - SchemaRegistryConfig values: 
	metric.reporters = []
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	kafkastore.ssl.trustmanager.algorithm = PKIX
	authentication.realm = 
	ssl.keystore.type = JKS
	kafkastore.topic = _schemas
	metrics.jmx.prefix = kafka.schema.registry
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.topic.replication.factor = 3
	ssl.truststore.password = 
	kafkastore.timeout.ms = 500
	host.name = localhost
	kafkastore.bootstrap.servers = []
	schema.registry.zk.namespace = schema_registry
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.kerberos.service.name = 
	ssl.endpoint.identification.algorithm = 
	compression.enable = false
	kafkastore.ssl.truststore.type = JKS
	avro.compatibility.level = full
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.truststore.location = 
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	kafkastore.ssl.keystore.type = JKS
	ssl.truststore.type = JKS
	kafkastore.ssl.truststore.password = 
	access.control.allow.origin = 
	ssl.truststore.location = 
	ssl.keystore.password = 
	port = 8081
	kafkastore.ssl.keystore.location = 
	master.eligibility = true
	ssl.client.auth = false
	kafkastore.ssl.keystore.password = 
	kafkastore.security.protocol = PLAINTEXT
	ssl.trustmanager.algorithm = 
	authentication.method = NONE
	request.logger.name = io.confluent.rest-utils.requests
	ssl.key.password = 
	kafkastore.zk.session.timeout.ms = 30000
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.ssl.key.password = 
	zookeeper.set.acl = false
	authentication.roles = [*]
	metrics.num.samples = 2
	ssl.protocol = TLS
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.connection.url = localhost:42181
	debug = false
	listeners = [http://localhost:58081]
	ssl.provider = 
	ssl.enabled.protocols = []
	shutdown.graceful.ms = 1000
	ssl.keystore.location = 
	ssl.cipher.suites = []
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.cipher.suites = 
	access.control.allow.methods = 
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	ssl.keymanager.algorithm = 
	metrics.sample.window.ms = 30000
	kafkastore.init.timeout.ms = 60000

2017-06-02 17:36:47 [pool-51-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@1121f315
2017-06-02 17:36:47 [pool-51-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:36:47 [pool-51-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/0:0:0:0:0:0:0:1:42181, initiating session
2017-06-02 17:36:47 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /0:0:0:0:0:0:0:1:58000
2017-06-02 17:36:47 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /0:0:0:0:0:0:0:1:58000
2017-06-02 17:36:47 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e17e840001 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:58000
2017-06-02 17:36:47 [pool-51-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:42181, sessionid = 0x15c69e17e840001, negotiated timeout = 30000
2017-06-02 17:36:47 [pool-51-thread-3] INFO  i.c.k.s.storage.KafkaStore - Initializing KafkaStore with broker endpoints: PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092
2017-06-02 17:36:47 [pool-51-thread-3] WARN  i.c.k.s.storage.KafkaStore - Creating the schema topic _schemas using a replication factor of 1, which is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic.
2017-06-02 17:36:47 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840001 type:setData cxid:0x8 zxid:0x1c txntype:-1 reqpath:n/a Error Path:/config/topics/_schemas Error:KeeperErrorCode = NoNode for /config/topics/_schemas
2017-06-02 17:36:47 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840001 type:create cxid:0x9 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:36:47 [pool-51-thread-3] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2017-06-02 17:36:47 [pool-51-thread-3] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	buffer.memory = 33554432
	client.id = producer-11
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2017-06-02 17:36:47 [pool-51-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:36:47 [pool-51-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:36:47 [pool-51-thread-3] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	check.crcs = true
	client.id = KafkaStore-reader-_schemas
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = schema-registry-localhost-58081
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-06-02 17:36:47 [pool-51-thread-3] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	check.crcs = true
	client.id = KafkaStore-reader-_schemas
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = schema-registry-localhost-58081
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-06-02 17:36:47 [pool-51-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:36:47 [pool-51-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:36:47 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x49 zxid:0x20 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_schemas/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_schemas/partitions/0
2017-06-02 17:36:47 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x4a zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_schemas/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_schemas/partitions
2017-06-02 17:36:47 [pool-51-thread-3] INFO  i.c.k.s.s.KafkaStoreReaderThread - Initialized last consumed offset to -1
[2017-06-02 17:36:47,283] INFO [kafka-store-reader-thread-_schemas], Starting  (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
2017-06-02 17:36:47 [pool-51-thread-3] INFO  i.c.k.s.storage.KafkaStore - Wait to catch up until the offset of the last message at 0
2017-06-02 17:36:47 [pool-51-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@4f088c7d
2017-06-02 17:36:47 [pool-51-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:36:47 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /0:0:0:0:0:0:0:1:58022
2017-06-02 17:36:47 [pool-51-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/0:0:0:0:0:0:0:1:42181, initiating session
2017-06-02 17:36:47 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /0:0:0:0:0:0:0:1:58022
2017-06-02 17:36:47 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e17e840002 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:58022
2017-06-02 17:36:47 [pool-51-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:42181, sessionid = 0x15c69e17e840002, negotiated timeout = 30000
2017-06-02 17:36:47 [pool-51-thread-3] INFO  i.c.k.s.storage.KafkaSchemaRegistry - Created schema registry namespace localhost:42181/schema_registry
2017-06-02 17:36:47 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e17e840002
2017-06-02 17:36:47 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /0:0:0:0:0:0:0:1:58022 which had sessionid 0x15c69e17e840002
2017-06-02 17:36:47 [pool-51-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e17e840002 closed
2017-06-02 17:36:47 [pool-51-thread-3-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e17e840002
2017-06-02 17:36:47 [pool-51-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181/schema_registry sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@362af4e8
2017-06-02 17:36:47 [pool-51-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:36:47 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:40694
2017-06-02 17:36:47 [pool-51-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/127.0.0.1:42181, initiating session
2017-06-02 17:36:47 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:40694
2017-06-02 17:36:47 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e17e840003 with negotiated timeout 30000 for client /127.0.0.1:40694
2017-06-02 17:36:47 [pool-51-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:42181, sessionid = 0x15c69e17e840003, negotiated timeout = 30000
2017-06-02 17:36:47 [pool-51-thread-3] INFO  i.c.k.s.z.ZookeeperMasterElector - Successfully elected the new master: {"host":"localhost","port":58081,"master_eligibility":true,"version":1}
2017-06-02 17:36:47 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840003 type:create cxid:0x7 zxid:0x2b txntype:-1 reqpath:n/a Error Path:/schema_registry/schema_registry_master Error:KeeperErrorCode = NodeExists for /schema_registry/schema_registry_master
2017-06-02 17:36:47 [ZkClient-EventThread-1629-localhost:42181/schema_registry] INFO  i.c.k.s.z.ZookeeperMasterElector - Successfully elected the new master: {"host":"localhost","port":58081,"master_eligibility":true,"version":1}
2017-06-02 17:36:47 [pool-51-thread-3] INFO  io.confluent.rest.Application - Adding listener: http://localhost:58081
2017-06-02 17:36:47 [pool-51-thread-3] INFO  org.eclipse.jetty.server.Server - jetty-9.2.12.v20150709
2017-06-02 17:36:48 [pool-51-thread-3] INFO  o.e.j.server.handler.ContextHandler - Started o.e.j.s.ServletContextHandler@4452a6e0{/,null,AVAILABLE}
2017-06-02 17:36:48 [pool-51-thread-3] INFO  o.e.j.s.NetworkTrafficServerConnector - Started NetworkTrafficServerConnector@7c3a3db0{HTTP/1.1}{localhost:58081}
2017-06-02 17:36:48 [pool-51-thread-3] INFO  org.eclipse.jetty.server.Server - Started @312946ms
2017-06-02 17:36:49 [pool-5-thread-28] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:36:49 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:36:49 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:36:49 [pool-5-thread-28] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = producer-12
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:36:49 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:36:49 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:36:49 [pool-5-thread-28] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:36:49 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:36:49 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:36:49 [pool-5-thread-28] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = producer-13
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:36:49 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:36:49 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:36:49 [pool-5-thread-28] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:36:49 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:36:49 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:36:49 [pool-5-thread-28] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = producer-14
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:36:49 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:36:49 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:36:49 [pool-5-thread-28] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:36:49 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:36:49 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:36:49 [pool-5-thread-28] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = producer-15
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:36:49 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:36:49 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:setData cxid:0x52 zxid:0x2c txntype:-1 reqpath:n/a Error Path:/config/topics/forklift-string-topic Error:KeeperErrorCode = NoNode for /config/topics/forklift-string-topic
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x53 zxid:0x2d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:setData cxid:0x71 zxid:0x30 txntype:-1 reqpath:n/a Error Path:/config/topics/forklift-map-topic Error:KeeperErrorCode = NoNode for /config/topics/forklift-map-topic
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x74 zxid:0x31 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/3
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x75 zxid:0x32 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x76 zxid:0x33 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x7d zxid:0x3a txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic Error:KeeperErrorCode = NodeExists for /brokers/topics/forklift-map-topic
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x7f zxid:0x3b txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/14
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x89 zxid:0x3e txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/12
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:setData cxid:0x8a zxid:0x3f txntype:-1 reqpath:n/a Error Path:/config/topics/forklift-object-topic Error:KeeperErrorCode = NoNode for /config/topics/forklift-object-topic
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x8c zxid:0x41 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x91 zxid:0x44 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/8
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x9b zxid:0x48 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/6
2017-06-02 17:36:49 [kafka-producer-network-thread | producer-13] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 0 : {forklift-string-topic=LEADER_NOT_AVAILABLE, forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0xa4 zxid:0x4b txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/7
2017-06-02 17:36:49 [kafka-producer-network-thread | producer-14] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 0 : {forklift-string-topic=LEADER_NOT_AVAILABLE, forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:49 [kafka-producer-network-thread | producer-15] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 0 : {forklift-string-topic=LEADER_NOT_AVAILABLE, forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0xaa zxid:0x4f txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic Error:KeeperErrorCode = NodeExists for /brokers/topics/forklift-object-topic
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0xab zxid:0x50 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/13
2017-06-02 17:36:49 [kafka-producer-network-thread | producer-12] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 0 : {forklift-string-topic=LEADER_NOT_AVAILABLE, forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0xae zxid:0x53 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/10
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0xb1 zxid:0x56 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/5
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0xb4 zxid:0x59 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/2
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0xb7 zxid:0x5c txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/4
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0xba zxid:0x5f txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/11
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0xbd zxid:0x62 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/15
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0xc0 zxid:0x65 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/1
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0xc3 zxid:0x68 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/9
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0xc6 zxid:0x6b txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/0
2017-06-02 17:36:49 [kafka-producer-network-thread | producer-13] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 1 : {forklift-string-topic=LEADER_NOT_AVAILABLE, forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:49 [kafka-producer-network-thread | producer-14] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 1 : {forklift-string-topic=LEADER_NOT_AVAILABLE, forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:49 [kafka-producer-network-thread | producer-12] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 1 : {forklift-string-topic=LEADER_NOT_AVAILABLE, forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x116 zxid:0x6e txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/13
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x117 zxid:0x6f txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x123 zxid:0x73 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/9
2017-06-02 17:36:49 [kafka-producer-network-thread | producer-15] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 1 : {forklift-string-topic=LEADER_NOT_AVAILABLE, forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x124 zxid:0x74 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x129 zxid:0x78 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/7
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x12c zxid:0x7b txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/3
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x12f zxid:0x7e txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/1
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x132 zxid:0x81 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/15
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x136 zxid:0x84 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/13
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x139 zxid:0x87 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/14
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x13c zxid:0x8a txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/6
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x140 zxid:0x8d txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/3
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x143 zxid:0x90 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/12
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x146 zxid:0x93 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/11
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x14a zxid:0x96 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/6
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x14d zxid:0x99 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/11
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x150 zxid:0x9c txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/9
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x154 zxid:0x9f txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/14
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x157 zxid:0xa2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/8
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x15a zxid:0xa5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/1
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x15d zxid:0xa8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/4
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x162 zxid:0xab txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/10
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x16d zxid:0xae txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/5
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x173 zxid:0xb1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/2
2017-06-02 17:36:49 [kafka-producer-network-thread | producer-14] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 2 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:49 [kafka-producer-network-thread | producer-13] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 2 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x17b zxid:0xb4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/15
2017-06-02 17:36:49 [kafka-producer-network-thread | producer-12] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 2 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x181 zxid:0xb7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/10
2017-06-02 17:36:49 [qtp430683137-1639] INFO  i.c.k.s.storage.KafkaStore - Wait to catch up until the offset of the last message at 1
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x186 zxid:0xba txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/7
2017-06-02 17:36:49 [kafka-producer-network-thread | producer-15] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 2 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:49 [qtp430683137-1639] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:36:49 +0000] "POST /subjects/forklift-string-topic-value/versions HTTP/1.1" 200 8  115
2017-06-02 17:36:49 [qtp430683137-1641] INFO  i.c.k.s.storage.KafkaStore - Wait to catch up until the offset of the last message at 2
2017-06-02 17:36:49 [qtp430683137-1640] INFO  i.c.k.s.storage.KafkaStore - Wait to catch up until the offset of the last message at 2
2017-06-02 17:36:49 [qtp430683137-1641] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:36:49 +0000] "POST /subjects/forklift-string-topic-value/versions HTTP/1.1" 200 8  172
2017-06-02 17:36:49 [qtp430683137-1639] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:36:49 +0000] "POST /subjects/forklift-string-topic-value/versions HTTP/1.1" 200 8  110
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x196 zxid:0xbd txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/8
2017-06-02 17:36:49 [qtp430683137-1640] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:36:49 +0000] "POST /subjects/forklift-string-topic-value/versions HTTP/1.1" 200 8  254
2017-06-02 17:36:49 [kafka-producer-network-thread | producer-14] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 3 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x1a3 zxid:0xc0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/5
2017-06-02 17:36:49 [kafka-producer-network-thread | producer-15] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 5 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:49 [kafka-producer-network-thread | producer-13] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 3 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x1a8 zxid:0xc3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/12
2017-06-02 17:36:49 [kafka-producer-network-thread | producer-12] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 3 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x1ac zxid:0xc6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/0
2017-06-02 17:36:50 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x1b8 zxid:0xc9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/0
2017-06-02 17:36:50 [kafka-producer-network-thread | producer-14] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 8 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:50 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x1c6 zxid:0xcc txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/2
2017-06-02 17:36:50 [kafka-producer-network-thread | producer-15] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 14 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:50 [kafka-producer-network-thread | producer-13] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 20 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:50 [kafka-producer-network-thread | producer-12] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 9 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:50 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x1cc zxid:0xcf txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/4
2017-06-02 17:36:50 [kafka-producer-network-thread | producer-15] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 19 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:50 [kafka-producer-network-thread | producer-14] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 16 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:50 [kafka-producer-network-thread | producer-13] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 24 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:50 [kafka-producer-network-thread | producer-12] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 17 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:50 [kafka-producer-network-thread | producer-15] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 29 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:50 [kafka-producer-network-thread | producer-13] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 37 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:50 [kafka-producer-network-thread | producer-14] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 24 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:50 [kafka-producer-network-thread | producer-12] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 22 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:50 [kafka-producer-network-thread | producer-15] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 33 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:50 [kafka-producer-network-thread | producer-14] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 32 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:50 [kafka-producer-network-thread | producer-13] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 45 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:50 [kafka-producer-network-thread | producer-12] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 29 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:50 [kafka-producer-network-thread | producer-15] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 38 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:50 [kafka-producer-network-thread | producer-14] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 46 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:50 [kafka-producer-network-thread | producer-13] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 51 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:36:50 [qtp430683137-1638] INFO  i.c.k.s.storage.KafkaStore - Wait to catch up until the offset of the last message at 2
2017-06-02 17:36:50 [qtp430683137-1638] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:36:50 +0000] "POST /subjects/forklift-object-topic-value/versions HTTP/1.1" 200 8  110
2017-06-02 17:36:50 [qtp430683137-1638] INFO  i.c.k.s.storage.KafkaStore - Wait to catch up until the offset of the last message at 3
2017-06-02 17:36:50 [qtp430683137-1638] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:36:50 +0000] "POST /subjects/forklift-map-topic-value/versions HTTP/1.1" 200 8  77
2017-06-02 17:36:50 [qtp430683137-1641] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:36:50 +0000] "POST /subjects/forklift-object-topic-value/versions HTTP/1.1" 200 8  63
2017-06-02 17:36:50 [qtp430683137-1639] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:36:50 +0000] "POST /subjects/forklift-map-topic-value/versions HTTP/1.1" 200 8  98
2017-06-02 17:36:50 [qtp430683137-1641] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:36:50 +0000] "POST /subjects/forklift-map-topic-value/versions HTTP/1.1" 200 8  56
2017-06-02 17:36:51 [qtp430683137-1640] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:36:50 +0000] "POST /subjects/forklift-map-topic-value/versions HTTP/1.1" 200 8  108
2017-06-02 17:36:51 [qtp430683137-1638] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:36:51 +0000] "POST /subjects/forklift-object-topic-value/versions HTTP/1.1" 200 8  13
2017-06-02 17:36:51 [qtp430683137-1639] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:36:50 +0000] "POST /subjects/forklift-object-topic-value/versions HTTP/1.1" 200 8  87
2017-06-02 17:36:51 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Starting Consumers for server: Server1
2017-06-02 17:36:51 [pool-58-thread-14] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:36:51 [pool-58-thread-14] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = consumer-6
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:36:51 [pool-58-thread-14] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:36:51 [pool-58-thread-14] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:36:51 [pool-58-thread-14] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:36:51 [pool-58-thread-14] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:36:51 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Starting Consumers for server: Server2
2017-06-02 17:36:51 [pool-58-thread-16] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:36:51 [pool-58-thread-16] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = consumer-7
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:36:51 [pool-58-thread-16] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:36:51 [pool-58-thread-16] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:36:51 [pool-58-thread-16] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:36:51 [pool-58-thread-16] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:setData cxid:0x24d zxid:0xd2 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x24e zxid:0xd3 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x287 zxid:0xd6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x288 zxid:0xd7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x28c zxid:0xdb txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x292 zxid:0xde txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x295 zxid:0xe1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x298 zxid:0xe4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x29b zxid:0xe7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x2a1 zxid:0xea txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x2a4 zxid:0xed txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x2ab zxid:0xf0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x2b1 zxid:0xf3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x2b8 zxid:0xf6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x2bc zxid:0xf9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x2bf zxid:0xfc txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x2c4 zxid:0xff txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x2c8 zxid:0x102 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x2cb zxid:0x105 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x2ce zxid:0x108 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x2d1 zxid:0x10b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x2da zxid:0x10e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x2dd zxid:0x111 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x2e0 zxid:0x114 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x2e3 zxid:0x117 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x2ea zxid:0x11a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x2ef zxid:0x11d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x2f2 zxid:0x120 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x2f5 zxid:0x123 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x2f8 zxid:0x126 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x2fb zxid:0x129 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x2fe zxid:0x12c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x301 zxid:0x12f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x304 zxid:0x132 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x307 zxid:0x135 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2017-06-02 17:36:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x30a zxid:0x138 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2017-06-02 17:36:52 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x30d zxid:0x13b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2017-06-02 17:36:52 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x310 zxid:0x13e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2017-06-02 17:36:52 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x313 zxid:0x141 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2017-06-02 17:36:52 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x316 zxid:0x144 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2017-06-02 17:36:52 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x319 zxid:0x147 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2017-06-02 17:36:52 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x31c zxid:0x14a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2017-06-02 17:36:52 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x31f zxid:0x14d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2017-06-02 17:36:52 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x322 zxid:0x150 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2017-06-02 17:36:52 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x325 zxid:0x153 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2017-06-02 17:36:52 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x328 zxid:0x156 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2017-06-02 17:36:52 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x32d zxid:0x159 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2017-06-02 17:36:52 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x332 zxid:0x15c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2017-06-02 17:36:52 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x337 zxid:0x15f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2017-06-02 17:36:52 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x33a zxid:0x162 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2017-06-02 17:36:52 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x33d zxid:0x165 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2017-06-02 17:36:52 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x340 zxid:0x168 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2017-06-02 17:36:52 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e17e840000 type:create cxid:0x343 zxid:0x16b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2017-06-02 17:36:54 [pool-60-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:36:54 [pool-60-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [] for group testGroup
2017-06-02 17:36:54 [pool-60-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:36:54 [pool-60-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Successfully joined group testGroup with generation 1
2017-06-02 17:36:54 [pool-60-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Setting newly assigned partitions [forklift-string-topic-14, forklift-string-topic-10, forklift-object-topic-2, forklift-string-topic-6, forklift-map-topic-12, forklift-string-topic-2, forklift-object-topic-3, forklift-map-topic-8, forklift-object-topic-7, forklift-map-topic-4, forklift-object-topic-11, forklift-map-topic-0, forklift-object-topic-15, forklift-string-topic-13, forklift-string-topic-9, forklift-object-topic-1, forklift-string-topic-5, forklift-object-topic-6, forklift-map-topic-15, forklift-string-topic-1, forklift-object-topic-10, forklift-map-topic-11, forklift-object-topic-14, forklift-map-topic-7, forklift-map-topic-3, forklift-string-topic-12, forklift-string-topic-8, forklift-object-topic-0, forklift-string-topic-4, forklift-object-topic-5, forklift-map-topic-14, forklift-string-topic-0, forklift-object-topic-9, forklift-map-topic-10, forklift-object-topic-13, forklift-map-topic-6, forklift-map-topic-2, forklift-string-topic-15, forklift-string-topic-11, forklift-string-topic-7, forklift-map-topic-13, forklift-string-topic-3, forklift-object-topic-4, forklift-map-topic-9, forklift-object-topic-8, forklift-map-topic-5, forklift-object-topic-12, forklift-map-topic-1] for group testGroup
2017-06-02 17:36:54 [pool-59-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:36:54 [pool-59-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [] for group testGroup
2017-06-02 17:36:54 [pool-59-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:36:54 [qtp430683137-1641] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:36:54 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 552  28
2017-06-02 17:36:54 [pool-58-thread-16] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:36:54 [pool-58-thread-16] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:36:54 [pool-58-thread-16] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:36:54 [pool-58-thread-16] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = producer-16
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:36:54 [pool-58-thread-16] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:36:54 [pool-58-thread-16] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:36:57 [pool-60-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [forklift-string-topic-14, forklift-string-topic-10, forklift-object-topic-2, forklift-string-topic-6, forklift-map-topic-12, forklift-string-topic-2, forklift-object-topic-3, forklift-map-topic-8, forklift-object-topic-7, forklift-map-topic-4, forklift-object-topic-11, forklift-map-topic-0, forklift-object-topic-15, forklift-string-topic-13, forklift-string-topic-9, forklift-object-topic-1, forklift-string-topic-5, forklift-object-topic-6, forklift-map-topic-15, forklift-string-topic-1, forklift-object-topic-10, forklift-map-topic-11, forklift-object-topic-14, forklift-map-topic-7, forklift-map-topic-3, forklift-string-topic-12, forklift-string-topic-8, forklift-object-topic-0, forklift-string-topic-4, forklift-object-topic-5, forklift-map-topic-14, forklift-string-topic-0, forklift-object-topic-9, forklift-map-topic-10, forklift-object-topic-13, forklift-map-topic-6, forklift-map-topic-2, forklift-string-topic-15, forklift-string-topic-11, forklift-string-topic-7, forklift-map-topic-13, forklift-string-topic-3, forklift-object-topic-4, forklift-map-topic-9, forklift-object-topic-8, forklift-map-topic-5, forklift-object-topic-12, forklift-map-topic-1] for group testGroup
2017-06-02 17:36:57 [pool-60-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:36:57 [pool-59-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Successfully joined group testGroup with generation 2
2017-06-02 17:36:57 [pool-59-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Setting newly assigned partitions [forklift-object-topic-2, forklift-object-topic-0, forklift-string-topic-6, forklift-string-topic-4, forklift-object-topic-5, forklift-string-topic-2, forklift-object-topic-3, forklift-string-topic-0, forklift-object-topic-7, forklift-map-topic-4, forklift-map-topic-6, forklift-map-topic-0, forklift-map-topic-2, forklift-object-topic-1, forklift-string-topic-7, forklift-string-topic-5, forklift-object-topic-6, forklift-string-topic-3, forklift-object-topic-4, forklift-string-topic-1, forklift-map-topic-5, forklift-map-topic-7, forklift-map-topic-1, forklift-map-topic-3] for group testGroup
2017-06-02 17:36:57 [pool-60-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Successfully joined group testGroup with generation 2
2017-06-02 17:36:57 [pool-60-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Setting newly assigned partitions [forklift-string-topic-14, forklift-string-topic-12, forklift-string-topic-10, forklift-string-topic-8, forklift-map-topic-12, forklift-map-topic-14, forklift-map-topic-8, forklift-object-topic-9, forklift-map-topic-10, forklift-object-topic-13, forklift-object-topic-11, forklift-object-topic-15, forklift-string-topic-15, forklift-string-topic-13, forklift-string-topic-11, forklift-string-topic-9, forklift-map-topic-13, forklift-map-topic-15, forklift-map-topic-9, forklift-object-topic-10, forklift-map-topic-11, forklift-object-topic-8, forklift-object-topic-14, forklift-object-topic-12] for group testGroup
2017-06-02 17:36:57 [qtp430683137-1640] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:36:57 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 552  15
2017-06-02 17:36:57 [pool-58-thread-14] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:36:57 [pool-58-thread-14] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:36:57 [pool-58-thread-14] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:36:57 [pool-58-thread-14] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = producer-17
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:36:57 [pool-58-thread-14] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:36:57 [pool-58-thread-14] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:37:01 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Stopping Consumers for server: Server1
2017-06-02 17:37:01 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:01 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:01 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:01 [pool-59-thread-1] INFO  forklift.controller.KafkaController - Wakeup, controlLoop exiting
2017-06-02 17:37:01 [pool-59-thread-1] INFO  forklift.controller.KafkaController - closing offset size committed: 24
2017-06-02 17:37:01 [pool-59-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:37:01 [pool-59-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:37:01 [pool-59-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:37:01 [pool-59-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:37:01 [pool-59-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:37:01 [pool-59-thread-1] INFO  forklift.controller.KafkaController - controlLoop closing kafkaConsumer
2017-06-02 17:37:01 [pool-5-thread-28] INFO  o.a.k.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-06-02 17:37:06 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Starting Consumers for server: Server3
2017-06-02 17:37:06 [pool-58-thread-19] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:37:06 [pool-58-thread-19] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = consumer-8
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:37:06 [pool-58-thread-19] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:37:06 [pool-58-thread-19] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:37:06 [pool-58-thread-19] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:37:06 [pool-58-thread-19] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:37:06 [pool-61-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:37:06 [pool-61-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [] for group testGroup
2017-06-02 17:37:06 [pool-61-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:37:09 [pool-60-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [forklift-string-topic-14, forklift-string-topic-12, forklift-string-topic-10, forklift-string-topic-8, forklift-map-topic-12, forklift-map-topic-14, forklift-object-topic-9, forklift-map-topic-8, forklift-map-topic-10, forklift-object-topic-13, forklift-object-topic-11, forklift-object-topic-15, forklift-string-topic-15, forklift-string-topic-13, forklift-string-topic-11, forklift-string-topic-9, forklift-map-topic-13, forklift-map-topic-15, forklift-object-topic-10, forklift-map-topic-9, forklift-map-topic-11, forklift-object-topic-8, forklift-object-topic-14, forklift-object-topic-12] for group testGroup
2017-06-02 17:37:09 [pool-60-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:37:11 [pool-60-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Successfully joined group testGroup with generation 3
2017-06-02 17:37:11 [pool-60-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Setting newly assigned partitions [forklift-object-topic-2, forklift-object-topic-0, forklift-string-topic-6, forklift-string-topic-4, forklift-object-topic-5, forklift-map-topic-12, forklift-string-topic-2, forklift-object-topic-3, forklift-map-topic-14, forklift-string-topic-0, forklift-object-topic-9, forklift-map-topic-8, forklift-object-topic-7, forklift-map-topic-10, forklift-object-topic-13, forklift-map-topic-4, forklift-object-topic-11, forklift-map-topic-6, forklift-map-topic-0, forklift-object-topic-15, forklift-map-topic-2, forklift-object-topic-1, forklift-string-topic-7, forklift-string-topic-5, forklift-object-topic-6, forklift-map-topic-13, forklift-string-topic-3, forklift-object-topic-4, forklift-map-topic-15, forklift-string-topic-1, forklift-object-topic-10, forklift-map-topic-9, forklift-object-topic-8, forklift-map-topic-11, forklift-object-topic-14, forklift-map-topic-5, forklift-object-topic-12, forklift-map-topic-7, forklift-map-topic-1, forklift-map-topic-3] for group testGroup
2017-06-02 17:37:11 [pool-61-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Successfully joined group testGroup with generation 3
2017-06-02 17:37:11 [pool-61-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Setting newly assigned partitions [forklift-string-topic-15, forklift-string-topic-14, forklift-string-topic-13, forklift-string-topic-12, forklift-string-topic-11, forklift-string-topic-10, forklift-string-topic-9, forklift-string-topic-8] for group testGroup
2017-06-02 17:37:11 [pool-61-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [forklift-string-topic-15, forklift-string-topic-14, forklift-string-topic-13, forklift-string-topic-12, forklift-string-topic-11, forklift-string-topic-10, forklift-string-topic-9, forklift-string-topic-8] for group testGroup
2017-06-02 17:37:11 [pool-61-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:37:11 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Stopping Consumers for server: Server2
2017-06-02 17:37:11 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:11 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:11 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:11 [pool-60-thread-1] INFO  forklift.controller.KafkaController - Wakeup, controlLoop exiting
2017-06-02 17:37:11 [pool-60-thread-1] INFO  forklift.controller.KafkaController - closing offset size committed: 5
2017-06-02 17:37:11 [pool-60-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:37:11 [pool-60-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:37:11 [pool-58-thread-18] ERROR forklift.consumer.Consumer - JMS Error in message loop: 
forklift.connectors.ConnectorException: Connection to Kafka Controller lost
	at forklift.consumer.KafkaTopicConsumer.receive(KafkaTopicConsumer.java:41) ~[classes/:na]
	at forklift.consumer.Consumer.messageLoop(Consumer.java:253) [classes/:na]
	at forklift.consumer.Consumer.listen(Consumer.java:233) [classes/:na]
	at forklift.integration.RebalanceTests$ForkliftServer.lambda$startConsumers$6(RebalanceTests.java:205) [test-classes/:na]
	at forklift.integration.RebalanceTests$ForkliftServer$$Lambda$187/809710382.run(Unknown Source) [test-classes/:na]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_31]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_31]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_31]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_31]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_31]
2017-06-02 17:37:11 [pool-60-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:37:11 [pool-60-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:37:11 [pool-60-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:37:11 [pool-60-thread-1] INFO  forklift.controller.KafkaController - controlLoop closing kafkaConsumer
2017-06-02 17:37:11 [pool-5-thread-28] INFO  o.a.k.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-06-02 17:37:11 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Waiting: 0
2017-06-02 17:37:12 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Waiting: 1
2017-06-02 17:37:13 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Waiting: 2
2017-06-02 17:37:14 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Waiting: 3
2017-06-02 17:37:15 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Waiting: 4
2017-06-02 17:37:16 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Waiting: 5
2017-06-02 17:37:17 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Waiting: 6
2017-06-02 17:37:18 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Waiting: 7
2017-06-02 17:37:19 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Waiting: 8
2017-06-02 17:37:20 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Waiting: 9
2017-06-02 17:37:21 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Waiting: 10
2017-06-02 17:37:21 [pool-61-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Successfully joined group testGroup with generation 4
2017-06-02 17:37:21 [pool-61-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Setting newly assigned partitions [forklift-string-topic-14, forklift-string-topic-10, forklift-object-topic-2, forklift-string-topic-6, forklift-map-topic-12, forklift-string-topic-2, forklift-object-topic-3, forklift-map-topic-8, forklift-object-topic-7, forklift-map-topic-4, forklift-object-topic-11, forklift-map-topic-0, forklift-object-topic-15, forklift-string-topic-13, forklift-string-topic-9, forklift-object-topic-1, forklift-string-topic-5, forklift-object-topic-6, forklift-map-topic-15, forklift-string-topic-1, forklift-object-topic-10, forklift-map-topic-11, forklift-object-topic-14, forklift-map-topic-7, forklift-map-topic-3, forklift-string-topic-12, forklift-string-topic-8, forklift-object-topic-0, forklift-string-topic-4, forklift-object-topic-5, forklift-map-topic-14, forklift-string-topic-0, forklift-object-topic-9, forklift-map-topic-10, forklift-object-topic-13, forklift-map-topic-6, forklift-map-topic-2, forklift-string-topic-15, forklift-string-topic-11, forklift-string-topic-7, forklift-map-topic-13, forklift-string-topic-3, forklift-object-topic-4, forklift-map-topic-9, forklift-object-topic-8, forklift-map-topic-5, forklift-object-topic-12, forklift-map-topic-1] for group testGroup
2017-06-02 17:37:21 [qtp430683137-1641] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:37:21 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 552  7
2017-06-02 17:37:21 [pool-58-thread-19] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:37:21 [pool-58-thread-19] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:37:21 [pool-58-thread-19] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:37:21 [pool-58-thread-19] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = producer-18
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:37:21 [pool-58-thread-19] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:37:21 [pool-58-thread-19] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:37:22 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Waiting: 11
2017-06-02 17:37:23 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Stopping Consumers for server: Server3
2017-06-02 17:37:23 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:23 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:23 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:23 [pool-61-thread-1] INFO  forklift.controller.KafkaController - Wakeup, controlLoop exiting
2017-06-02 17:37:23 [pool-61-thread-1] INFO  forklift.controller.KafkaController - closing offset size committed: 48
2017-06-02 17:37:23 [pool-61-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:37:23 [pool-61-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:37:23 [pool-61-thread-1] INFO  forklift.controller.KafkaController - controlLoop closing kafkaConsumer
2017-06-02 17:37:23 [pool-5-thread-28] INFO  o.a.k.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-06-02 17:37:23 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - SentIds: 14370 consumedIds: 14370
2017-06-02 17:37:23 [pool-5-thread-28] INFO  o.a.k.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-06-02 17:37:23 [pool-5-thread-28] INFO  o.a.k.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-06-02 17:37:23 [pool-5-thread-28] INFO  o.a.k.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-06-02 17:37:23 [pool-5-thread-28] INFO  o.a.k.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-06-02 17:37:23 [pool-5-thread-28] INFO  o.e.j.s.NetworkTrafficServerConnector - Stopped NetworkTrafficServerConnector@7c3a3db0{HTTP/1.1}{localhost:58081}
2017-06-02 17:37:23 [pool-5-thread-28] INFO  o.e.j.server.handler.ContextHandler - Stopped o.e.j.s.ServletContextHandler@4452a6e0{/,null,UNAVAILABLE}
2017-06-02 17:37:23 [pool-5-thread-28] INFO  i.c.k.s.storage.KafkaSchemaRegistry - Shutting down schema registry
[2017-06-02 17:37:23,981] INFO [kafka-store-reader-thread-_schemas], Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
[2017-06-02 17:37:23,981] INFO [kafka-store-reader-thread-_schemas], Stopped  (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
[2017-06-02 17:37:23,982] INFO [kafka-store-reader-thread-_schemas], Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
2017-06-02 17:37:23 [pool-5-thread-28] INFO  i.c.k.s.s.KafkaStoreReaderThread - KafkaStoreReaderThread shutdown complete.
2017-06-02 17:37:23 [pool-5-thread-28] INFO  o.a.k.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-06-02 17:37:23 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e17e840001
2017-06-02 17:37:24 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /0:0:0:0:0:0:0:1:58000 which had sessionid 0x15c69e17e840001
2017-06-02 17:37:24 [pool-51-thread-3-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e17e840001
2017-06-02 17:37:24 [pool-5-thread-28] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e17e840001 closed
2017-06-02 17:37:24 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e17e840003
2017-06-02 17:37:24 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /127.0.0.1:40694 which had sessionid 0x15c69e17e840003
2017-06-02 17:37:24 [pool-5-thread-28] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e17e840003 closed
2017-06-02 17:37:24 [pool-51-thread-3-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e17e840003
2017-06-02 17:37:27 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e17e840000
2017-06-02 17:37:27 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /0:0:0:0:0:0:0:1:57984 which had sessionid 0x15c69e17e840000
2017-06-02 17:37:27 [pool-5-thread-28] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e17e840000 closed
2017-06-02 17:37:27 [pool-51-thread-2-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e17e840000
2017-06-02 17:37:29 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - NIOServerCnxn factory exited run method
2017-06-02 17:37:29 [pool-5-thread-28] INFO  o.a.zookeeper.server.ZooKeeperServer - shutting down
2017-06-02 17:37:29 [pool-5-thread-28] INFO  o.a.z.server.SessionTrackerImpl - Shutting down
2017-06-02 17:37:29 [pool-5-thread-28] INFO  o.a.z.server.PrepRequestProcessor - Shutting down
2017-06-02 17:37:29 [pool-5-thread-28] INFO  o.a.z.server.SyncRequestProcessor - Shutting down
2017-06-02 17:37:29 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - PrepRequestProcessor exited loop!
2017-06-02 17:37:29 [SyncThread:0] INFO  o.a.z.server.SyncRequestProcessor - SyncRequestProcessor exited!
2017-06-02 17:37:29 [pool-5-thread-28] INFO  o.a.z.server.FinalRequestProcessor - shutdown of request processor complete
2017-06-02 17:37:30 [SessionTracker] INFO  o.a.z.server.SessionTrackerImpl - SessionTrackerImpl exited loop!
2017-06-02 17:37:31 [pool-63-thread-1] INFO  o.a.z.server.ZooKeeperServerMain - Starting server
2017-06-02 17:37:31 [pool-63-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - tickTime set to 2000
2017-06-02 17:37:31 [pool-63-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - minSessionTimeout set to -1
2017-06-02 17:37:31 [pool-63-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - maxSessionTimeout set to -1
2017-06-02 17:37:31 [pool-63-thread-1] INFO  o.a.z.server.NIOServerCnxnFactory - binding to port 0.0.0.0/0.0.0.0:42181
2017-06-02 17:37:31 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:40846
2017-06-02 17:37:31 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] WARN  o.a.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x0, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_31]
2017-06-02 17:37:31 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /127.0.0.1:40846 (no session established for client)
2017-06-02 17:37:31 [pool-63-thread-2] INFO  kafka.server.KafkaConfig - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	default.replication.factor = 1
	delete.topic.enable = false
	fetch.purgatory.purge.interval.requests = 1000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.protocol.version = 0.10.1-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listeners = PLAINTEXT://:49092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /home/travis/build/dcshock/forklift/src/test/resources/zafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.10.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 16
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	unclean.leader.election.enable = true
	zookeeper.connect = localhost:42181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2017-06-02 17:37:31 [pool-63-thread-2] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@578bb0a2
2017-06-02 17:37:31 [pool-63-thread-2-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:37:31 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:40852
2017-06-02 17:37:31 [pool-63-thread-2-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/127.0.0.1:42181, initiating session
2017-06-02 17:37:31 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:40852
2017-06-02 17:37:31 [SyncThread:0] INFO  o.a.z.server.persistence.FileTxnLog - Creating new log file: log.1
2017-06-02 17:37:31 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e2337e0000 with negotiated timeout 6000 for client /127.0.0.1:40852
2017-06-02 17:37:31 [pool-63-thread-2-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:42181, sessionid = 0x15c69e2337e0000, negotiated timeout = 6000
2017-06-02 17:37:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x4 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2017-06-02 17:37:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0xa zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2017-06-02 17:37:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x12 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2017-06-02 17:37:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x1a zxid:0x11 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2017-06-02 17:37:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:setData cxid:0x22 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2017-06-02 17:37:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:delete cxid:0x33 zxid:0x17 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2017-06-02 17:37:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x3e zxid:0x18 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2017-06-02 17:37:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x3f zxid:0x19 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2017-06-02 17:37:31 [pool-63-thread-2] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:37:31 [pool-63-thread-2] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:37:33 [pool-63-thread-3] INFO  i.c.k.s.rest.SchemaRegistryConfig - SchemaRegistryConfig values: 
	metric.reporters = []
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	kafkastore.ssl.trustmanager.algorithm = PKIX
	authentication.realm = 
	ssl.keystore.type = JKS
	kafkastore.topic = _schemas
	metrics.jmx.prefix = kafka.schema.registry
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.topic.replication.factor = 3
	ssl.truststore.password = 
	kafkastore.timeout.ms = 500
	host.name = localhost
	kafkastore.bootstrap.servers = []
	schema.registry.zk.namespace = schema_registry
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.kerberos.service.name = 
	ssl.endpoint.identification.algorithm = 
	compression.enable = false
	kafkastore.ssl.truststore.type = JKS
	avro.compatibility.level = full
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.truststore.location = 
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	kafkastore.ssl.keystore.type = JKS
	ssl.truststore.type = JKS
	kafkastore.ssl.truststore.password = 
	access.control.allow.origin = 
	ssl.truststore.location = 
	ssl.keystore.password = 
	port = 8081
	kafkastore.ssl.keystore.location = 
	master.eligibility = true
	ssl.client.auth = false
	kafkastore.ssl.keystore.password = 
	kafkastore.security.protocol = PLAINTEXT
	ssl.trustmanager.algorithm = 
	authentication.method = NONE
	request.logger.name = io.confluent.rest-utils.requests
	ssl.key.password = 
	kafkastore.zk.session.timeout.ms = 30000
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.ssl.key.password = 
	zookeeper.set.acl = false
	authentication.roles = [*]
	metrics.num.samples = 2
	ssl.protocol = TLS
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.connection.url = localhost:42181
	debug = false
	listeners = [http://localhost:58081]
	ssl.provider = 
	ssl.enabled.protocols = []
	shutdown.graceful.ms = 1000
	ssl.keystore.location = 
	ssl.cipher.suites = []
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.cipher.suites = 
	access.control.allow.methods = 
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	ssl.keymanager.algorithm = 
	metrics.sample.window.ms = 30000
	kafkastore.init.timeout.ms = 60000

2017-06-02 17:37:33 [pool-63-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@b214efe
2017-06-02 17:37:33 [pool-63-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:37:33 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:40864
2017-06-02 17:37:33 [pool-63-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/127.0.0.1:42181, initiating session
2017-06-02 17:37:33 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:40864
2017-06-02 17:37:33 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e2337e0001 with negotiated timeout 30000 for client /127.0.0.1:40864
2017-06-02 17:37:33 [pool-63-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:42181, sessionid = 0x15c69e2337e0001, negotiated timeout = 30000
2017-06-02 17:37:33 [pool-63-thread-3] INFO  i.c.k.s.storage.KafkaStore - Initializing KafkaStore with broker endpoints: PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092
2017-06-02 17:37:33 [pool-63-thread-3] WARN  i.c.k.s.storage.KafkaStore - Creating the schema topic _schemas using a replication factor of 1, which is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic.
2017-06-02 17:37:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0001 type:setData cxid:0x8 zxid:0x1c txntype:-1 reqpath:n/a Error Path:/config/topics/_schemas Error:KeeperErrorCode = NoNode for /config/topics/_schemas
2017-06-02 17:37:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0001 type:create cxid:0x9 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:37:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x49 zxid:0x20 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_schemas/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_schemas/partitions/0
2017-06-02 17:37:33 [pool-63-thread-3] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2017-06-02 17:37:33 [pool-63-thread-3] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	buffer.memory = 33554432
	client.id = producer-19
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2017-06-02 17:37:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x4a zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_schemas/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_schemas/partitions
2017-06-02 17:37:33 [pool-63-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:37:33 [pool-63-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:37:33 [pool-63-thread-3] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	check.crcs = true
	client.id = KafkaStore-reader-_schemas
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = schema-registry-localhost-58081
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-06-02 17:37:33 [pool-63-thread-3] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	check.crcs = true
	client.id = KafkaStore-reader-_schemas
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = schema-registry-localhost-58081
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-06-02 17:37:33 [pool-63-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:37:33 [pool-63-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:37:33 [pool-63-thread-3] INFO  i.c.k.s.s.KafkaStoreReaderThread - Initialized last consumed offset to -1
[2017-06-02 17:37:33,507] INFO [kafka-store-reader-thread-_schemas], Starting  (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
2017-06-02 17:37:33 [pool-63-thread-3] INFO  i.c.k.s.storage.KafkaStore - Wait to catch up until the offset of the last message at 0
2017-06-02 17:37:33 [pool-63-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@32458894
2017-06-02 17:37:33 [pool-63-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:37:33 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:40884
2017-06-02 17:37:33 [pool-63-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/127.0.0.1:42181, initiating session
2017-06-02 17:37:33 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:40884
2017-06-02 17:37:33 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e2337e0002 with negotiated timeout 30000 for client /127.0.0.1:40884
2017-06-02 17:37:33 [pool-63-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:42181, sessionid = 0x15c69e2337e0002, negotiated timeout = 30000
2017-06-02 17:37:33 [pool-63-thread-3] INFO  i.c.k.s.storage.KafkaSchemaRegistry - Created schema registry namespace localhost:42181/schema_registry
2017-06-02 17:37:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e2337e0002
2017-06-02 17:37:33 [pool-63-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e2337e0002 closed
2017-06-02 17:37:33 [pool-63-thread-3-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e2337e0002
2017-06-02 17:37:33 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /127.0.0.1:40884 which had sessionid 0x15c69e2337e0002
2017-06-02 17:37:33 [pool-63-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181/schema_registry sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@1968fdb3
2017-06-02 17:37:33 [pool-63-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:37:33 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:40886
2017-06-02 17:37:33 [pool-63-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/127.0.0.1:42181, initiating session
2017-06-02 17:37:33 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:40886
2017-06-02 17:37:33 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e2337e0003 with negotiated timeout 30000 for client /127.0.0.1:40886
2017-06-02 17:37:33 [pool-63-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:42181, sessionid = 0x15c69e2337e0003, negotiated timeout = 30000
2017-06-02 17:37:33 [pool-63-thread-3] INFO  i.c.k.s.z.ZookeeperMasterElector - Successfully elected the new master: {"host":"localhost","port":58081,"master_eligibility":true,"version":1}
2017-06-02 17:37:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0003 type:create cxid:0x7 zxid:0x2b txntype:-1 reqpath:n/a Error Path:/schema_registry/schema_registry_master Error:KeeperErrorCode = NodeExists for /schema_registry/schema_registry_master
2017-06-02 17:37:33 [ZkClient-EventThread-1737-localhost:42181/schema_registry] INFO  i.c.k.s.z.ZookeeperMasterElector - Successfully elected the new master: {"host":"localhost","port":58081,"master_eligibility":true,"version":1}
2017-06-02 17:37:33 [pool-63-thread-3] INFO  io.confluent.rest.Application - Adding listener: http://localhost:58081
2017-06-02 17:37:33 [pool-63-thread-3] INFO  org.eclipse.jetty.server.Server - jetty-9.2.12.v20150709
2017-06-02 17:37:33 [pool-63-thread-3] INFO  o.e.j.server.handler.ContextHandler - Started o.e.j.s.ServletContextHandler@55d88373{/,null,AVAILABLE}
2017-06-02 17:37:34 [pool-63-thread-3] INFO  o.e.j.s.NetworkTrafficServerConnector - Started NetworkTrafficServerConnector@7192ad31{HTTP/1.1}{localhost:58081}
2017-06-02 17:37:34 [pool-63-thread-3] INFO  org.eclipse.jetty.server.Server - Started @358917ms
2017-06-02 17:37:35 [pool-5-thread-28] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:37:35 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:37:35 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:37:35 [pool-5-thread-28] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = producer-20
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:37:35 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:37:35 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:setData cxid:0x52 zxid:0x2c txntype:-1 reqpath:n/a Error Path:/config/topics/forklift-string-topic Error:KeeperErrorCode = NoNode for /config/topics/forklift-string-topic
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x53 zxid:0x2d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x6a zxid:0x30 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/3
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x6c zxid:0x31 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x71 zxid:0x35 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/14
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:setData cxid:0x74 zxid:0x37 txntype:-1 reqpath:n/a Error Path:/config/topics/forklift-map-topic Error:KeeperErrorCode = NoNode for /config/topics/forklift-map-topic
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x76 zxid:0x39 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x77 zxid:0x3a txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/12
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x7e zxid:0x3f txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/8
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x81 zxid:0x42 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/6
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:setData cxid:0x84 zxid:0x44 txntype:-1 reqpath:n/a Error Path:/config/topics/forklift-object-topic Error:KeeperErrorCode = NoNode for /config/topics/forklift-object-topic
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x86 zxid:0x46 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x87 zxid:0x47 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/7
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x8c zxid:0x4c txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/13
2017-06-02 17:37:35 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 0 : {forklift-string-topic=LEADER_NOT_AVAILABLE, forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x8f zxid:0x4f txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/10
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x92 zxid:0x52 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/5
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x95 zxid:0x55 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/2
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x98 zxid:0x58 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/4
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x9b zxid:0x5b txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/11
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x9e zxid:0x5e txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/15
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0xa1 zxid:0x61 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/1
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0xa4 zxid:0x64 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/9
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0xa7 zxid:0x67 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/0
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0xd8 zxid:0x6a txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/13
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0xd9 zxid:0x6b txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0xde zxid:0x6f txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/9
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0xdf zxid:0x70 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0xe5 zxid:0x74 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/7
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0xe9 zxid:0x77 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/3
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0xec zxid:0x7a txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/1
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0xf0 zxid:0x7d txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/15
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0xf3 zxid:0x80 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/13
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0xf6 zxid:0x83 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/14
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0xfa zxid:0x86 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/6
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0xfd zxid:0x89 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/3
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x102 zxid:0x8c txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/12
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x109 zxid:0x8f txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/11
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x10c zxid:0x92 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/6
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x112 zxid:0x95 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/11
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x116 zxid:0x98 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/9
2017-06-02 17:37:35 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 1 : {forklift-string-topic=LEADER_NOT_AVAILABLE, forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x11a zxid:0x9b txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/14
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x11d zxid:0x9e txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/8
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x120 zxid:0xa1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/1
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x123 zxid:0xa4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/4
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x126 zxid:0xa7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/10
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x129 zxid:0xaa txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/5
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x12c zxid:0xad txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/2
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x12f zxid:0xb0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/15
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x132 zxid:0xb3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/10
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x135 zxid:0xb6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/7
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x138 zxid:0xb9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/8
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x13b zxid:0xbc txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/5
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x13e zxid:0xbf txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/12
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x141 zxid:0xc2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/0
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x144 zxid:0xc5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/0
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x147 zxid:0xc8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-map-topic/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-map-topic/partitions/2
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x14a zxid:0xcb txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-object-topic/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-object-topic/partitions/4
2017-06-02 17:37:35 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 2 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:37:35 [qtp210294954-1746] INFO  i.c.k.s.storage.KafkaStore - Wait to catch up until the offset of the last message at 1
2017-06-02 17:37:35 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Starting Consumers for server: Server1
2017-06-02 17:37:35 [qtp210294954-1746] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:37:35 +0000] "POST /subjects/forklift-string-topic-value/versions HTTP/1.1" 200 8  86
2017-06-02 17:37:35 [pool-70-thread-4] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:37:35 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 3 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:37:35 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Starting Consumers for server: Server2
2017-06-02 17:37:35 [pool-70-thread-4] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = consumer-9
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:37:35 [pool-70-thread-4] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:37:35 [pool-70-thread-4] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:37:35 [pool-70-thread-7] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:37:35 [pool-70-thread-4] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:37:35 [pool-70-thread-4] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:37:35 [pool-70-thread-7] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = consumer-10
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:37:35 [pool-70-thread-7] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:37:35 [pool-70-thread-7] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:37:35 [pool-70-thread-7] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:37:35 [pool-70-thread-7] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:37:35 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Starting Consumers for server: Server3
2017-06-02 17:37:35 [pool-70-thread-10] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:37:35 [pool-70-thread-10] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = consumer-11
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:37:35 [pool-70-thread-10] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:37:35 [pool-70-thread-10] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:37:35 [kafka-producer-network-thread | producer-20] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 9 : {forklift-map-topic=LEADER_NOT_AVAILABLE, forklift-object-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:37:35 [pool-70-thread-10] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:37:35 [pool-70-thread-10] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:37:35 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Starting Consumers for server: Server4
2017-06-02 17:37:35 [pool-70-thread-13] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:37:35 [pool-70-thread-13] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = consumer-12
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:37:35 [pool-70-thread-13] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:37:35 [pool-70-thread-13] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:37:35 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Starting Consumers for server: Server5
2017-06-02 17:37:35 [pool-70-thread-13] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:37:35 [pool-70-thread-13] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:37:35 [pool-70-thread-16] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:setData cxid:0x183 zxid:0xce txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2017-06-02 17:37:35 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Starting Consumers for server: Server6
2017-06-02 17:37:35 [pool-70-thread-16] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = consumer-13
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:37:35 [pool-70-thread-16] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:37:35 [pool-70-thread-16] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:37:35 [pool-70-thread-19] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:37:35 [pool-70-thread-19] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = consumer-14
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:37:35 [pool-70-thread-19] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:37:35 [pool-70-thread-19] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:37:35 [pool-70-thread-19] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:37:35 [pool-70-thread-19] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:37:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x184 zxid:0xcf txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:37:35 [pool-70-thread-16] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:37:35 [pool-70-thread-16] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:37:35 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Starting Consumers for server: Server7
2017-06-02 17:37:35 [pool-70-thread-22] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:37:35 [pool-70-thread-22] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = consumer-15
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:37:35 [pool-70-thread-22] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:37:35 [pool-70-thread-22] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:37:35 [pool-70-thread-22] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:37:35 [pool-70-thread-22] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:37:35 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Starting Consumers for server: Server8
2017-06-02 17:37:35 [pool-70-thread-25] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:37:35 [pool-70-thread-25] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = consumer-16
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:37:35 [pool-70-thread-25] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:37:35 [pool-70-thread-25] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:37:35 [pool-70-thread-25] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:37:35 [pool-70-thread-25] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:37:35 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Starting Consumers for server: Server9
2017-06-02 17:37:35 [pool-70-thread-28] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:37:35 [pool-70-thread-28] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = consumer-17
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:37:35 [pool-70-thread-28] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:37:35 [pool-70-thread-28] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:37:35 [pool-70-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:37:35 [pool-70-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:37:35 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Starting Consumers for server: Server10
2017-06-02 17:37:35 [pool-70-thread-32] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x1c6 zxid:0xd2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2017-06-02 17:37:36 [pool-70-thread-32] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = consumer-18
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:37:36 [pool-70-thread-32] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:37:36 [pool-70-thread-32] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:37:36 [pool-70-thread-32] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:37:36 [pool-70-thread-32] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x1c7 zxid:0xd3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2017-06-02 17:37:36 [qtp210294954-1747] INFO  i.c.k.s.storage.KafkaStore - Wait to catch up until the offset of the last message at 2
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x1e2 zxid:0xd7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x1f1 zxid:0xda txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x206 zxid:0xdd txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x20a zxid:0xe0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x20d zxid:0xe3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x210 zxid:0xe6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x213 zxid:0xe9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x216 zxid:0xec txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2017-06-02 17:37:36 [qtp210294954-1747] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:37:36 +0000] "POST /subjects/forklift-map-topic-value/versions HTTP/1.1" 200 8  206
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x224 zxid:0xef txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2017-06-02 17:37:36 [qtp210294954-1748] INFO  i.c.k.s.storage.KafkaStore - Wait to catch up until the offset of the last message at 3
2017-06-02 17:37:36 [qtp210294954-1748] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:37:36 +0000] "POST /subjects/forklift-object-topic-value/versions HTTP/1.1" 200 8  59
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x23c zxid:0xf2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x250 zxid:0xf5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x25d zxid:0xf8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x26a zxid:0xfb txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x273 zxid:0xfe txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x276 zxid:0x101 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x279 zxid:0x104 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x27d zxid:0x107 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x281 zxid:0x10a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x288 zxid:0x10d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x28b zxid:0x110 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x28e zxid:0x113 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x29a zxid:0x116 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x29d zxid:0x119 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x2a6 zxid:0x11c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x2b0 zxid:0x11f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x2bb zxid:0x122 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x2be zxid:0x125 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x2c1 zxid:0x128 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x2c4 zxid:0x12b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x2c7 zxid:0x12e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x2ca zxid:0x131 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x2ce zxid:0x134 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x2d7 zxid:0x137 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x2dc zxid:0x13a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x2df zxid:0x13d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x2e2 zxid:0x140 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x2e5 zxid:0x143 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x2ee zxid:0x146 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x2fc zxid:0x149 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x303 zxid:0x14c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x306 zxid:0x14f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x309 zxid:0x152 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x30c zxid:0x155 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x30f zxid:0x158 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x312 zxid:0x15b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x31b zxid:0x15e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x321 zxid:0x161 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x324 zxid:0x164 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2017-06-02 17:37:36 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2337e0000 type:create cxid:0x327 zxid:0x167 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2017-06-02 17:37:37 [pool-80-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:37:37 [pool-80-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [] for group testGroup
2017-06-02 17:37:37 [pool-80-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:37:37 [pool-80-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Successfully joined group testGroup with generation 1
2017-06-02 17:37:37 [pool-80-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Setting newly assigned partitions [forklift-string-topic-14, forklift-string-topic-10, forklift-object-topic-2, forklift-string-topic-6, forklift-map-topic-12, forklift-string-topic-2, forklift-object-topic-3, forklift-map-topic-8, forklift-object-topic-7, forklift-map-topic-4, forklift-object-topic-11, forklift-map-topic-0, forklift-object-topic-15, forklift-string-topic-13, forklift-string-topic-9, forklift-object-topic-1, forklift-string-topic-5, forklift-object-topic-6, forklift-map-topic-15, forklift-string-topic-1, forklift-object-topic-10, forklift-map-topic-11, forklift-object-topic-14, forklift-map-topic-7, forklift-map-topic-3, forklift-string-topic-12, forklift-string-topic-8, forklift-object-topic-0, forklift-string-topic-4, forklift-object-topic-5, forklift-map-topic-14, forklift-string-topic-0, forklift-object-topic-9, forklift-map-topic-10, forklift-object-topic-13, forklift-map-topic-6, forklift-map-topic-2, forklift-string-topic-15, forklift-string-topic-11, forklift-string-topic-7, forklift-map-topic-13, forklift-string-topic-3, forklift-object-topic-4, forklift-map-topic-9, forklift-object-topic-8, forklift-map-topic-5, forklift-object-topic-12, forklift-map-topic-1] for group testGroup
2017-06-02 17:37:37 [pool-76-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:37:37 [pool-77-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:37:37 [pool-76-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [] for group testGroup
2017-06-02 17:37:37 [pool-74-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:37:37 [pool-76-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:37:37 [pool-75-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:37:37 [pool-77-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [] for group testGroup
2017-06-02 17:37:37 [pool-77-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:37:37 [pool-74-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [] for group testGroup
2017-06-02 17:37:37 [pool-74-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:37:37 [pool-75-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [] for group testGroup
2017-06-02 17:37:37 [pool-75-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:37:37 [pool-73-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:37:37 [pool-71-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:37:37 [pool-73-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [] for group testGroup
2017-06-02 17:37:37 [pool-73-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:37:37 [pool-72-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:37:37 [pool-79-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:37:37 [pool-72-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [] for group testGroup
2017-06-02 17:37:37 [pool-72-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:37:37 [pool-79-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [] for group testGroup
2017-06-02 17:37:37 [pool-79-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:37:37 [pool-71-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [] for group testGroup
2017-06-02 17:37:37 [pool-71-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:37:37 [pool-78-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:37:37 [pool-78-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [] for group testGroup
2017-06-02 17:37:37 [pool-78-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:37:37 [qtp210294954-1745] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:37:37 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 552  21
2017-06-02 17:37:40 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Stopping Consumers for server: Server1
2017-06-02 17:37:40 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:40 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:40 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:40 [pool-71-thread-1] INFO  forklift.controller.KafkaController - Wakeup, controlLoop exiting
2017-06-02 17:37:40 [pool-71-thread-1] INFO  forklift.controller.KafkaController - closing offset size committed: 0
2017-06-02 17:37:40 [pool-71-thread-1] INFO  forklift.controller.KafkaController - controlLoop closing kafkaConsumer
2017-06-02 17:37:40 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Stopping Consumers for server: Server2
2017-06-02 17:37:40 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:40 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:40 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:40 [pool-72-thread-1] INFO  forklift.controller.KafkaController - Wakeup, controlLoop exiting
2017-06-02 17:37:40 [pool-72-thread-1] INFO  forklift.controller.KafkaController - closing offset size committed: 0
2017-06-02 17:37:40 [pool-72-thread-1] INFO  forklift.controller.KafkaController - controlLoop closing kafkaConsumer
2017-06-02 17:37:40 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Stopping Consumers for server: Server3
2017-06-02 17:37:40 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:40 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:40 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:40 [pool-73-thread-1] INFO  forklift.controller.KafkaController - Wakeup, controlLoop exiting
2017-06-02 17:37:40 [pool-73-thread-1] INFO  forklift.controller.KafkaController - closing offset size committed: 0
2017-06-02 17:37:40 [pool-73-thread-1] INFO  forklift.controller.KafkaController - controlLoop closing kafkaConsumer
2017-06-02 17:37:40 [pool-80-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [forklift-string-topic-14, forklift-string-topic-10, forklift-object-topic-2, forklift-string-topic-6, forklift-map-topic-12, forklift-string-topic-2, forklift-object-topic-3, forklift-map-topic-8, forklift-object-topic-7, forklift-map-topic-4, forklift-object-topic-11, forklift-map-topic-0, forklift-object-topic-15, forklift-string-topic-13, forklift-string-topic-9, forklift-object-topic-1, forklift-string-topic-5, forklift-object-topic-6, forklift-map-topic-15, forklift-string-topic-1, forklift-object-topic-10, forklift-map-topic-11, forklift-object-topic-14, forklift-map-topic-7, forklift-map-topic-3, forklift-string-topic-12, forklift-string-topic-8, forklift-object-topic-0, forklift-string-topic-4, forklift-object-topic-5, forklift-map-topic-14, forklift-string-topic-0, forklift-object-topic-9, forklift-map-topic-10, forklift-object-topic-13, forklift-map-topic-6, forklift-map-topic-2, forklift-string-topic-15, forklift-string-topic-11, forklift-string-topic-7, forklift-map-topic-13, forklift-string-topic-3, forklift-object-topic-4, forklift-map-topic-9, forklift-object-topic-8, forklift-map-topic-5, forklift-object-topic-12, forklift-map-topic-1] for group testGroup
2017-06-02 17:37:40 [pool-80-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:37:40 [pool-77-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Successfully joined group testGroup with generation 2
2017-06-02 17:37:40 [pool-77-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Setting newly assigned partitions [forklift-map-topic-9, forklift-object-topic-10, forklift-object-topic-9, forklift-map-topic-11, forklift-map-topic-10, forklift-string-topic-11, forklift-string-topic-10, forklift-object-topic-11] for group testGroup
2017-06-02 17:37:40 [pool-79-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Successfully joined group testGroup with generation 2
2017-06-02 17:37:40 [pool-79-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Setting newly assigned partitions [forklift-string-topic-13] for group testGroup
2017-06-02 17:37:40 [pool-79-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [forklift-string-topic-13] for group testGroup
2017-06-02 17:37:41 [pool-79-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:37:41 [pool-74-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Successfully joined group testGroup with generation 2
2017-06-02 17:37:41 [pool-74-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Setting newly assigned partitions [forklift-string-topic-4, forklift-string-topic-5] for group testGroup
2017-06-02 17:37:40 [pool-76-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Successfully joined group testGroup with generation 2
2017-06-02 17:37:41 [pool-76-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Setting newly assigned partitions [forklift-object-topic-5, forklift-object-topic-4, forklift-object-topic-3, forklift-map-topic-5, forklift-map-topic-4, forklift-string-topic-7, forklift-map-topic-3, forklift-string-topic-6] for group testGroup
2017-06-02 17:37:40 [pool-75-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Successfully joined group testGroup with generation 2
2017-06-02 17:37:41 [pool-75-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Setting newly assigned partitions [forklift-object-topic-6, forklift-map-topic-8, forklift-object-topic-8, forklift-object-topic-7, forklift-map-topic-7, forklift-map-topic-6, forklift-string-topic-9, forklift-string-topic-8] for group testGroup
2017-06-02 17:37:41 [pool-78-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Successfully joined group testGroup with generation 2
2017-06-02 17:37:41 [pool-78-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Setting newly assigned partitions [forklift-map-topic-13, forklift-map-topic-12, forklift-string-topic-12, forklift-object-topic-13, forklift-object-topic-12] for group testGroup
2017-06-02 17:37:41 [pool-80-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Successfully joined group testGroup with generation 2
2017-06-02 17:37:41 [pool-80-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Setting newly assigned partitions [forklift-map-topic-15, forklift-map-topic-14, forklift-string-topic-14, forklift-object-topic-14, forklift-object-topic-15] for group testGroup
2017-06-02 17:37:41 [pool-74-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [forklift-string-topic-4, forklift-string-topic-5] for group testGroup
2017-06-02 17:37:41 [pool-74-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:37:41 [qtp210294954-1746] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:37:40 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 552  35
2017-06-02 17:37:41 [pool-70-thread-24] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:37:41 [pool-70-thread-24] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:37:41 [pool-70-thread-24] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:37:41 [pool-70-thread-24] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = producer-21
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:37:41 [qtp210294954-1747] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:37:41 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 552  28
2017-06-02 17:37:41 [qtp210294954-1745] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:37:41 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 552  3
2017-06-02 17:37:41 [qtp210294954-1746] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:37:41 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 552  34
2017-06-02 17:37:41 [pool-70-thread-24] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:37:41 [pool-70-thread-24] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:37:41 [pool-70-thread-20] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:37:41 [pool-70-thread-20] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:37:41 [pool-70-thread-20] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:37:41 [pool-70-thread-20] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = producer-22
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:37:41 [pool-70-thread-25] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:37:41 [pool-70-thread-25] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:37:41 [pool-70-thread-25] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:37:41 [pool-70-thread-20] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:37:41 [pool-70-thread-20] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:37:41 [pool-70-thread-18] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:37:41 [pool-70-thread-18] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:37:41 [pool-70-thread-18] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:37:41 [pool-70-thread-18] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = producer-24
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:37:41 [pool-70-thread-25] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = producer-23
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:37:41 [pool-70-thread-25] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:37:41 [pool-70-thread-25] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:37:41 [pool-70-thread-18] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:37:41 [pool-70-thread-18] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:37:44 [pool-80-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [forklift-map-topic-15, forklift-map-topic-14, forklift-string-topic-14, forklift-object-topic-14, forklift-object-topic-15] for group testGroup
2017-06-02 17:37:44 [pool-80-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:37:44 [pool-78-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [forklift-map-topic-13, forklift-map-topic-12, forklift-string-topic-12, forklift-object-topic-13, forklift-object-topic-12] for group testGroup
2017-06-02 17:37:44 [pool-78-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:37:44 [pool-75-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [forklift-object-topic-6, forklift-map-topic-8, forklift-object-topic-8, forklift-object-topic-7, forklift-map-topic-7, forklift-map-topic-6, forklift-string-topic-9, forklift-string-topic-8] for group testGroup
2017-06-02 17:37:44 [pool-75-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:37:44 [pool-77-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [forklift-map-topic-9, forklift-object-topic-10, forklift-object-topic-9, forklift-map-topic-11, forklift-map-topic-10, forklift-string-topic-11, forklift-string-topic-10, forklift-object-topic-11] for group testGroup
2017-06-02 17:37:44 [pool-77-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:37:44 [pool-76-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [forklift-object-topic-5, forklift-object-topic-4, forklift-object-topic-3, forklift-map-topic-5, forklift-map-topic-4, forklift-string-topic-7, forklift-map-topic-3, forklift-string-topic-6] for group testGroup
2017-06-02 17:37:44 [pool-76-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:37:45 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Stopping Consumers for server: Server4
2017-06-02 17:37:45 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:45 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:45 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:45 [pool-74-thread-1] INFO  forklift.controller.KafkaController - Wakeup, controlLoop exiting
2017-06-02 17:37:45 [pool-74-thread-1] INFO  forklift.controller.KafkaController - closing offset size committed: 0
2017-06-02 17:37:45 [pool-74-thread-1] INFO  forklift.controller.KafkaController - controlLoop closing kafkaConsumer
2017-06-02 17:37:45 [pool-74-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:37:45 [pool-74-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:37:45 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Stopping Consumers for server: Server5
2017-06-02 17:37:45 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:45 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:45 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:45 [pool-76-thread-1] INFO  forklift.controller.KafkaController - Wakeup, controlLoop exiting
2017-06-02 17:37:45 [pool-76-thread-1] INFO  forklift.controller.KafkaController - closing offset size committed: 0
2017-06-02 17:37:45 [pool-76-thread-1] INFO  forklift.controller.KafkaController - controlLoop closing kafkaConsumer
2017-06-02 17:37:45 [pool-76-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:37:45 [pool-76-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:37:45 [pool-5-thread-28] INFO  o.a.k.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-06-02 17:37:45 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Stopping Consumers for server: Server6
2017-06-02 17:37:45 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:45 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:45 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:45 [pool-75-thread-1] INFO  forklift.controller.KafkaController - Wakeup, controlLoop exiting
2017-06-02 17:37:45 [pool-75-thread-1] INFO  forklift.controller.KafkaController - closing offset size committed: 0
2017-06-02 17:37:45 [pool-75-thread-1] INFO  forklift.controller.KafkaController - controlLoop closing kafkaConsumer
2017-06-02 17:37:45 [pool-75-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:37:45 [pool-75-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:37:45 [pool-5-thread-28] INFO  o.a.k.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-06-02 17:37:50 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Stopping Consumers for server: Server7
2017-06-02 17:37:50 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:50 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:50 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:50 [pool-77-thread-1] INFO  forklift.controller.KafkaController - Wakeup, controlLoop exiting
2017-06-02 17:37:50 [pool-77-thread-1] INFO  forklift.controller.KafkaController - closing offset size committed: 0
2017-06-02 17:37:50 [pool-77-thread-1] INFO  forklift.controller.KafkaController - controlLoop closing kafkaConsumer
2017-06-02 17:37:50 [pool-77-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:37:50 [pool-77-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:37:50 [pool-5-thread-28] INFO  o.a.k.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-06-02 17:37:50 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Stopping Consumers for server: Server8
2017-06-02 17:37:50 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:50 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:50 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:50 [pool-78-thread-1] INFO  forklift.controller.KafkaController - Wakeup, controlLoop exiting
2017-06-02 17:37:50 [pool-78-thread-1] INFO  forklift.controller.KafkaController - closing offset size committed: 0
2017-06-02 17:37:50 [pool-78-thread-1] INFO  forklift.controller.KafkaController - controlLoop closing kafkaConsumer
2017-06-02 17:37:50 [pool-78-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:37:50 [pool-78-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:37:50 [pool-5-thread-28] INFO  o.a.k.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-06-02 17:37:50 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Stopping Consumers for server: Server9
2017-06-02 17:37:50 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:50 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:50 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:37:50 [pool-79-thread-1] INFO  forklift.controller.KafkaController - Wakeup, controlLoop exiting
2017-06-02 17:37:50 [pool-79-thread-1] INFO  forklift.controller.KafkaController - closing offset size committed: 0
2017-06-02 17:37:50 [pool-79-thread-1] INFO  forklift.controller.KafkaController - controlLoop closing kafkaConsumer
2017-06-02 17:37:50 [pool-79-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:37:50 [pool-79-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:37:50 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Waiting: 0
2017-06-02 17:37:50 [pool-80-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Successfully joined group testGroup with generation 3
2017-06-02 17:37:50 [pool-80-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Setting newly assigned partitions [forklift-map-topic-15, forklift-map-topic-14, forklift-string-topic-15, forklift-string-topic-14, forklift-object-topic-14, forklift-object-topic-15] for group testGroup
2017-06-02 17:37:51 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Waiting: 1
2017-06-02 17:37:52 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Waiting: 2
2017-06-02 17:37:53 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Waiting: 3
2017-06-02 17:37:54 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Waiting: 4
2017-06-02 17:37:55 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Waiting: 5
2017-06-02 17:37:56 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Waiting: 6
2017-06-02 17:37:57 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Waiting: 7
2017-06-02 17:37:58 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Waiting: 8
2017-06-02 17:37:59 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Waiting: 9
2017-06-02 17:38:00 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Waiting: 10
2017-06-02 17:38:01 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Waiting: 11
2017-06-02 17:38:02 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Waiting: 12
2017-06-02 17:38:03 [pool-80-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [forklift-map-topic-15, forklift-map-topic-14, forklift-string-topic-15, forklift-string-topic-14, forklift-object-topic-14, forklift-object-topic-15] for group testGroup
2017-06-02 17:38:03 [pool-80-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:38:03 [pool-80-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Successfully joined group testGroup with generation 4
2017-06-02 17:38:03 [pool-80-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Setting newly assigned partitions [forklift-string-topic-14, forklift-string-topic-10, forklift-object-topic-2, forklift-string-topic-6, forklift-map-topic-12, forklift-string-topic-2, forklift-object-topic-3, forklift-map-topic-8, forklift-object-topic-7, forklift-map-topic-4, forklift-object-topic-11, forklift-map-topic-0, forklift-object-topic-15, forklift-string-topic-13, forklift-string-topic-9, forklift-object-topic-1, forklift-string-topic-5, forklift-object-topic-6, forklift-map-topic-15, forklift-string-topic-1, forklift-object-topic-10, forklift-map-topic-11, forklift-object-topic-14, forklift-map-topic-7, forklift-map-topic-3, forklift-string-topic-12, forklift-string-topic-8, forklift-object-topic-0, forklift-string-topic-4, forklift-object-topic-5, forklift-map-topic-14, forklift-string-topic-0, forklift-object-topic-9, forklift-map-topic-10, forklift-object-topic-13, forklift-map-topic-6, forklift-map-topic-2, forklift-string-topic-15, forklift-string-topic-11, forklift-string-topic-7, forklift-map-topic-13, forklift-string-topic-3, forklift-object-topic-4, forklift-map-topic-9, forklift-object-topic-8, forklift-map-topic-5, forklift-object-topic-12, forklift-map-topic-1] for group testGroup
2017-06-02 17:38:03 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - Waiting: 13
2017-06-02 17:38:04 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - SentIds: 2989 consumedIds: 2989
2017-06-02 17:38:04 [pool-80-thread-1] INFO  forklift.controller.KafkaController - Wakeup, controlLoop exiting
2017-06-02 17:38:04 [pool-80-thread-1] INFO  forklift.controller.KafkaController - closing offset size committed: 42
2017-06-02 17:38:04 [pool-80-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:38:05 [pool-80-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:38:05 [pool-80-thread-1] INFO  forklift.controller.KafkaController - controlLoop closing kafkaConsumer
2017-06-02 17:38:05 [pool-5-thread-28] INFO  o.a.k.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-06-02 17:38:05 [pool-5-thread-28] INFO  o.e.j.s.NetworkTrafficServerConnector - Stopped NetworkTrafficServerConnector@7192ad31{HTTP/1.1}{localhost:58081}
2017-06-02 17:38:05 [pool-5-thread-28] INFO  o.e.j.server.handler.ContextHandler - Stopped o.e.j.s.ServletContextHandler@55d88373{/,null,UNAVAILABLE}
2017-06-02 17:38:05 [pool-5-thread-28] INFO  i.c.k.s.storage.KafkaSchemaRegistry - Shutting down schema registry
[2017-06-02 17:38:05,131] INFO [kafka-store-reader-thread-_schemas], Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
[2017-06-02 17:38:05,134] INFO [kafka-store-reader-thread-_schemas], Stopped  (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
[2017-06-02 17:38:05,134] INFO [kafka-store-reader-thread-_schemas], Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
2017-06-02 17:38:05 [pool-5-thread-28] INFO  i.c.k.s.s.KafkaStoreReaderThread - KafkaStoreReaderThread shutdown complete.
2017-06-02 17:38:05 [pool-5-thread-28] INFO  o.a.k.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-06-02 17:38:05 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e2337e0001
2017-06-02 17:38:05 [pool-5-thread-28] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e2337e0001 closed
2017-06-02 17:38:05 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /127.0.0.1:40864 which had sessionid 0x15c69e2337e0001
2017-06-02 17:38:05 [pool-63-thread-3-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e2337e0001
2017-06-02 17:38:05 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e2337e0003
2017-06-02 17:38:05 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /127.0.0.1:40886 which had sessionid 0x15c69e2337e0003
2017-06-02 17:38:05 [pool-5-thread-28] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e2337e0003 closed
2017-06-02 17:38:05 [pool-63-thread-3-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e2337e0003
2017-06-02 17:38:06 [pool-70-thread-31] ERROR forklift.consumer.Consumer - JMS Error in message loop: 
forklift.connectors.ConnectorException: Connection to Kafka Controller lost
	at forklift.consumer.KafkaTopicConsumer.receive(KafkaTopicConsumer.java:41) ~[classes/:na]
	at forklift.consumer.Consumer.messageLoop(Consumer.java:253) [classes/:na]
	at forklift.consumer.Consumer.listen(Consumer.java:233) [classes/:na]
	at forklift.integration.RebalanceTests$ForkliftServer.lambda$startConsumers$6(RebalanceTests.java:205) [test-classes/:na]
	at forklift.integration.RebalanceTests$ForkliftServer$$Lambda$187/809710382.run(Unknown Source) [test-classes/:na]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_31]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_31]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_31]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_31]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_31]
2017-06-02 17:38:06 [pool-70-thread-32] ERROR forklift.consumer.Consumer - JMS Error in message loop: 
forklift.connectors.ConnectorException: Connection to Kafka Controller lost
	at forklift.consumer.KafkaTopicConsumer.receive(KafkaTopicConsumer.java:41) ~[classes/:na]
	at forklift.consumer.Consumer.messageLoop(Consumer.java:253) [classes/:na]
	at forklift.consumer.Consumer.listen(Consumer.java:233) [classes/:na]
	at forklift.integration.RebalanceTests$ForkliftServer.lambda$startConsumers$6(RebalanceTests.java:205) [test-classes/:na]
	at forklift.integration.RebalanceTests$ForkliftServer$$Lambda$187/809710382.run(Unknown Source) [test-classes/:na]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_31]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_31]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_31]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_31]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_31]
2017-06-02 17:38:06 [pool-70-thread-33] ERROR forklift.consumer.Consumer - JMS Error in message loop: 
forklift.connectors.ConnectorException: Connection to Kafka Controller lost
	at forklift.consumer.KafkaTopicConsumer.receive(KafkaTopicConsumer.java:41) ~[classes/:na]
	at forklift.consumer.Consumer.messageLoop(Consumer.java:253) [classes/:na]
	at forklift.consumer.Consumer.listen(Consumer.java:233) [classes/:na]
	at forklift.integration.RebalanceTests$ForkliftServer.lambda$startConsumers$6(RebalanceTests.java:205) [test-classes/:na]
	at forklift.integration.RebalanceTests$ForkliftServer$$Lambda$187/809710382.run(Unknown Source) [test-classes/:na]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_31]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_31]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_31]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_31]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_31]
2017-06-02 17:38:07 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e2337e0000
2017-06-02 17:38:07 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /127.0.0.1:40852 which had sessionid 0x15c69e2337e0000
2017-06-02 17:38:07 [pool-5-thread-28] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e2337e0000 closed
2017-06-02 17:38:07 [pool-63-thread-2-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e2337e0000
2017-06-02 17:38:09 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - NIOServerCnxn factory exited run method
2017-06-02 17:38:09 [pool-5-thread-28] INFO  o.a.zookeeper.server.ZooKeeperServer - shutting down
2017-06-02 17:38:09 [pool-5-thread-28] INFO  o.a.z.server.SessionTrackerImpl - Shutting down
2017-06-02 17:38:09 [pool-5-thread-28] INFO  o.a.z.server.PrepRequestProcessor - Shutting down
2017-06-02 17:38:09 [pool-5-thread-28] INFO  o.a.z.server.SyncRequestProcessor - Shutting down
2017-06-02 17:38:09 [SyncThread:0] INFO  o.a.z.server.SyncRequestProcessor - SyncRequestProcessor exited!
2017-06-02 17:38:09 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - PrepRequestProcessor exited loop!
2017-06-02 17:38:09 [pool-5-thread-28] INFO  o.a.z.server.FinalRequestProcessor - shutdown of request processor complete
2017-06-02 17:38:10 [SessionTracker] INFO  o.a.z.server.SessionTrackerImpl - SessionTrackerImpl exited loop!
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest forklift.integration.[33mRebalanceTests[0m.[36mtestRebalanceUnderLoad[0m started[0m
[0m[[0minfo[0m] [0mTest forklift.integration.[33mRebalanceTests[0m.[36mtestMultipleConcurrentRebalancing[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 2 total, 86.165s[0m[0m
2017-06-02 17:38:10 [pool-82-thread-1] INFO  o.a.z.server.ZooKeeperServerMain - Starting server
2017-06-02 17:38:10 [pool-82-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - tickTime set to 2000
2017-06-02 17:38:10 [pool-82-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - minSessionTimeout set to -1
2017-06-02 17:38:10 [pool-82-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - maxSessionTimeout set to -1
2017-06-02 17:38:10 [pool-82-thread-1] INFO  o.a.z.server.NIOServerCnxnFactory - binding to port 0.0.0.0/0.0.0.0:42181
2017-06-02 17:38:10 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:41020
2017-06-02 17:38:10 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] WARN  o.a.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x0, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_31]
2017-06-02 17:38:10 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /127.0.0.1:41020 (no session established for client)
2017-06-02 17:38:10 [pool-82-thread-2] INFO  kafka.server.KafkaConfig - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	default.replication.factor = 1
	delete.topic.enable = false
	fetch.purgatory.purge.interval.requests = 1000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.protocol.version = 0.10.1-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listeners = PLAINTEXT://:49092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /home/travis/build/dcshock/forklift/src/test/resources/zafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.10.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 16
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	unclean.leader.election.enable = true
	zookeeper.connect = localhost:42181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2017-06-02 17:38:10 [pool-82-thread-2] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@4a42d155
2017-06-02 17:38:10 [pool-82-thread-2-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:38:10 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /0:0:0:0:0:0:0:1:58356
2017-06-02 17:38:10 [pool-82-thread-2-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/0:0:0:0:0:0:0:1:42181, initiating session
2017-06-02 17:38:10 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /0:0:0:0:0:0:0:1:58356
2017-06-02 17:38:10 [SyncThread:0] INFO  o.a.z.server.persistence.FileTxnLog - Creating new log file: log.1
2017-06-02 17:38:10 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e2cf370000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:58356
2017-06-02 17:38:10 [pool-82-thread-2-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:42181, sessionid = 0x15c69e2cf370000, negotiated timeout = 6000
2017-06-02 17:38:10 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x4 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2017-06-02 17:38:11 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0xa zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2017-06-02 17:38:11 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x12 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2017-06-02 17:38:11 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x1a zxid:0x11 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2017-06-02 17:38:11 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:setData cxid:0x24 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2017-06-02 17:38:11 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:delete cxid:0x33 zxid:0x17 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2017-06-02 17:38:11 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x3e zxid:0x18 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2017-06-02 17:38:11 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x3f zxid:0x19 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2017-06-02 17:38:11 [pool-82-thread-2] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:38:11 [pool-82-thread-2] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:38:13 [pool-82-thread-3] INFO  i.c.k.s.rest.SchemaRegistryConfig - SchemaRegistryConfig values: 
	metric.reporters = []
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	kafkastore.ssl.trustmanager.algorithm = PKIX
	authentication.realm = 
	ssl.keystore.type = JKS
	kafkastore.topic = _schemas
	metrics.jmx.prefix = kafka.schema.registry
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.topic.replication.factor = 3
	ssl.truststore.password = 
	kafkastore.timeout.ms = 500
	host.name = localhost
	kafkastore.bootstrap.servers = []
	schema.registry.zk.namespace = schema_registry
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.kerberos.service.name = 
	ssl.endpoint.identification.algorithm = 
	compression.enable = false
	kafkastore.ssl.truststore.type = JKS
	avro.compatibility.level = full
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.truststore.location = 
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	kafkastore.ssl.keystore.type = JKS
	ssl.truststore.type = JKS
	kafkastore.ssl.truststore.password = 
	access.control.allow.origin = 
	ssl.truststore.location = 
	ssl.keystore.password = 
	port = 8081
	kafkastore.ssl.keystore.location = 
	master.eligibility = true
	ssl.client.auth = false
	kafkastore.ssl.keystore.password = 
	kafkastore.security.protocol = PLAINTEXT
	ssl.trustmanager.algorithm = 
	authentication.method = NONE
	request.logger.name = io.confluent.rest-utils.requests
	ssl.key.password = 
	kafkastore.zk.session.timeout.ms = 30000
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.ssl.key.password = 
	zookeeper.set.acl = false
	authentication.roles = [*]
	metrics.num.samples = 2
	ssl.protocol = TLS
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.connection.url = localhost:42181
	debug = false
	listeners = [http://localhost:58081]
	ssl.provider = 
	ssl.enabled.protocols = []
	shutdown.graceful.ms = 1000
	ssl.keystore.location = 
	ssl.cipher.suites = []
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.cipher.suites = 
	access.control.allow.methods = 
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	ssl.keymanager.algorithm = 
	metrics.sample.window.ms = 30000
	kafkastore.init.timeout.ms = 60000

2017-06-02 17:38:13 [pool-82-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@5d9d986c
2017-06-02 17:38:13 [pool-82-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:38:13 [pool-82-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/0:0:0:0:0:0:0:1:42181, initiating session
2017-06-02 17:38:13 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /0:0:0:0:0:0:0:1:58372
2017-06-02 17:38:13 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /0:0:0:0:0:0:0:1:58372
2017-06-02 17:38:13 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e2cf370001 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:58372
2017-06-02 17:38:13 [pool-82-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:42181, sessionid = 0x15c69e2cf370001, negotiated timeout = 30000
2017-06-02 17:38:13 [pool-82-thread-3] INFO  i.c.k.s.storage.KafkaStore - Initializing KafkaStore with broker endpoints: PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092
2017-06-02 17:38:13 [pool-82-thread-3] WARN  i.c.k.s.storage.KafkaStore - Creating the schema topic _schemas using a replication factor of 1, which is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic.
2017-06-02 17:38:13 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370001 type:setData cxid:0x8 zxid:0x1c txntype:-1 reqpath:n/a Error Path:/config/topics/_schemas Error:KeeperErrorCode = NoNode for /config/topics/_schemas
2017-06-02 17:38:13 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370001 type:create cxid:0x9 zxid:0x1d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:38:13 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x49 zxid:0x20 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_schemas/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_schemas/partitions/0
2017-06-02 17:38:13 [pool-82-thread-3] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2017-06-02 17:38:13 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x4a zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_schemas/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_schemas/partitions
2017-06-02 17:38:13 [pool-82-thread-3] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	buffer.memory = 33554432
	client.id = producer-25
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2017-06-02 17:38:13 [pool-82-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:38:13 [pool-82-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:38:13 [pool-82-thread-3] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	check.crcs = true
	client.id = KafkaStore-reader-_schemas
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = schema-registry-localhost-58081
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-06-02 17:38:13 [pool-82-thread-3] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	check.crcs = true
	client.id = KafkaStore-reader-_schemas
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = schema-registry-localhost-58081
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-06-02 17:38:13 [pool-82-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:38:13 [pool-82-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:38:13 [pool-82-thread-3] INFO  i.c.k.s.s.KafkaStoreReaderThread - Initialized last consumed offset to -1
[2017-06-02 17:38:13,334] INFO [kafka-store-reader-thread-_schemas], Starting  (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
2017-06-02 17:38:13 [pool-82-thread-3] INFO  i.c.k.s.storage.KafkaStore - Wait to catch up until the offset of the last message at 0
2017-06-02 17:38:13 [pool-82-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@4387587d
2017-06-02 17:38:13 [pool-82-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:38:13 [pool-82-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/0:0:0:0:0:0:0:1:42181, initiating session
2017-06-02 17:38:13 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /0:0:0:0:0:0:0:1:58394
2017-06-02 17:38:13 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /0:0:0:0:0:0:0:1:58394
2017-06-02 17:38:13 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e2cf370002 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:58394
2017-06-02 17:38:13 [pool-82-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:42181, sessionid = 0x15c69e2cf370002, negotiated timeout = 30000
2017-06-02 17:38:13 [pool-82-thread-3] INFO  i.c.k.s.storage.KafkaSchemaRegistry - Created schema registry namespace localhost:42181/schema_registry
2017-06-02 17:38:13 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e2cf370002
2017-06-02 17:38:13 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /0:0:0:0:0:0:0:1:58394 which had sessionid 0x15c69e2cf370002
2017-06-02 17:38:13 [pool-82-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e2cf370002 closed
2017-06-02 17:38:13 [pool-82-thread-3-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e2cf370002
2017-06-02 17:38:13 [pool-82-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181/schema_registry sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@2f6d63af
2017-06-02 17:38:13 [pool-82-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:38:13 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /0:0:0:0:0:0:0:1:58398
2017-06-02 17:38:13 [pool-82-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/0:0:0:0:0:0:0:1:42181, initiating session
2017-06-02 17:38:13 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /0:0:0:0:0:0:0:1:58398
2017-06-02 17:38:13 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e2cf370003 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:58398
2017-06-02 17:38:13 [pool-82-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:42181, sessionid = 0x15c69e2cf370003, negotiated timeout = 30000
2017-06-02 17:38:13 [pool-82-thread-3] INFO  i.c.k.s.z.ZookeeperMasterElector - Successfully elected the new master: {"host":"localhost","port":58081,"master_eligibility":true,"version":1}
2017-06-02 17:38:13 [pool-82-thread-3] INFO  io.confluent.rest.Application - Adding listener: http://localhost:58081
2017-06-02 17:38:13 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370003 type:create cxid:0x7 zxid:0x2b txntype:-1 reqpath:n/a Error Path:/schema_registry/schema_registry_master Error:KeeperErrorCode = NodeExists for /schema_registry/schema_registry_master
2017-06-02 17:38:13 [ZkClient-EventThread-1868-localhost:42181/schema_registry] INFO  i.c.k.s.z.ZookeeperMasterElector - Successfully elected the new master: {"host":"localhost","port":58081,"master_eligibility":true,"version":1}
2017-06-02 17:38:13 [pool-82-thread-3] INFO  org.eclipse.jetty.server.Server - jetty-9.2.12.v20150709
2017-06-02 17:38:14 [pool-82-thread-3] INFO  o.e.j.server.handler.ContextHandler - Started o.e.j.s.ServletContextHandler@32aae7dd{/,null,AVAILABLE}
2017-06-02 17:38:14 [pool-82-thread-3] INFO  o.e.j.s.NetworkTrafficServerConnector - Started NetworkTrafficServerConnector@2b502796{HTTP/1.1}{localhost:58081}
2017-06-02 17:38:14 [pool-82-thread-3] INFO  org.eclipse.jetty.server.Server - Started @399030ms
2017-06-02 17:38:15 [pool-5-thread-28] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:38:15 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:38:15 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:38:15 [pool-5-thread-28] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = producer-26
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:38:15 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:38:15 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:38:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:setData cxid:0x52 zxid:0x2c txntype:-1 reqpath:n/a Error Path:/config/topics/forklift-string-topic Error:KeeperErrorCode = NoNode for /config/topics/forklift-string-topic
2017-06-02 17:38:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x53 zxid:0x2d txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:38:15 [kafka-producer-network-thread | producer-26] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 0 : {forklift-string-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:38:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x6a zxid:0x30 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/3
2017-06-02 17:38:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x6b zxid:0x31 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions
2017-06-02 17:38:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x6f zxid:0x35 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/14
2017-06-02 17:38:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x72 zxid:0x38 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/12
2017-06-02 17:38:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x75 zxid:0x3b txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/8
2017-06-02 17:38:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x78 zxid:0x3e txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/6
2017-06-02 17:38:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x7b zxid:0x41 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/7
2017-06-02 17:38:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x7e zxid:0x44 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/13
2017-06-02 17:38:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x81 zxid:0x47 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/10
2017-06-02 17:38:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x84 zxid:0x4a txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/5
2017-06-02 17:38:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x87 zxid:0x4d txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/2
2017-06-02 17:38:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x8a zxid:0x50 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/4
2017-06-02 17:38:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x8d zxid:0x53 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/11
2017-06-02 17:38:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x90 zxid:0x56 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/15
2017-06-02 17:38:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x93 zxid:0x59 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/1
2017-06-02 17:38:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x96 zxid:0x5c txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/9
2017-06-02 17:38:15 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x99 zxid:0x5f txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/0
2017-06-02 17:38:15 [kafka-producer-network-thread | producer-26] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 1 : {forklift-string-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:38:15 [qtp1444391509-1878] INFO  i.c.k.s.storage.KafkaStore - Wait to catch up until the offset of the last message at 1
2017-06-02 17:38:15 [qtp1444391509-1878] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:38:15 +0000] "POST /subjects/forklift-string-topic-value/versions HTTP/1.1" 200 8  85
2017-06-02 17:38:16 [pool-5-thread-28] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:38:16 [pool-5-thread-28] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = consumer-19
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:38:16 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:38:16 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:38:16 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:38:16 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:setData cxid:0xb3 zxid:0x62 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0xb4 zxid:0x63 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0xed zxid:0x66 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0xee zxid:0x67 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0xf2 zxid:0x6b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0xf5 zxid:0x6e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0xf8 zxid:0x71 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0xfb zxid:0x74 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0xfe zxid:0x77 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x101 zxid:0x7a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x104 zxid:0x7d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x107 zxid:0x80 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x10a zxid:0x83 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x10d zxid:0x86 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x110 zxid:0x89 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x113 zxid:0x8c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x116 zxid:0x8f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x119 zxid:0x92 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x11c zxid:0x95 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x11f zxid:0x98 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x122 zxid:0x9b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x128 zxid:0x9e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x12b zxid:0xa1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x12e zxid:0xa4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x131 zxid:0xa7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x134 zxid:0xaa txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x137 zxid:0xad txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x13a zxid:0xb0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x13d zxid:0xb3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x140 zxid:0xb6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x143 zxid:0xb9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x146 zxid:0xbc txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x149 zxid:0xbf txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x14c zxid:0xc2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x14f zxid:0xc5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x152 zxid:0xc8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x155 zxid:0xcb txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x158 zxid:0xce txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x15b zxid:0xd1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x15e zxid:0xd4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x161 zxid:0xd7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x164 zxid:0xda txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x167 zxid:0xdd txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x16a zxid:0xe0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x16d zxid:0xe3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x170 zxid:0xe6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x173 zxid:0xe9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x176 zxid:0xec txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x179 zxid:0xef txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x17c zxid:0xf2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x17f zxid:0xf5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x182 zxid:0xf8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2017-06-02 17:38:16 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e2cf370000 type:create cxid:0x185 zxid:0xfb txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2017-06-02 17:38:20 [pool-89-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:38:20 [pool-89-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [] for group testGroup
2017-06-02 17:38:20 [pool-89-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:38:20 [pool-89-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Successfully joined group testGroup with generation 1
2017-06-02 17:38:20 [pool-89-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Setting newly assigned partitions [forklift-string-topic-15, forklift-string-topic-14, forklift-string-topic-13, forklift-string-topic-12, forklift-string-topic-11, forklift-string-topic-10, forklift-string-topic-9, forklift-string-topic-8, forklift-string-topic-7, forklift-string-topic-6, forklift-string-topic-5, forklift-string-topic-4, forklift-string-topic-3, forklift-string-topic-2, forklift-string-topic-1, forklift-string-topic-0] for group testGroup
2017-06-02 17:38:20 [qtp1444391509-1879] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:38:20 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 552  74
2017-06-02 17:38:23 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:38:23 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - SentIds: 1000 consumedIds: 1000
2017-06-02 17:38:23 [pool-89-thread-1] INFO  forklift.controller.KafkaController - Wakeup, controlLoop exiting
2017-06-02 17:38:23 [pool-89-thread-1] INFO  forklift.controller.KafkaController - closing offset size committed: 16
2017-06-02 17:38:25 [pool-5-thread-28] ERROR forklift.controller.KafkaController - Failed to stop KafkaController in 2000 MILLISECONDS
2017-06-02 17:38:25 [pool-5-thread-28] INFO  o.a.k.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-06-02 17:38:25 [pool-5-thread-28] INFO  o.e.j.s.NetworkTrafficServerConnector - Stopped NetworkTrafficServerConnector@2b502796{HTTP/1.1}{localhost:58081}
2017-06-02 17:38:25 [pool-5-thread-28] INFO  o.e.j.server.handler.ContextHandler - Stopped o.e.j.s.ServletContextHandler@32aae7dd{/,null,UNAVAILABLE}
2017-06-02 17:38:25 [pool-5-thread-28] INFO  i.c.k.s.storage.KafkaSchemaRegistry - Shutting down schema registry
[2017-06-02 17:38:25,330] INFO [kafka-store-reader-thread-_schemas], Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
[2017-06-02 17:38:25,334] INFO [kafka-store-reader-thread-_schemas], Stopped  (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
[2017-06-02 17:38:25,334] INFO [kafka-store-reader-thread-_schemas], Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
2017-06-02 17:38:25 [pool-5-thread-28] INFO  i.c.k.s.s.KafkaStoreReaderThread - KafkaStoreReaderThread shutdown complete.
2017-06-02 17:38:25 [pool-5-thread-28] INFO  o.a.k.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-06-02 17:38:25 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e2cf370001
2017-06-02 17:38:25 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /0:0:0:0:0:0:0:1:58372 which had sessionid 0x15c69e2cf370001
2017-06-02 17:38:25 [pool-82-thread-3-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e2cf370001
2017-06-02 17:38:25 [pool-5-thread-28] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e2cf370001 closed
2017-06-02 17:38:25 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e2cf370003
2017-06-02 17:38:25 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /0:0:0:0:0:0:0:1:58398 which had sessionid 0x15c69e2cf370003
2017-06-02 17:38:25 [pool-5-thread-28] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e2cf370003 closed
2017-06-02 17:38:25 [pool-82-thread-3-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e2cf370003
2017-06-02 17:38:27 [pool-89-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:38:27 [pool-89-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:38:29 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e2cf370000
2017-06-02 17:38:29 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /0:0:0:0:0:0:0:1:58356 which had sessionid 0x15c69e2cf370000
2017-06-02 17:38:29 [pool-5-thread-28] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e2cf370000 closed
2017-06-02 17:38:29 [pool-82-thread-2-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e2cf370000
2017-06-02 17:38:31 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - NIOServerCnxn factory exited run method
2017-06-02 17:38:31 [pool-5-thread-28] INFO  o.a.zookeeper.server.ZooKeeperServer - shutting down
2017-06-02 17:38:31 [pool-5-thread-28] INFO  o.a.z.server.SessionTrackerImpl - Shutting down
2017-06-02 17:38:31 [pool-5-thread-28] INFO  o.a.z.server.PrepRequestProcessor - Shutting down
2017-06-02 17:38:31 [pool-5-thread-28] INFO  o.a.z.server.SyncRequestProcessor - Shutting down
2017-06-02 17:38:31 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - PrepRequestProcessor exited loop!
2017-06-02 17:38:31 [SyncThread:0] INFO  o.a.z.server.SyncRequestProcessor - SyncRequestProcessor exited!
2017-06-02 17:38:31 [pool-5-thread-28] INFO  o.a.z.server.FinalRequestProcessor - shutdown of request processor complete
2017-06-02 17:38:32 [SessionTracker] INFO  o.a.z.server.SessionTrackerImpl - SessionTrackerImpl exited loop!
2017-06-02 17:38:32 [pool-91-thread-1] INFO  o.a.z.server.ZooKeeperServerMain - Starting server
2017-06-02 17:38:32 [pool-91-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - tickTime set to 2000
2017-06-02 17:38:32 [pool-91-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - minSessionTimeout set to -1
2017-06-02 17:38:32 [pool-91-thread-1] INFO  o.a.zookeeper.server.ZooKeeperServer - maxSessionTimeout set to -1
2017-06-02 17:38:32 [pool-91-thread-1] INFO  o.a.z.server.NIOServerCnxnFactory - binding to port 0.0.0.0/0.0.0.0:42181
2017-06-02 17:38:32 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:41264
2017-06-02 17:38:32 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] WARN  o.a.zookeeper.server.NIOServerCnxn - caught end of stream exception
org.apache.zookeeper.server.ServerCnxn$EndOfStreamException: Unable to read additional data from client sessionid 0x0, likely client has closed socket
	at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228) ~[zookeeper-3.4.9.jar:3.4.9-1757313]
	at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFactory.java:203) [zookeeper-3.4.9.jar:3.4.9-1757313]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_31]
2017-06-02 17:38:32 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /127.0.0.1:41264 (no session established for client)
2017-06-02 17:38:32 [pool-91-thread-2] INFO  kafka.server.KafkaConfig - KafkaConfig values: 
	advertised.host.name = null
	advertised.listeners = null
	advertised.port = null
	authorizer.class.name = 
	auto.create.topics.enable = true
	auto.leader.rebalance.enable = true
	background.threads = 10
	broker.id = 1
	broker.id.generation.enable = true
	broker.rack = null
	compression.type = producer
	connections.max.idle.ms = 600000
	controlled.shutdown.enable = true
	controlled.shutdown.max.retries = 3
	controlled.shutdown.retry.backoff.ms = 5000
	controller.socket.timeout.ms = 30000
	default.replication.factor = 1
	delete.topic.enable = false
	fetch.purgatory.purge.interval.requests = 1000
	group.max.session.timeout.ms = 300000
	group.min.session.timeout.ms = 6000
	host.name = 
	inter.broker.protocol.version = 0.10.1-IV2
	leader.imbalance.check.interval.seconds = 300
	leader.imbalance.per.broker.percentage = 10
	listeners = PLAINTEXT://:49092
	log.cleaner.backoff.ms = 15000
	log.cleaner.dedupe.buffer.size = 134217728
	log.cleaner.delete.retention.ms = 86400000
	log.cleaner.enable = true
	log.cleaner.io.buffer.load.factor = 0.9
	log.cleaner.io.buffer.size = 524288
	log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
	log.cleaner.min.cleanable.ratio = 0.5
	log.cleaner.min.compaction.lag.ms = 0
	log.cleaner.threads = 1
	log.cleanup.policy = [delete]
	log.dir = /tmp/kafka-logs
	log.dirs = /home/travis/build/dcshock/forklift/src/test/resources/zafka
	log.flush.interval.messages = 9223372036854775807
	log.flush.interval.ms = null
	log.flush.offset.checkpoint.interval.ms = 60000
	log.flush.scheduler.interval.ms = 9223372036854775807
	log.index.interval.bytes = 4096
	log.index.size.max.bytes = 10485760
	log.message.format.version = 0.10.1-IV2
	log.message.timestamp.difference.max.ms = 9223372036854775807
	log.message.timestamp.type = CreateTime
	log.preallocate = false
	log.retention.bytes = -1
	log.retention.check.interval.ms = 300000
	log.retention.hours = 168
	log.retention.minutes = null
	log.retention.ms = null
	log.roll.hours = 168
	log.roll.jitter.hours = 0
	log.roll.jitter.ms = null
	log.roll.ms = null
	log.segment.bytes = 1073741824
	log.segment.delete.delay.ms = 60000
	max.connections.per.ip = 2147483647
	max.connections.per.ip.overrides = 
	message.max.bytes = 1000012
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	min.insync.replicas = 1
	num.io.threads = 8
	num.network.threads = 3
	num.partitions = 16
	num.recovery.threads.per.data.dir = 1
	num.replica.fetchers = 1
	offset.metadata.max.bytes = 4096
	offsets.commit.required.acks = -1
	offsets.commit.timeout.ms = 5000
	offsets.load.buffer.size = 5242880
	offsets.retention.check.interval.ms = 600000
	offsets.retention.minutes = 1440
	offsets.topic.compression.codec = 0
	offsets.topic.num.partitions = 50
	offsets.topic.replication.factor = 3
	offsets.topic.segment.bytes = 104857600
	port = 9092
	principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
	producer.purgatory.purge.interval.requests = 1000
	queued.max.requests = 500
	quota.consumer.default = 9223372036854775807
	quota.producer.default = 9223372036854775807
	quota.window.num = 11
	quota.window.size.seconds = 1
	replica.fetch.backoff.ms = 1000
	replica.fetch.max.bytes = 1048576
	replica.fetch.min.bytes = 1
	replica.fetch.response.max.bytes = 10485760
	replica.fetch.wait.max.ms = 500
	replica.high.watermark.checkpoint.interval.ms = 5000
	replica.lag.time.max.ms = 10000
	replica.socket.receive.buffer.bytes = 65536
	replica.socket.timeout.ms = 30000
	replication.quota.window.num = 11
	replication.quota.window.size.seconds = 1
	request.timeout.ms = 30000
	reserved.broker.max.id = 1000
	sasl.enabled.mechanisms = [GSSAPI]
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.principal.to.local.rules = [DEFAULT]
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism.inter.broker.protocol = GSSAPI
	security.inter.broker.protocol = PLAINTEXT
	socket.receive.buffer.bytes = 102400
	socket.request.max.bytes = 104857600
	socket.send.buffer.bytes = 102400
	ssl.cipher.suites = null
	ssl.client.auth = none
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	unclean.leader.election.enable = true
	zookeeper.connect = localhost:42181
	zookeeper.connection.timeout.ms = 6000
	zookeeper.session.timeout.ms = 6000
	zookeeper.set.acl = false
	zookeeper.sync.time.ms = 2000

2017-06-02 17:38:32 [pool-91-thread-2] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181 sessionTimeout=6000 watcher=org.I0Itec.zkclient.ZkClient@12576a42
2017-06-02 17:38:32 [pool-91-thread-2-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:38:32 [pool-91-thread-2-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/0:0:0:0:0:0:0:1:42181, initiating session
2017-06-02 17:38:32 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /0:0:0:0:0:0:0:1:58604
2017-06-02 17:38:32 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /0:0:0:0:0:0:0:1:58604
2017-06-02 17:38:32 [SyncThread:0] INFO  o.a.z.server.persistence.FileTxnLog - Creating new log file: log.1
2017-06-02 17:38:32 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e324590000 with negotiated timeout 6000 for client /0:0:0:0:0:0:0:1:58604
2017-06-02 17:38:32 [pool-91-thread-2-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:42181, sessionid = 0x15c69e324590000, negotiated timeout = 6000
2017-06-02 17:38:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x4 zxid:0x3 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NoNode for /brokers
2017-06-02 17:38:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0xa zxid:0x7 txntype:-1 reqpath:n/a Error Path:/config Error:KeeperErrorCode = NoNode for /config
2017-06-02 17:38:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x12 zxid:0xc txntype:-1 reqpath:n/a Error Path:/admin Error:KeeperErrorCode = NoNode for /admin
2017-06-02 17:38:32 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x1a zxid:0x11 txntype:-1 reqpath:n/a Error Path:/cluster Error:KeeperErrorCode = NoNode for /cluster
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:setData cxid:0x22 zxid:0x15 txntype:-1 reqpath:n/a Error Path:/controller_epoch Error:KeeperErrorCode = NoNode for /controller_epoch
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:delete cxid:0x33 zxid:0x17 txntype:-1 reqpath:n/a Error Path:/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /admin/preferred_replica_election
2017-06-02 17:38:33 [pool-89-thread-1] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 77 : {forklift-string-topic=INVALID_REPLICATION_FACTOR}
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x3f zxid:0x18 txntype:-1 reqpath:n/a Error Path:/brokers Error:KeeperErrorCode = NodeExists for /brokers
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x40 zxid:0x19 txntype:-1 reqpath:n/a Error Path:/brokers/ids Error:KeeperErrorCode = NodeExists for /brokers/ids
2017-06-02 17:38:33 [pool-91-thread-2] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:38:33 [pool-91-thread-2] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:setData cxid:0x48 zxid:0x1b txntype:-1 reqpath:n/a Error Path:/config/topics/forklift-string-topic Error:KeeperErrorCode = NoNode for /config/topics/forklift-string-topic
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x49 zxid:0x1c txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x60 zxid:0x1f txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/3
2017-06-02 17:38:33 [pool-89-thread-1] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 78 : {forklift-string-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:setData cxid:0x65 zxid:0x20 txntype:-1 reqpath:n/a Error Path:/config/topics/__consumer_offsets Error:KeeperErrorCode = NoNode for /config/topics/__consumer_offsets
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x66 zxid:0x21 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x67 zxid:0x22 txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x6d zxid:0x28 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/14
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x70 zxid:0x2b txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/12
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x73 zxid:0x2e txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/8
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x76 zxid:0x31 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/6
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x79 zxid:0x34 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/7
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x7c zxid:0x37 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/13
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x7f zxid:0x3a txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/10
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x82 zxid:0x3d txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/5
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x85 zxid:0x40 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/2
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x88 zxid:0x43 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/4
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x8b zxid:0x46 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/11
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x90 zxid:0x49 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/15
2017-06-02 17:38:33 [pool-89-thread-1] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 80 : {forklift-string-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x94 zxid:0x4c txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/1
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x99 zxid:0x4f txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/9
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x9d zxid:0x52 txntype:-1 reqpath:n/a Error Path:/brokers/topics/forklift-string-topic/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/forklift-string-topic/partitions/0
2017-06-02 17:38:33 [pool-89-thread-1] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 82 : {forklift-string-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0xdd zxid:0x55 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/32 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/32
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0xde zxid:0x56 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0xe9 zxid:0x5a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/16 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/16
2017-06-02 17:38:33 [pool-89-thread-1] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 84 : {forklift-string-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0xf1 zxid:0x5d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/49 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/49
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0xf5 zxid:0x60 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/44 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/44
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0xf9 zxid:0x63 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/28 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/28
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0xfe zxid:0x66 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/17 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/17
2017-06-02 17:38:33 [pool-89-thread-1] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 86 : {forklift-string-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x102 zxid:0x69 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/23 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/23
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x109 zxid:0x6c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/7 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/7
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x10d zxid:0x6f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/4 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/4
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x110 zxid:0x72 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/29 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/29
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x114 zxid:0x75 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/35 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/35
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x117 zxid:0x78 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/3 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/3
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x11b zxid:0x7b txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/24 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/24
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x11e zxid:0x7e txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/41 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/41
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x121 zxid:0x81 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/0
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x125 zxid:0x84 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/38 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/38
2017-06-02 17:38:33 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x129 zxid:0x87 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/13 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/13
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x12f zxid:0x8a txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/8 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/8
2017-06-02 17:38:34 [pool-89-thread-1] WARN  o.apache.kafka.clients.NetworkClient - Error while fetching metadata with correlation id 88 : {forklift-string-topic=LEADER_NOT_AVAILABLE}
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x135 zxid:0x8d txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/5 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/5
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x139 zxid:0x90 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/39 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/39
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x13c zxid:0x93 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/36 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/36
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x13f zxid:0x96 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/40 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/40
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x142 zxid:0x99 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/45 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/45
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x145 zxid:0x9c txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/15 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/15
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x148 zxid:0x9f txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/33 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/33
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x14b zxid:0xa2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/37 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/37
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x14e zxid:0xa5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/21 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/21
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x151 zxid:0xa8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/6 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/6
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x154 zxid:0xab txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/11 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/11
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x157 zxid:0xae txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/20 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/20
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x15a zxid:0xb1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/47 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/47
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x15d zxid:0xb4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/2 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/2
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x160 zxid:0xb7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/27 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/27
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x165 zxid:0xba txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/34 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/34
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x169 zxid:0xbd txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/9 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/9
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x16c zxid:0xc0 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/22 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/22
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x16f zxid:0xc3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/42 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/42
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x172 zxid:0xc6 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/14 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/14
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x175 zxid:0xc9 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/25 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/25
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x178 zxid:0xcc txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/10 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/10
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x17b zxid:0xcf txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/48 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/48
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x17e zxid:0xd2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/31 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/31
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x181 zxid:0xd5 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/18 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/18
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x184 zxid:0xd8 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/19 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/19
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x187 zxid:0xdb txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/12 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/12
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x18a zxid:0xde txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/46 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/46
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x18d zxid:0xe1 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/43 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/43
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x190 zxid:0xe4 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/1 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/1
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x193 zxid:0xe7 txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/26 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/26
2017-06-02 17:38:34 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x196 zxid:0xea txntype:-1 reqpath:n/a Error Path:/brokers/topics/__consumer_offsets/partitions/30 Error:KeeperErrorCode = NoNode for /brokers/topics/__consumer_offsets/partitions/30
2017-06-02 17:38:35 [pool-89-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:38:35 [pool-89-thread-1] ERROR forklift.controller.KafkaController - controlLoop error commiting sync
org.apache.kafka.clients.consumer.CommitFailedException: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing the session timeout or by reducing the maximum size of batches returned in poll() with max.poll.records.
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetCommitResponseHandler.handle(ConsumerCoordinator.java:674) ~[kafka-clients-0.10.1.1-cp1.jar:na]
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetCommitResponseHandler.handle(ConsumerCoordinator.java:615) ~[kafka-clients-0.10.1.1-cp1.jar:na]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$CoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:742) ~[kafka-clients-0.10.1.1-cp1.jar:na]
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$CoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:722) ~[kafka-clients-0.10.1.1-cp1.jar:na]
	at org.apache.kafka.clients.consumer.internals.RequestFuture$1.onSuccess(RequestFuture.java:186) ~[kafka-clients-0.10.1.1-cp1.jar:na]
	at org.apache.kafka.clients.consumer.internals.RequestFuture.fireSuccess(RequestFuture.java:149) ~[kafka-clients-0.10.1.1-cp1.jar:na]
	at org.apache.kafka.clients.consumer.internals.RequestFuture.complete(RequestFuture.java:116) ~[kafka-clients-0.10.1.1-cp1.jar:na]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler.fireCompletion(ConsumerNetworkClient.java:479) ~[kafka-clients-0.10.1.1-cp1.jar:na]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.firePendingCompletedRequests(ConsumerNetworkClient.java:316) ~[kafka-clients-0.10.1.1-cp1.jar:na]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:256) ~[kafka-clients-0.10.1.1-cp1.jar:na]
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:180) ~[kafka-clients-0.10.1.1-cp1.jar:na]
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:499) ~[kafka-clients-0.10.1.1-cp1.jar:na]
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1104) ~[kafka-clients-0.10.1.1-cp1.jar:na]
	at forklift.controller.KafkaController.controlLoop(KafkaController.java:198) ~[classes/:na]
	at forklift.controller.KafkaController$$Lambda$160/917792966.run(Unknown Source) [classes/:na]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [na:1.8.0_31]
	at java.util.concurrent.FutureTask.run(FutureTask.java:266) [na:1.8.0_31]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [na:1.8.0_31]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [na:1.8.0_31]
	at java.lang.Thread.run(Thread.java:745) [na:1.8.0_31]
2017-06-02 17:38:35 [pool-89-thread-1] INFO  forklift.controller.KafkaController - controlLoop closing kafkaConsumer
2017-06-02 17:38:35 [pool-91-thread-3] INFO  i.c.k.s.rest.SchemaRegistryConfig - SchemaRegistryConfig values: 
	metric.reporters = []
	kafkastore.sasl.kerberos.kinit.cmd = /usr/bin/kinit
	response.mediatype.default = application/vnd.schemaregistry.v1+json
	kafkastore.ssl.trustmanager.algorithm = PKIX
	authentication.realm = 
	ssl.keystore.type = JKS
	kafkastore.topic = _schemas
	metrics.jmx.prefix = kafka.schema.registry
	kafkastore.ssl.enabled.protocols = TLSv1.2,TLSv1.1,TLSv1
	kafkastore.topic.replication.factor = 3
	ssl.truststore.password = 
	kafkastore.timeout.ms = 500
	host.name = localhost
	kafkastore.bootstrap.servers = []
	schema.registry.zk.namespace = schema_registry
	kafkastore.sasl.kerberos.ticket.renew.window.factor = 0.8
	kafkastore.sasl.kerberos.service.name = 
	ssl.endpoint.identification.algorithm = 
	compression.enable = false
	kafkastore.ssl.truststore.type = JKS
	avro.compatibility.level = full
	kafkastore.ssl.protocol = TLS
	kafkastore.ssl.provider = 
	kafkastore.ssl.truststore.location = 
	response.mediatype.preferred = [application/vnd.schemaregistry.v1+json, application/vnd.schemaregistry+json, application/json]
	kafkastore.ssl.keystore.type = JKS
	ssl.truststore.type = JKS
	kafkastore.ssl.truststore.password = 
	access.control.allow.origin = 
	ssl.truststore.location = 
	ssl.keystore.password = 
	port = 8081
	kafkastore.ssl.keystore.location = 
	master.eligibility = true
	ssl.client.auth = false
	kafkastore.ssl.keystore.password = 
	kafkastore.security.protocol = PLAINTEXT
	ssl.trustmanager.algorithm = 
	authentication.method = NONE
	request.logger.name = io.confluent.rest-utils.requests
	ssl.key.password = 
	kafkastore.zk.session.timeout.ms = 30000
	kafkastore.sasl.mechanism = GSSAPI
	kafkastore.sasl.kerberos.ticket.renew.jitter = 0.05
	kafkastore.ssl.key.password = 
	zookeeper.set.acl = false
	authentication.roles = [*]
	metrics.num.samples = 2
	ssl.protocol = TLS
	kafkastore.ssl.keymanager.algorithm = SunX509
	kafkastore.connection.url = localhost:42181
	debug = false
	listeners = [http://localhost:58081]
	ssl.provider = 
	ssl.enabled.protocols = []
	shutdown.graceful.ms = 1000
	ssl.keystore.location = 
	ssl.cipher.suites = []
	kafkastore.ssl.endpoint.identification.algorithm = 
	kafkastore.ssl.cipher.suites = 
	access.control.allow.methods = 
	kafkastore.sasl.kerberos.min.time.before.relogin = 60000
	ssl.keymanager.algorithm = 
	metrics.sample.window.ms = 30000
	kafkastore.init.timeout.ms = 60000

2017-06-02 17:38:35 [pool-91-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@75faa3fd
2017-06-02 17:38:35 [pool-91-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:38:35 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:41300
2017-06-02 17:38:35 [pool-91-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/127.0.0.1:42181, initiating session
2017-06-02 17:38:35 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:41300
2017-06-02 17:38:35 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e324590001 with negotiated timeout 30000 for client /127.0.0.1:41300
2017-06-02 17:38:35 [pool-91-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:42181, sessionid = 0x15c69e324590001, negotiated timeout = 30000
2017-06-02 17:38:35 [pool-91-thread-3] INFO  i.c.k.s.storage.KafkaStore - Initializing KafkaStore with broker endpoints: PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092
2017-06-02 17:38:35 [pool-91-thread-3] WARN  i.c.k.s.storage.KafkaStore - Creating the schema topic _schemas using a replication factor of 1, which is less than the desired one of 3. If this is a production environment, it's crucial to add more brokers and increase the replication factor of the topic.
2017-06-02 17:38:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590001 type:setData cxid:0x8 zxid:0xee txntype:-1 reqpath:n/a Error Path:/config/topics/_schemas Error:KeeperErrorCode = NoNode for /config/topics/_schemas
2017-06-02 17:38:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590001 type:create cxid:0x9 zxid:0xef txntype:-1 reqpath:n/a Error Path:/config/topics Error:KeeperErrorCode = NodeExists for /config/topics
2017-06-02 17:38:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x1dc zxid:0xf2 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_schemas/partitions/0 Error:KeeperErrorCode = NoNode for /brokers/topics/_schemas/partitions/0
2017-06-02 17:38:35 [pool-91-thread-3] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2017-06-02 17:38:35 [pool-91-thread-3] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = -1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	buffer.memory = 33554432
	client.id = producer-27
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

2017-06-02 17:38:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590000 type:create cxid:0x1dd zxid:0xf3 txntype:-1 reqpath:n/a Error Path:/brokers/topics/_schemas/partitions Error:KeeperErrorCode = NoNode for /brokers/topics/_schemas/partitions
2017-06-02 17:38:35 [pool-91-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:38:35 [pool-91-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:38:35 [pool-91-thread-3] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	check.crcs = true
	client.id = KafkaStore-reader-_schemas
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = schema-registry-localhost-58081
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-06-02 17:38:35 [pool-91-thread-3] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [PLAINTEXT://testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092]
	check.crcs = true
	client.id = KafkaStore-reader-_schemas
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = schema-registry-localhost-58081
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2017-06-02 17:38:35 [pool-91-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:38:35 [pool-91-thread-3] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:38:35 [pool-91-thread-3] INFO  i.c.k.s.s.KafkaStoreReaderThread - Initialized last consumed offset to -1
[2017-06-02 17:38:35,225] INFO [kafka-store-reader-thread-_schemas], Starting  (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
2017-06-02 17:38:35 [pool-91-thread-3] INFO  i.c.k.s.storage.KafkaStore - Wait to catch up until the offset of the last message at 0
2017-06-02 17:38:35 [pool-91-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181 sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@739e81f
2017-06-02 17:38:35 [pool-91-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/127.0.0.1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:38:35 [pool-91-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/127.0.0.1:42181, initiating session
2017-06-02 17:38:35 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /127.0.0.1:41320
2017-06-02 17:38:35 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /127.0.0.1:41320
2017-06-02 17:38:35 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e324590002 with negotiated timeout 30000 for client /127.0.0.1:41320
2017-06-02 17:38:35 [pool-91-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/127.0.0.1:42181, sessionid = 0x15c69e324590002, negotiated timeout = 30000
2017-06-02 17:38:35 [pool-91-thread-3] INFO  i.c.k.s.storage.KafkaSchemaRegistry - Created schema registry namespace localhost:42181/schema_registry
2017-06-02 17:38:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e324590002
2017-06-02 17:38:35 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /127.0.0.1:41320 which had sessionid 0x15c69e324590002
2017-06-02 17:38:35 [pool-91-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e324590002 closed
2017-06-02 17:38:35 [pool-91-thread-3-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e324590002
2017-06-02 17:38:35 [pool-91-thread-3] INFO  org.apache.zookeeper.ZooKeeper - Initiating client connection, connectString=localhost:42181/schema_registry sessionTimeout=30000 watcher=org.I0Itec.zkclient.ZkClient@59d7e4d
2017-06-02 17:38:35 [pool-91-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:42181. Will not attempt to authenticate using SASL (unknown error)
2017-06-02 17:38:35 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - Accepted socket connection from /0:0:0:0:0:0:0:1:58654
2017-06-02 17:38:35 [pool-91-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Socket connection established to localhost/0:0:0:0:0:0:0:1:42181, initiating session
2017-06-02 17:38:35 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.ZooKeeperServer - Client attempting to establish new session at /0:0:0:0:0:0:0:1:58654
2017-06-02 17:38:35 [SyncThread:0] INFO  o.a.zookeeper.server.ZooKeeperServer - Established session 0x15c69e324590003 with negotiated timeout 30000 for client /0:0:0:0:0:0:0:1:58654
2017-06-02 17:38:35 [pool-91-thread-3-SendThread(localhost:42181)] INFO  org.apache.zookeeper.ClientCnxn - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:42181, sessionid = 0x15c69e324590003, negotiated timeout = 30000
2017-06-02 17:38:35 [pool-91-thread-3] INFO  i.c.k.s.z.ZookeeperMasterElector - Successfully elected the new master: {"host":"localhost","port":58081,"master_eligibility":true,"version":1}
2017-06-02 17:38:35 [pool-91-thread-3] INFO  io.confluent.rest.Application - Adding listener: http://localhost:58081
2017-06-02 17:38:35 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Got user-level KeeperException when processing sessionid:0x15c69e324590003 type:create cxid:0x7 zxid:0xfd txntype:-1 reqpath:n/a Error Path:/schema_registry/schema_registry_master Error:KeeperErrorCode = NodeExists for /schema_registry/schema_registry_master
2017-06-02 17:38:35 [ZkClient-EventThread-1943-localhost:42181/schema_registry] INFO  i.c.k.s.z.ZookeeperMasterElector - Successfully elected the new master: {"host":"localhost","port":58081,"master_eligibility":true,"version":1}
2017-06-02 17:38:35 [pool-91-thread-3] INFO  org.eclipse.jetty.server.Server - jetty-9.2.12.v20150709
2017-06-02 17:38:35 [pool-91-thread-3] INFO  o.e.j.server.handler.ContextHandler - Started o.e.j.s.ServletContextHandler@69e7320b{/,null,AVAILABLE}
2017-06-02 17:38:36 [pool-91-thread-3] INFO  o.e.j.s.NetworkTrafficServerConnector - Started NetworkTrafficServerConnector@4b247628{HTTP/1.1}{localhost:58081}
2017-06-02 17:38:36 [pool-91-thread-3] INFO  org.eclipse.jetty.server.Server - Started @420919ms
2017-06-02 17:38:37 [pool-5-thread-28] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = 
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:38:37 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:38:37 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000

2017-06-02 17:38:37 [pool-5-thread-28] INFO  o.a.k.c.producer.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	block.on.buffer.full = false
	bootstrap.servers = [127.0.0.1:49092]
	buffer.memory = 33554432
	client.id = producer-28
	compression.type = none
	connections.max.idle.ms = 540000
	interceptor.classes = null
	key.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.fetch.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 0
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	timeout.ms = 30000
	value.serializer = class io.confluent.kafka.serializers.KafkaAvroSerializer

2017-06-02 17:38:37 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:38:37 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:38:37 [qtp466436296-1952] INFO  i.c.k.s.storage.KafkaStore - Wait to catch up until the offset of the last message at 1
2017-06-02 17:38:37 [qtp466436296-1952] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:38:37 +0000] "POST /subjects/forklift-string-topic-value/versions HTTP/1.1" 200 8  94
2017-06-02 17:38:41 [pool-5-thread-28] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = 
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:38:41 [pool-5-thread-28] INFO  o.a.k.c.consumer.ConsumerConfig - ConsumerConfig values: 
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [127.0.0.1:49092]
	check.crcs = true
	client.id = consumer-20
	connections.max.idle.ms = 540000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = testGroup
	heartbeat.interval.ms = 3000
	interceptor.classes = null
	key.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 200
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.ms = 50
	request.timeout.ms = 305000
	retry.backoff.ms = 100
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.confluent.kafka.serializers.KafkaAvroDeserializer

2017-06-02 17:38:41 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:38:41 [pool-5-thread-28] INFO  i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	schema.registry.url = [http://127.0.0.1:58081]
	max.schemas.per.subject = 1000
	specific.avro.reader = false

2017-06-02 17:38:41 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka version : 0.10.1.1-cp1
2017-06-02 17:38:41 [pool-5-thread-28] INFO  o.a.kafka.common.utils.AppInfoParser - Kafka commitId : 240c37b2cde80127
2017-06-02 17:38:41 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Creating thread pool of 10
2017-06-02 17:38:41 [pool-98-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:38:41 [pool-98-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Revoking previously assigned partitions [] for group testGroup
2017-06-02 17:38:41 [pool-98-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - (Re-)joining group testGroup
2017-06-02 17:38:41 [pool-98-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Successfully joined group testGroup with generation 1
2017-06-02 17:38:41 [pool-98-thread-1] INFO  o.a.k.c.c.i.ConsumerCoordinator - Setting newly assigned partitions [forklift-string-topic-15, forklift-string-topic-14, forklift-string-topic-13, forklift-string-topic-12, forklift-string-topic-11, forklift-string-topic-10, forklift-string-topic-9, forklift-string-topic-8, forklift-string-topic-7, forklift-string-topic-6, forklift-string-topic-5, forklift-string-topic-4, forklift-string-topic-3, forklift-string-topic-2, forklift-string-topic-1, forklift-string-topic-0] for group testGroup
2017-06-02 17:38:41 [qtp466436296-1953] INFO  io.confluent.rest-utils.requests - 127.0.0.1 - - [02/Jun/2017:17:38:41 +0000] "GET /schemas/ids/1 HTTP/1.1" 200 552  40
2017-06-02 17:38:45 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Consumer shutting down
2017-06-02 17:38:45 [pool-5-thread-28] INFO  forklift.consumer.Consumer - Shutting down thread pool - active 0
2017-06-02 17:38:45 [pool-5-thread-28] INFO  f.integration.BaseIntegrationTest - SentIds: 10000 consumedIds: 10000
2017-06-02 17:38:45 [pool-98-thread-1] INFO  forklift.controller.KafkaController - Wakeup, controlLoop exiting
2017-06-02 17:38:45 [pool-98-thread-1] INFO  forklift.controller.KafkaController - closing offset size committed: 16
2017-06-02 17:38:45 [pool-98-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Marking the coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) dead for group testGroup
2017-06-02 17:38:46 [pool-98-thread-1] INFO  o.a.k.c.c.i.AbstractCoordinator - Discovered coordinator testing-docker-4b5344a7-fb33-4069-ab56-779f85c0ae0c:49092 (id: 2147483646 rack: null) for group testGroup.
2017-06-02 17:38:46 [pool-98-thread-1] INFO  forklift.controller.KafkaController - controlLoop closing kafkaConsumer
2017-06-02 17:38:46 [pool-5-thread-28] INFO  o.a.k.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-06-02 17:38:46 [pool-5-thread-28] INFO  o.e.j.s.NetworkTrafficServerConnector - Stopped NetworkTrafficServerConnector@4b247628{HTTP/1.1}{localhost:58081}
2017-06-02 17:38:46 [pool-5-thread-28] INFO  o.e.j.server.handler.ContextHandler - Stopped o.e.j.s.ServletContextHandler@69e7320b{/,null,UNAVAILABLE}
2017-06-02 17:38:46 [pool-5-thread-28] INFO  i.c.k.s.storage.KafkaSchemaRegistry - Shutting down schema registry
[2017-06-02 17:38:46,084] INFO [kafka-store-reader-thread-_schemas], Shutting down (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
[2017-06-02 17:38:46,088] INFO [kafka-store-reader-thread-_schemas], Stopped  (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
[2017-06-02 17:38:46,088] INFO [kafka-store-reader-thread-_schemas], Shutdown completed (io.confluent.kafka.schemaregistry.storage.KafkaStoreReaderThread:70)
2017-06-02 17:38:46 [pool-5-thread-28] INFO  i.c.k.s.s.KafkaStoreReaderThread - KafkaStoreReaderThread shutdown complete.
2017-06-02 17:38:46 [pool-5-thread-28] INFO  o.a.k.clients.producer.KafkaProducer - Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
2017-06-02 17:38:46 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e324590001
2017-06-02 17:38:46 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /127.0.0.1:41300 which had sessionid 0x15c69e324590001
2017-06-02 17:38:46 [pool-5-thread-28] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e324590001 closed
2017-06-02 17:38:46 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e324590003
2017-06-02 17:38:46 [pool-91-thread-3-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e324590001
2017-06-02 17:38:46 [pool-5-thread-28] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e324590003 closed
2017-06-02 17:38:46 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /0:0:0:0:0:0:0:1:58654 which had sessionid 0x15c69e324590003
2017-06-02 17:38:46 [pool-91-thread-3-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e324590003
2017-06-02 17:38:49 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - Processed session termination for sessionid: 0x15c69e324590000
2017-06-02 17:38:49 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.zookeeper.server.NIOServerCnxn - Closed socket connection for client /0:0:0:0:0:0:0:1:58604 which had sessionid 0x15c69e324590000
2017-06-02 17:38:49 [pool-5-thread-28] INFO  org.apache.zookeeper.ZooKeeper - Session: 0x15c69e324590000 closed
2017-06-02 17:38:49 [pool-91-thread-2-EventThread] INFO  org.apache.zookeeper.ClientCnxn - EventThread shut down for session: 0x15c69e324590000
2017-06-02 17:38:51 [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:42181] INFO  o.a.z.server.NIOServerCnxnFactory - NIOServerCnxn factory exited run method
2017-06-02 17:38:51 [pool-5-thread-28] INFO  o.a.zookeeper.server.ZooKeeperServer - shutting down
2017-06-02 17:38:51 [pool-5-thread-28] INFO  o.a.z.server.SessionTrackerImpl - Shutting down
2017-06-02 17:38:51 [pool-5-thread-28] INFO  o.a.z.server.PrepRequestProcessor - Shutting down
2017-06-02 17:38:51 [pool-5-thread-28] INFO  o.a.z.server.SyncRequestProcessor - Shutting down
2017-06-02 17:38:51 [ProcessThread(sid:0 cport:42181):] INFO  o.a.z.server.PrepRequestProcessor - PrepRequestProcessor exited loop!
2017-06-02 17:38:51 [SyncThread:0] INFO  o.a.z.server.SyncRequestProcessor - SyncRequestProcessor exited!
2017-06-02 17:38:51 [pool-5-thread-28] INFO  o.a.z.server.FinalRequestProcessor - shutdown of request processor complete
2017-06-02 17:38:52 [SessionTracker] INFO  o.a.z.server.SessionTrackerImpl - SessionTrackerImpl exited loop!
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest forklift.integration.[33mStringMessageTests[0m.[36mtestStringMessage[0m started[0m
[0m[[0minfo[0m] [0mTest forklift.integration.[33mStringMessageTests[0m.[36mtestMultiThreadedStringMessage[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 2 total, 41.699s[0m[0m
2017-06-02 17:38:52 [pool-104-thread-1] INFO  forklift.controller.KafkaController - closing offset size committed: 0
2017-06-02 17:38:52 [pool-104-thread-1] INFO  forklift.controller.KafkaController - controlLoop closing kafkaConsumer
2017-06-02 17:38:53 [pool-106-thread-1] INFO  forklift.controller.KafkaController - closing offset size committed: 0
2017-06-02 17:38:53 [pool-106-thread-1] INFO  forklift.controller.KafkaController - controlLoop closing kafkaConsumer
2017-06-02 17:38:53 [pool-107-thread-1] INFO  forklift.controller.KafkaController - Interrupted, controlLoop exiting
2017-06-02 17:38:53 [pool-107-thread-1] INFO  forklift.controller.KafkaController - closing offset size committed: 0
2017-06-02 17:38:53 [pool-107-thread-1] INFO  forklift.controller.KafkaController - controlLoop closing kafkaConsumer
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest forklift.connectors.[33mKafkaControllerTests[0m.[36maddTopicTrueTest[0m started[0m
[0m[[0minfo[0m] [0mTest forklift.connectors.[33mKafkaControllerTests[0m.[36mremoveNotAddedTopicTest[0m started[0m
[0m[[0minfo[0m] [0mTest forklift.connectors.[33mKafkaControllerTests[0m.[36mremoveAddedTopicTest[0m started[0m
[0m[[0minfo[0m] [0mTest forklift.connectors.[33mKafkaControllerTests[0m.[36maddRemoveAddTest[0m started[0m
[0m[[0minfo[0m] [0mTest forklift.connectors.[33mKafkaControllerTests[0m.[36maddTopicFalseTest[0m started[0m
[0m[[0minfo[0m] [0mTest forklift.connectors.[33mKafkaControllerTests[0m.[36mfirstSubscribeAndPollingTest[0m started[0m
[0m[[0minfo[0m] [0mTest forklift.connectors.[33mKafkaControllerTests[0m.[36misRunningTest[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 7 total, 0.465s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest forklift.connectors.[33mAcknowledgedRecordHandlerTests[0m.[36macknowledgeRecordFalseTest[0m started[0m
[0m[[0minfo[0m] [0mTest forklift.connectors.[33mAcknowledgedRecordHandlerTests[0m.[36mremovePartitionsOffsetTest[0m started[0m
[0m[[0minfo[0m] [0mTest forklift.connectors.[33mAcknowledgedRecordHandlerTests[0m.[36macknowledgeRecordTrueTest[0m started[0m
[0m[[0minfo[0m] [0mTest forklift.connectors.[33mAcknowledgedRecordHandlerTests[0m.[36mremovePartitionAcknowledgeTest[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 4 total, 0.003s[0m[0m
[0m[[0minfo[0m] [0m[34mTest run started[0m[0m
[0m[[0minfo[0m] [0mTest forklift.consumer.[33mKafkaTopicConsumerTests[0m.[36mreceiveTimeoutTest[0m started[0m
[0m[[0minfo[0m] [0mTest forklift.consumer.[33mKafkaTopicConsumerTests[0m.[36mreceiveMessageTest[0m started[0m
[0m[[0minfo[0m] [0mTest forklift.consumer.[33mKafkaTopicConsumerTests[0m.[36maddTopicTest[0m started[0m
[0m[[0minfo[0m] [0mTest forklift.consumer.[33mKafkaTopicConsumerTests[0m.[36mcloseAndRemoveTopicTest[0m started[0m
[0m[[0minfo[0m] [0mTest forklift.consumer.[33mKafkaTopicConsumerTests[0m.[36mreceiveWithControllerNotRunning[0m started[0m
[0m[[0minfo[0m] [0m[34mTest run finished: [0m[34m0 failed[0m[34m, [0m[34m0 ignored[0m[34m, 5 total, 0.098s[0m[0m
[0m[[0minfo[0m] [0mPassed: Total 32, Failed 0, Errors 0, Passed 32[0m
[0m[[32msuccess[0m] [0mTotal time: 321 s, completed Jun 2, 2017 5:38:57 PM[0m

travis_time:end:104bfdec:start=1496424694721074168,finish=1496425138877786104,duration=444156711936[0K
[32;1mThe command "sbt ++2.11.4 test" exited with 0.[0m

Done. Your build exited with 0.
